{
  "id": 433,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2023-11-17T02:26:24.154Z",
  "cooked": "<p>Hmm, I\u2019ve mostly been thinking of linearisation and chunking as synonyms \u2013 you never do one without the other, and once you\u2019re done you only deal with chunks, not individual txs.</p>\n<p>Feels to me like it might be possible to build up chunks from ancestor scoring directly (so create a graph of single-tx chunks; merge the chunks that cpfp each other greedily by ancestor fee rate; update anc fee rates as you go, which may result in other chunks cpfp\u2019ing newly merged chunks; then sort the resulting chunks by their final score), but trying to write it down, it doesn\u2019t seem much simpler compared to the approach you\u2019re suggesting.</p>\n<p>I think a simple-ish case this still wouldn\u2019t catch is:</p>\n<pre data-code-height=\"147\" data-code-wrap=\"mermaid\"><code class=\"lang-mermaid\">graph BT\n    A[A: 8]\n    B[B: 0, vsize=5x]\n    C[C: 12; afr=10] --&gt; A\n    D[D: 48; afr=8] --&gt; A\n    E[E: 48; afr=8] --&gt; A\n    D --&gt; B;\n    E --&gt; B;\n</code></pre>\n<p>(ie A,C,D,E are all the same size, B is 5x that size, A pays 8 in fees, C pays 12 in fees, etc)</p>\n<p>The ancestor linearisation is A,C,B,D,E (picking C then D then E), and (I think) the new algorithm would produce a single chunk with score 12.89, but it would be more optimal to generate ABDE,C with scores 13 and 12.</p>\n<p>Think that\u2019s just saying \u201cthis isn\u2019t optimal in all cases\u201d though, which isn\u2019t really news.</p>",
  "post_number": 2,
  "post_type": 1,
  "posts_count": 8,
  "updated_at": "2023-11-17T02:26:24.154Z",
  "reply_count": 0,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 0,
  "reads": 26,
  "readers_count": 25,
  "score": 65.2,
  "yours": false,
  "topic_id": 201,
  "topic_slug": "linearization-post-processing-o-n-2-fancy-chunking",
  "topic_title": "Linearization post-processing (O(n^2) fancy chunking)",
  "topic_html_title": "Linearization post-processing (O(n^2) fancy chunking)",
  "category_id": 8,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "Hmm, I've mostly been thinking of linearisation and chunking as synonyms -- you never do one without the other, and once you're done you only deal with chunks, not individual txs.\n\nFeels to me like it might be possible to build up chunks from ancestor scoring directly (so create a graph of single-tx chunks; merge the chunks that cpfp each other greedily by ancestor fee rate; update anc fee rates as you go, which may result in other chunks cpfp'ing newly merged chunks; then sort the resulting chunks by their final score), but trying to write it down, it doesn't seem much simpler compared to the approach you're suggesting.\n\nI think a simple-ish case this still wouldn't catch is:\n\n```mermaid height=147,auto\ngraph BT\n    A[A: 8]\n    B[B: 0, vsize=5x]\n    C[C: 12; afr=10] --> A\n    D[D: 48; afr=8] --> A\n    E[E: 48; afr=8] --> A\n    D --> B;\n    E --> B;\n```\n\n(ie A,C,D,E are all the same size, B is 5x that size, A pays 8 in fees, C pays 12 in fees, etc)\n\nThe ancestor linearisation is A,C,B,D,E (picking C then D then E), and (I think) the new algorithm would produce a single chunk with score 12.89, but it would be more optimal to generate ABDE,C with scores 13 and 12.\n\nThink that's just saying \"this isn't optimal in all cases\" though, which isn't really news.",
  "actions_summary": [
    {
      "id": 2,
      "count": 4
    }
  ],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Hmm, I\u2019ve mostly been thinking of linearisation and chunking as synonyms \u2013 you never do one without the other, and once you\u2019re done you only deal with chunks, not individual txs. \nFeels to me like it might be possible to build up chunks from ancestor scoring directly (so create a graph of single-tx &hellip;",
  "truncated": true,
  "post_url": "/t/linearization-post-processing-o-n-2-fancy-chunking/201/2",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 4
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 4,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}