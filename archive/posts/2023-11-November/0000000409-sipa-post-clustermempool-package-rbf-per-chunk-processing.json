{
  "id": 409,
  "name": "Pieter Wuille",
  "username": "sipa",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/1100_2.png",
  "created_at": "2023-11-14T19:30:47.607Z",
  "cooked": "<p>Successor to <a href=\"https://delvingbitcoin.org/t/post-clustermempool-package-rbf/173\" class=\"inline-onebox\">[DEFUNCT] Post-clustermempool Package RBF</a>. I felt starting over in a new topic is a bit cleaner.</p>\n<h3><a name=\"starting-from-a-minimal-design-1\" class=\"anchor\" href=\"#starting-from-a-minimal-design-1\"></a>Starting from a minimal design</h3>\n<p>As a thought experiment, start with a minimal design: the relayed package must be a single chunk (when not considering in-mempool ancestors) after linearization, and it is only ever considered in its entirety, or not at all. This avoids the complexity of trying to optimize finding the best subset to take subject to DoS constraints, is sufficient for the one-parent-one-child case, and computationally speaking, only involves a single feerate diagram comparison (the most potentially expensive step). I feel this would be a perfectly reasonable candidate design to consider for a first implementation.</p>\n<p>A straightforward generalization of this is possible: if the relayed package (excluding in-mempool ancestors) after linearization consists of multiple chunks, process them completely separately (exactly as if they were submitted one by one). This makes it not gratuitously reject packages due to the receiver unexpectedly splitting the linearization up as a result of having some subpackage already, but beyond that doesn\u2019t provide any \u201cquality\u201d that package-must-be-one-chunk wouldn\u2019t have. It\u2019s also not computationally worse - if multiple diagram checks are too expensive, processing can be interrupted (like GETDATA etc.) between chunks to limit P2P message processing latency. And since it\u2019s exactly equivalent to an attacker just giving multiple packages, there is no additional DoS concern either.</p>\n<p>Maybe that generalization is actually what we want already.</p>\n<h3><a name=\"resulting-proposal-2\" class=\"anchor\" href=\"#resulting-proposal-2\"></a>Resulting proposal</h3>\n<p>To be explicit, here is what that would amount to for a received package (set of transactions) <code>PKG</code>:</p>\n<ul>\n<li>\n<ol>\n<li><strong>Deduplication</strong>: remove from <code>PKG</code> any transaction that\u2019s already in the receiver\u2019s mempool.</li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li><strong>Pre-linearization</strong>: linearize (what remains of) <code>PKG</code> (so <em>without</em> in-mempool dependencies).</li>\n</ol>\n</li>\n<li>\n<ol start=\"3\">\n<li><strong>Splitting</strong>: For each chunk <code>CNK</code> in that linearization (in order of decreasing feerate):</li>\n</ol>\n<ul>\n<li>\n<ol start=\"4\">\n<li><strong>Limiting</strong>: If <code>feerate(CNK) &lt; max(mempoolminfee, incremental_relay_feerate)</code>, stop processing (of this and all further chunks). This is necessary to avoid tiny-increment replacements at the bottom of the mempool, and can cheaply be done early on. This only works because any low-feerate suffix of the linearization will, if accepted to the mempool, become a low-feerate set there too (and possibly even lower, if it\u2019s merged with other things). Thus, this lets us efficiently predict and prevent additions to the mempool that would be below its minimum feerate. This aspect does not work pre-clustermempool.</li>\n</ol>\n</li>\n<li>\n<ol start=\"5\">\n<li><strong>Conflict-finding</strong>: find the set <code>CON</code>, the in-mempool conflicts with <code>CNK</code>.</li>\n</ol>\n</li>\n<li>\n<ol start=\"6\">\n<li><strong>Replacement checks</strong>: Only necessary if <code>CON</code> is non-empty:</li>\n</ol>\n<ul>\n<li>\n<ol start=\"7\">\n<li><strong>Relay check</strong>: If <code>fee(CNK) &lt; fee(CON) + incremental_relay_feerate * size(CNK)</code>, then the replacement does not pay for relay of the chunk. If so, stop processing this chunk and continue with further ones (which may fail due to having dependencies in this failed chunk).</li>\n</ol>\n</li>\n<li>\n<ol start=\"8\">\n<li><strong>Tail check</strong>: if <code>fee(CNK) &lt; fee(CON) + tail_feerate * (size(CNK) - size(CON))</code>, the replacement worsens the bottom of the mempool, so continue with the next chunk. This check is only necessary if <code>tail_feerate &gt; incremental_relay_feerate</code>.</li>\n</ol>\n</li>\n<li>\n<ol start=\"9\">\n<li><strong>Gather OLD</strong>: the union of all in-mempool clusters that contain elements of <code>CON</code>, or contain ancestors of <code>CNK</code>.</li>\n</ol>\n</li>\n<li>\n<ol start=\"10\">\n<li><strong>Compute NEW</strong>: <code>NEW = OLD - CON + CNK</code>.</li>\n</ol>\n</li>\n<li>\n<ol start=\"11\">\n<li><strong>Linearization</strong>: linearize all clusters in <code>NEW</code> (note that there can be multiple; a replacement can split up clusters).</li>\n</ol>\n</li>\n<li>\n<ol start=\"12\">\n<li><strong>Diagram check</strong>: verify that the fee-size diagram of <code>NEW</code> is nowhere worse than that of <code>OLD</code>, and at least in some place better. If not, the replacement is not necessarily an improvement to the mempool, and continue with the next chunk.</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>\n<ol start=\"13\">\n<li><strong>Verification</strong>: verify all transactions in <code>CNK</code> under standard/policy rules (including script verification). If this fails, continue with the next chunk. Otherwise, the chunk is a valid and desirable addition/replacement to the mempool.</li>\n</ol>\n</li>\n<li>\n<ol start=\"14\">\n<li><strong>Eviction</strong> Drop all of <code>CON</code> from the mempool (if any).</li>\n</ol>\n</li>\n<li>\n<ol start=\"15\">\n<li><strong>Addition</strong> Add all of <code>CNK</code> to the mempool, performing consensus validation to prime execution/script caches, and have a last-resort check that consensus validity is implied by policy validity.</li>\n</ol>\n</li>\n<li>\n<ol start=\"16\">\n<li><strong>Interruption</strong> If needed, interrupt processing to allow other peers\u2019 messages</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3><a name=\"good-enough-3\" class=\"anchor\" href=\"#good-enough-3\"></a>Good enough?</h3>\n<p>The result of this whole thing is that it does result in a limited \u201cfind better subset of new package to accept\u201d over only considering all/nothing of package, but this seems more of a side-effect of trying to make sure things don\u2019t gratuitously break when the receiver\u2019s mempool differs, than being a goal on itself.</p>\n<p>Another observation is that this does <em>not</em> permit earlier chunks\u2019 replacements to pay for the relay of later chunks (every chunk needs to pay for itself), but it <em>does</em> permit replacements within one chunk to pay for the later transactions in the same chunk. Consider this example (<code>sats/bytes</code> notation, <code>mempoolminfee=1 sat/byte</code>):</p>\n<pre data-code-height=\"169\" data-code-wrap=\"mermaid\"><code class=\"lang-mermaid\">graph BT \n   B[\"Tx B: 500/100\"] --&gt; A[\"Tx A: 3000/1000\"];\n   B x--x |conflict| Bp[\"Tx B': 1000/500\"];\n</code></pre>\n<p>If only <code>B'</code> is in the mempool already, then the package <code>A,B</code> will be accepted by the above rules, because \u2018A\u2019 helps pay the fee for the relay of <code>B'</code>. If however <code>A,B'</code> were in the mempool already, then <code>B</code> would not be accepted as the net fee would be negative (and thus certainly not enough to pay for the relay of <code>B</code>).</p>\n<p>Because <code>B</code> is \u201cappropriating\u201d the fee from <code>A</code> to pay for the relay of <code>B'</code>, the replacement breaks if the receiver already has <code>A</code>. In principle, that means an attacker that sees <code>A,B</code> could choose to only pass on <code>A</code> to a victim, resulting in <code>B</code> becoming (semi-permanently) unacceptable to the victim. This may be undesirable to the author of <code>B</code>, but nothing can be done about this without fundamentally different anti-DoS rules. It\u2019s only possible to be more restrictive and not permit the replacement at all (e.g. by trying to split chunks up into even smaller pieces if they\u2019re below <code>mempoolminfee</code>). Instead, I believe the observation is just that appropriation of parent fees cannot be guaranteed to work, as it depends on how nodes see the transactions packaged up, so users should be advised to avoid it (and it\u2019s rather strange anyway, perhaps there aren\u2019t really use cases for it regardless).</p>\n<p>And I think that\u2019s also a justification why it is acceptable that this <em>wouldn\u2019t</em> work across chunks: since appropriation cannot cannot be relied on for the same reason (receiver may have higher chunk already), we don\u2019t need to spend effort on making appropriation work well (but if it\u2019s easier to permit it, like within-chunk, that\u2019s also not a problem).</p>\n<p><s>I\u2019m not sure it is also acceptable that it doesn\u2019t work across chunks in the other direction. It seems reasonable that we\u2019d want to permit child fees to pay for evictions necessary for their parents. If so, if the <strong>Relay check</strong> (7) fails, instead of stopping of processing, perhaps the loop can continue, but with the combination of all unprocessed chunks so far as <code>CNK</code>? That actually starts to sound a lot like the approach from PR26711, except gathering until DoS checks are satisfied, rather than gathering until feerate checks are satisfied.</s> EDIT: this is likely not necessary, and leads to complex interactions between feerate and fee checks.</p>\n<p>In a way, this design is pretty much taking what we\u2019re allowing today (submitting a transaction one by one), but now also permit grouping transactions together as little as possible while retaining the newly desired functionality: that higher-feerate children can be grouped with their parents at processing time.</p>",
  "post_number": 1,
  "post_type": 1,
  "posts_count": 16,
  "updated_at": "2024-04-25T20:27:27.920Z",
  "reply_count": 4,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 108,
  "reads": 47,
  "readers_count": 46,
  "score": 594.4,
  "yours": false,
  "topic_id": 190,
  "topic_slug": "post-clustermempool-package-rbf-per-chunk-processing",
  "topic_title": "Post-clustermempool package RBF: per-chunk processing",
  "topic_html_title": "Post-clustermempool package RBF: per-chunk processing",
  "category_id": 8,
  "display_username": "Pieter Wuille",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 16,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "Successor to https://delvingbitcoin.org/t/post-clustermempool-package-rbf/173. I felt starting over in a new topic is a bit cleaner.\n\n### Starting from a minimal design\n\nAs a thought experiment, start with a minimal design: the relayed package must be a single chunk (when not considering in-mempool ancestors) after linearization, and it is only ever considered in its entirety, or not at all. This avoids the complexity of trying to optimize finding the best subset to take subject to DoS constraints, is sufficient for the one-parent-one-child case, and computationally speaking, only involves a single feerate diagram comparison (the most potentially expensive step). I feel this would be a perfectly reasonable candidate design to consider for a first implementation.\n\nA straightforward generalization of this is possible: if the relayed package (excluding in-mempool ancestors) after linearization consists of multiple chunks, process them completely separately (exactly as if they were submitted one by one). This makes it not gratuitously reject packages due to the receiver unexpectedly splitting the linearization up as a result of having some subpackage already, but beyond that doesn't provide any \"quality\" that package-must-be-one-chunk wouldn't have. It's also not computationally worse - if multiple diagram checks are too expensive, processing can be interrupted (like GETDATA etc.) between chunks to limit P2P message processing latency. And since it's exactly equivalent to an attacker just giving multiple packages, there is no additional DoS concern either.\n\nMaybe that generalization is actually what we want already.\n\n### Resulting proposal\n\nTo be explicit, here is what that would amount to for a received package (set of transactions) `PKG`:\n\n* 1. **Deduplication**: remove from `PKG` any transaction that's already in the receiver's mempool.\n* 2. **Pre-linearization**: linearize (what remains of) `PKG` (so *without* in-mempool dependencies).\n* 3. **Splitting**: For each chunk `CNK` in that linearization (in order of decreasing feerate):\n  * 4. **Limiting**: If `feerate(CNK) < max(mempoolminfee, incremental_relay_feerate)`, stop processing (of this and all further chunks). This is necessary to avoid tiny-increment replacements at the bottom of the mempool, and can cheaply be done early on. This only works because any low-feerate suffix of the linearization will, if accepted to the mempool, become a low-feerate set there too (and possibly even lower, if it's merged with other things). Thus, this lets us efficiently predict and prevent additions to the mempool that would be below its minimum feerate. This aspect does not work pre-clustermempool.\n  * 5. **Conflict-finding**: find the set `CON`, the in-mempool conflicts with `CNK`.\n  * 6. **Replacement checks**: Only necessary if `CON` is non-empty:\n    * 7. **Relay check**: If `fee(CNK) < fee(CON) + incremental_relay_feerate * size(CNK)`, then the replacement does not pay for relay of the chunk. If so, stop processing this chunk and continue with further ones (which may fail due to having dependencies in this failed chunk).\n    * 8. **Tail check**: if `fee(CNK) < fee(CON) + tail_feerate * (size(CNK) - size(CON))`, the replacement worsens the bottom of the mempool, so continue with the next chunk. This check is only necessary if `tail_feerate > incremental_relay_feerate`.\n    * 9. **Gather OLD**: the union of all in-mempool clusters that contain elements of `CON`, or contain ancestors of `CNK`.\n    * 10. **Compute NEW**: `NEW = OLD - CON + CNK`.\n    * 11. **Linearization**: linearize all clusters in `NEW` (note that there can be multiple; a replacement can split up clusters).\n    * 12. **Diagram check**: verify that the fee-size diagram of `NEW` is nowhere worse than that of `OLD`, and at least in some place better. If not, the replacement is not necessarily an improvement to the mempool, and continue with the next chunk.\n  * 13. **Verification**: verify all transactions in `CNK` under standard/policy rules (including script verification). If this fails, continue with the next chunk. Otherwise, the chunk is a valid and desirable addition/replacement to the mempool.\n  * 14. **Eviction** Drop all of `CON` from the mempool (if any).\n  * 15. **Addition** Add all of `CNK` to the mempool, performing consensus validation to prime execution/script caches, and have a last-resort check that consensus validity is implied by policy validity.\n  * 16. **Interruption** If needed, interrupt processing to allow other peers' messages \n\n### Good enough?\n\nThe result of this whole thing is that it does result in a limited \"find better subset of new package to accept\" over only considering all/nothing of package, but this seems more of a side-effect of trying to make sure things don't gratuitously break when the receiver's mempool differs, than being a goal on itself.\n\nAnother observation is that this does *not* permit earlier chunks' replacements to pay for the relay of later chunks (every chunk needs to pay for itself), but it *does* permit replacements within one chunk to pay for the later transactions in the same chunk. Consider this example (`sats/bytes` notation, `mempoolminfee=1 sat/byte`):\n\n```mermaid height=169,auto\ngraph BT \n   B[\"Tx B: 500/100\"] --> A[\"Tx A: 3000/1000\"];\n   B x--x |conflict| Bp[\"Tx B': 1000/500\"];\n```\n\nIf only `B'` is in the mempool already, then the package `A,B` will be accepted by the above rules, because 'A' helps pay the fee for the relay of `B'`. If however `A,B'` were in the mempool already, then `B` would not be accepted as the net fee would be negative (and thus certainly not enough to pay for the relay of `B`).\n\nBecause `B` is \"appropriating\" the fee from `A` to pay for the relay of `B'`, the replacement breaks if the receiver already has `A`. In principle, that means an attacker that sees `A,B` could choose to only pass on `A` to a victim, resulting in `B` becoming (semi-permanently) unacceptable to the victim. This may be undesirable to the author of `B`, but nothing can be done about this without fundamentally different anti-DoS rules. It's only possible to be more restrictive and not permit the replacement at all (e.g. by trying to split chunks up into even smaller pieces if they're below `mempoolminfee`). Instead, I believe the observation is just that appropriation of parent fees cannot be guaranteed to work, as it depends on how nodes see the transactions packaged up, so users should be advised to avoid it (and it's rather strange anyway, perhaps there aren't really use cases for it regardless).\n\nAnd I think that's also a justification why it is acceptable that this *wouldn't* work across chunks: since appropriation cannot cannot be relied on for the same reason (receiver may have higher chunk already), we don't need to spend effort on making appropriation work well (but if it's easier to permit it, like within-chunk, that's also not a problem).\n\n~~I'm not sure it is also acceptable that it doesn't work across chunks in the other direction. It seems reasonable that we'd want to permit child fees to pay for evictions necessary for their parents. If so, if the **Relay check** (7) fails, instead of stopping of processing, perhaps the loop can continue, but with the combination of all unprocessed chunks so far as `CNK`? That actually starts to sound a lot like the approach from PR26711, except gathering until DoS checks are satisfied, rather than gathering until feerate checks are satisfied.~~ EDIT: this is likely not necessary, and leads to complex interactions between feerate and fee checks.\n\nIn a way, this design is pretty much taking what we're allowing today (submitting a transaction one by one), but now also permit grouping transactions together as little as possible while retaining the newly desired functionality: that higher-feerate children can be grouped with their parents at processing time.",
  "actions_summary": [
    {
      "id": 2,
      "count": 2
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 96,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Successor to <a href=\"https://delvingbitcoin.org/t/post-clustermempool-package-rbf/173\" class=\"inline-onebox\">[DEFUNCT] Post-clustermempool Package RBF</a>. I felt starting over in a new topic is a bit cleaner. \n<a name=\"starting-from-a-minimal-design-1\" class=\"anchor\" href=\"#starting-from-a-minimal-design-1\"></a>Starting from a minimal design\nAs a thought experiment, start with a minimal design: the relayed package must be a single chunk (when not considering in-mempool ancestors) after linearizati&hellip;",
  "truncated": true,
  "post_url": "/t/post-clustermempool-package-rbf-per-chunk-processing/190/1",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 2
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 2,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null,
  "can_vote": false
}