{
  "id": 359,
  "name": "Pieter Wuille",
  "username": "sipa",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/1100_2.png",
  "created_at": "2023-11-09T01:19:54.383Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"instagibbs\" data-post=\"2\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/instagibbs/48/28_2.png\" class=\"avatar\"> instagibbs:</div>\n<blockquote>\n<p>I think this links back to our conversation yesterday. If you have two same-unit-size txs, A and B, where A is 0-fee, B is 1 fee, and <code>mempoolminfee</code> is 1, then B would be accepted when submitted by itself, but rejected as a package <code>A+B</code>. In this scenario of course, we\u2019re only considering \u201cchunks\u201d since we\u2019re not connecting the package to the mempool clusters.</p>\n</blockquote>\n</aside>\n<p>I\u2019m not sure I understand the example. Do A and B depend on each other? Is one in the mempool already?</p>\n<aside class=\"quote no-group\" data-username=\"instagibbs\" data-post=\"2\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/instagibbs/48/28_2.png\" class=\"avatar\"> instagibbs:</div>\n<blockquote>\n<p>I assume this is where scripts are being run as well?</p>\n</blockquote>\n</aside>\n<p>Indeed.</p>\n<aside class=\"quote no-group\" data-username=\"instagibbs\" data-post=\"2\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/instagibbs/48/28_2.png\" class=\"avatar\"> instagibbs:</div>\n<blockquote>\n<p>What kind of failures are possible here if any?</p>\n</blockquote>\n</aside>\n<p>None, if all goes well. The consensus checks are there for (a) priming the script/validation cache and (b) being absolutely sure that no cases exist where standardness checks permit something that consensus does not.</p>\n<aside class=\"quote no-group\" data-username=\"instagibbs\" data-post=\"2\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/instagibbs/48/28_2.png\" class=\"avatar\"> instagibbs:</div>\n<blockquote>\n<p>I assume <code>TimeToSize</code> is another step we want, after 12.</p>\n</blockquote>\n</aside>\n<p>Indeed.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"3\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/3_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Anything done before script-validation isn\u2019t really DoS protection, it\u2019s just an optimisation?</p>\n</blockquote>\n</aside>\n<p>Do you mean doing this pre-eviction <em>here</em> (as opposed to later) is an optimization? If so, I may agree. But not removing (and not otherwise outlawing) sub-<code>mempoolminfee</code> stuff in packages would constitute a DoS risk, I believe (free relay by continuously replacing the bottom tx in the mempool at <span class=\"math\">\\epsilon</span> feerate increments). This gets stopped by increasing <code>mempoolminfee</code> <em>above</em> the evicted transactions\u2019 feerate when eviction happens, so that anything new accepted into it is (for the time being) strictly higher feerate.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"3\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/3_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>\u201cAt this point the package is <em>desirable</em>\u201d perhaps? We\u2019ve established it\u2019s got a nice feerate, etc, but not done the consensus checks from 12, so it may actually be garbage.</p>\n</blockquote>\n</aside>\n<p>Unless our code is broken, standardness checks (done in (10)) are strictly more restrictive than the consensus checks in (12). These last ones are just for priming the validation cache and a last-ditch protection against bugs in standardness validation that could make it less restrictive than consensus.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"3\" data-topic=\"173\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/3_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Maybe you can do ancestor-first package acceptance via chunking? Once you linearise <code>NEW</code> go through the chunks with new txs in order, and add just those txs to the mempool; updating <code>OLD</code>, <code>NEW</code> and <code>CON</code> as you go? If you get a chunk that\u2019s not worth adding to the mempool (or that fails validation), abort completely.</p>\n</blockquote>\n</aside>\n<p>There are many things that <em>can</em> be done to find a better combination of <code>OLD</code> and <code>NEW</code> things than exactly the package as relayed indicates. They include:</p>\n<ul>\n<li>Running an <span class=\"math\">O(n^2)</span> chunk merging algorithm on the old and new linearization.</li>\n<li>Running an actual conflict-aware <span class=\"math\">O(2^n)</span> linearization algorithm that finds the best (or approximation thereof) feerate subset in the combination.</li>\n<li>Requiring the peer to give us their full cluster linearization, which we could just accept if it looks good.</li>\n<li>\u2026</li>\n</ul>\n<p>But all of these are either incomplete, high-bandwidth, or computationally infeasible for all but the smallest cases. We could do relatively cheap improvements, but they will still permit \u201cundesirable\u201d more complex situations like this. Or we can restrict cluster/replacement sizes so much that we can always find the optimal combination.</p>\n<p>However, I\u2019d rather not get into a discussion of what approaches to consider without knowing what <em>good enough</em> is. Are there attacks possible without any improvements over the package relayed as-is? Note that if the peer is malicious, it\u2019s ok to do something suboptimal as long as it doesn\u2019t prevent us from accepting the \u201cright\u201d solution later from an honest peer. And if it\u2019s good enough, maybe we don\u2019t need to bother with patching up simple and obvious suboptimalities. And if it\u2019s not good enough, then patching only the simple cases likely still leaves other cases that are still not enough.</p>",
  "post_number": 4,
  "post_type": 1,
  "posts_count": 11,
  "updated_at": "2023-11-09T01:33:55.618Z",
  "reply_count": 3,
  "reply_to_post_number": null,
  "quote_count": 2,
  "incoming_link_count": 0,
  "reads": 12,
  "readers_count": 11,
  "score": 17.4,
  "yours": false,
  "topic_id": 173,
  "topic_slug": "defunct-post-clustermempool-package-rbf",
  "topic_title": "[DEFUNCT] Post-clustermempool Package RBF",
  "topic_html_title": "[DEFUNCT] Post-clustermempool Package RBF",
  "category_id": 8,
  "display_username": "Pieter Wuille",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"instagibbs, post:2, topic:173\"]\nI think this links back to our conversation yesterday. If you have two same-unit-size txs, A and B, where A is 0-fee, B is 1 fee, and `mempoolminfee` is 1, then B would be accepted when submitted by itself, but rejected as a package `A+B`. In this scenario of course, we\u2019re only considering \u201cchunks\u201d since we\u2019re not connecting the package to the mempool clusters.\n[/quote]\n\nI'm not sure I understand the example. Do A and B depend on each other? Is one in the mempool already? \n\n[quote=\"instagibbs, post:2, topic:173\"]\nI assume this is where scripts are being run as well?\n[/quote]\n\nIndeed.\n\n[quote=\"instagibbs, post:2, topic:173\"]\nWhat kind of failures are possible here if any?\n[/quote]\n\nNone, if all goes well. The consensus checks are there for (a) priming the script/validation cache and (b) being absolutely sure that no cases exist where standardness checks permit something that consensus does not.\n\n[quote=\"instagibbs, post:2, topic:173\"]\nI assume `TimeToSize` is another step we want, after 12.\n[/quote]\n\nIndeed.\n\n[quote=\"ajtowns, post:3, topic:173\"]\nAnything done before script-validation isn\u2019t really DoS protection, it\u2019s just an optimisation?\n[/quote]\n\nDo you mean doing this pre-eviction *here* (as opposed to later) is an optimization? If so, I may agree. But not removing (and not otherwise outlawing) sub-`mempoolminfee` stuff in packages would constitute a DoS risk, I believe (free relay by continuously replacing the bottom tx in the mempool at $\\epsilon$ feerate increments). This gets stopped by increasing `mempoolminfee` *above* the evicted transactions' feerate when eviction happens, so that anything new accepted into it is (for the time being) strictly higher feerate.\n\n[quote=\"ajtowns, post:3, topic:173\"]\n\u201cAt this point the package is *desirable*\u201d perhaps? We\u2019ve established it\u2019s got a nice feerate, etc, but not done the consensus checks from 12, so it may actually be garbage.\n[/quote]\n\nUnless our code is broken, standardness checks (done in (10)) are strictly more restrictive than the consensus checks in (12). These last ones are just for priming the validation cache and a last-ditch protection against bugs in standardness validation that could make it less restrictive than consensus.\n\n[quote=\"ajtowns, post:3, topic:173\"]\nMaybe you can do ancestor-first package acceptance via chunking? Once you linearise `NEW` go through the chunks with new txs in order, and add just those txs to the mempool; updating `OLD`, `NEW` and `CON` as you go? If you get a chunk that\u2019s not worth adding to the mempool (or that fails validation), abort completely.\n[/quote]\n\nThere are many things that *can* be done to find a better combination of `OLD` and `NEW` things than exactly the package as relayed indicates. They include:\n* Running an $O(n^2)$ chunk merging algorithm on the old and new linearization.\n* Running an actual conflict-aware $O(2^n)$ linearization algorithm that finds the best (or approximation thereof) feerate subset in the combination.\n* Requiring the peer to give us their full cluster linearization, which we could just accept if it looks good.\n* ...\n\nBut all of these are either incomplete, high-bandwidth, or computationally infeasible for all but the smallest cases. We could do relatively cheap improvements, but they will still permit \"undesirable\" more complex situations like this. Or we can restrict cluster/replacement sizes so much that we can always find the optimal combination.\n\nHowever, I'd rather not get into a discussion of what approaches to consider without knowing what *good enough* is. Are there attacks possible without any improvements over the package relayed as-is? Note that if the peer is malicious, it's ok to do something suboptimal as long as it doesn't prevent us from accepting the \"right\" solution later from an honest peer. And if it's good enough, maybe we don't need to bother with patching up simple and obvious suboptimalities. And if it's not good enough, then patching only the simple cases likely still leaves other cases that are still not enough.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 96,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "I\u2019m not sure I understand the example. Do A and B depend on each other? Is one in the mempool already? \n\nIndeed. \n\nNone, if all goes well. The consensus checks are there for (a) priming the script/validation cache and (b) being absolutely sure that no cases exist where standardness checks permit so&hellip;",
  "truncated": true,
  "post_url": "/t/defunct-post-clustermempool-package-rbf/173/4",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}