{
  "id": 489,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2023-11-26T16:22:09.295Z",
  "cooked": "<p>I think all these steps rely really heavily on how they\u2019re setup via the prefix intersection algorithm \u2013 eg, <span class=\"math\">c_{j+1}</span> is a chunk in <span class=\"math\">\\gamma_j + c_{j+1}</span>, because <span class=\"math\">\\gamma_j = c_1 + c_2 + .. + c_j</span> and <span class=\"math\">c_1, c_2, .., c_n</span> is a correct chunking, and then the fact that you generate a chunking by merging tx sets in any order means that if you add stuff on the end of that, you can start off with that chunking, and then you\u2019ll only potentially be merging those chunks from the tail, you\u2019ll never need to split them up.</p>\n<p>I\u2019m starting to have a bit of luck formalising this in lean4, fwiw, but it\u2019s slow progress : I can convert a list of txs into a chunking, and compare fee rate graphs (evaluating the diagram at each integer byte/weight with a total fee in <span class=\"math\">\\mathbb Q</span>), but currently don\u2019t have any theorems about any of that.</p>\n<p>(If you have a better way of defining a diagram than as a function from <span class=\"math\">\\mathbb N \\to \\mathbb Q</span> that\u2019d be great. I started off trying to do line segments from <span class=\"math\">(s_1,f_1) \\to (s_2,f_2)</span> but that got super painful super fast)</p>",
  "post_number": 18,
  "post_type": 1,
  "posts_count": 46,
  "updated_at": "2023-11-26T16:24:32.871Z",
  "reply_count": 1,
  "reply_to_post_number": 17,
  "quote_count": 0,
  "incoming_link_count": 1,
  "reads": 38,
  "readers_count": 37,
  "score": 17.6,
  "yours": false,
  "topic_id": 209,
  "topic_slug": "merging-incomparable-linearizations",
  "topic_title": "Merging incomparable linearizations",
  "topic_html_title": "Merging incomparable linearizations",
  "category_id": 8,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "reply_to_user": {
    "id": 96,
    "username": "sipa",
    "name": "Pieter Wuille",
    "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/1100_2.png"
  },
  "bookmarked": false,
  "raw": "I think all these steps rely really heavily on how they're setup via the prefix intersection algorithm -- eg, $c_{j+1}$ is a chunk in $\\gamma_j + c_{j+1}$, because $\\gamma_j = c_1 + c_2 + .. + c_j$ and $c_1, c_2, .., c_n$ is a correct chunking, and then the fact that you generate a chunking by merging tx sets in any order means that if you add stuff on the end of that, you can start off with that chunking, and then you'll only potentially be merging those chunks from the tail, you'll never need to split them up.\n\nI'm starting to have a bit of luck formalising this in lean4, fwiw, but it's slow progress : I can convert a list of txs into a chunking, and compare fee rate graphs (evaluating the diagram at each integer byte/weight with a total fee in $\\mathbb Q$), but currently don't have any theorems about any of that.\n\n(If you have a better way of defining a diagram than as a function from $\\mathbb N \\to \\mathbb Q$ that'd be great. I started off trying to do line segments from $(s_1,f_1) \\to (s_2,f_2)$ but that got super painful super fast)",
  "actions_summary": [],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "I think all these steps rely really heavily on how they\u2019re setup via the prefix intersection algorithm \u2013 eg, c_{j+1} is a chunk in \\gamma_j + c_{j+1}, because \\gamma_j = c_1 + c_2 + .. + c_j and c_1, c_2, .., c_n is a correct chunking, and then the fact that you generate a chunking by merging tx set&hellip;",
  "truncated": true,
  "post_url": "/t/merging-incomparable-linearizations/209/18",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}