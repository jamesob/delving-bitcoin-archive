{
  "id": 505,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2023-11-28T08:12:11.857Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"209\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/1100_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>The highest chunk feerate of the bad transactions, again retaining the order of <span class=\"math\">L</span>, does not exceed <span class=\"math\">f</span>.</p>\n</blockquote>\n</aside>\n<p>I don\u2019t like that assumption; you can only check it after you\u2019ve done all the work, rather than beforehand, and it conceivably could turn out to be false. I think a better assumption would be \u201cThe first chunk of <span class=\"math\">L</span> has a feerate <span class=\"math\">f_0</span> which does not exceed <span class=\"math\">f</span>\u201d</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"209\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/1100_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>there must be some topologically valid subset</p>\n</blockquote>\n</aside>\n<p>I think by \u201ctopologically valid\u201d you\u2019re meaning that no parents follow their child, <strong>and</strong> that all parents are included; ie if you have <span class=\"math\">c</span> spends <span class=\"math\">p</span> spends <span class=\"math\">gp</span>, then <span class=\"math\">[gp, p, c]</span> and <span class=\"math\">[gp, p]</span> are topologically valid, but <span class=\"math\">[p,c]</span> is not. This lets you say that if <span class=\"math\">b</span> is topologically valid, then for any <span class=\"math\">a,x</span>, if <span class=\"math\">a + b</span> is topologically valid, then <span class=\"math\">b + a</span> is also topologically valid. You also have <span class=\"math\">a + b</span> being t.v implies <span class=\"math\">a</span> is t.v, and that gives you <span class=\"math\">b_1 + b_2 + .. + b_n</span> being t.v and <span class=\"math\">a_0 + b_1 + .. + b_n + a_n</span> being t.v gives <span class=\"math\">b_1 + .. + b_n + a_0 + .. + a_n</span> being t.v.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"209\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/1100_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>Modify the linearization by reordering the <span class=\"math\">c_t</span> transactions such that all of <span class=\"math\">c_t \\cap T</span> are at the start of <span class=\"math\">c_t</span>.</p>\n</blockquote>\n</aside>\n<p>For the intermediate steps, you\u2019re not moving txs all the way to the front, though, so I think you want something slightly cleverer still; perhaps <span class=\"math\">a + b + c</span> and <span class=\"math\">a + c</span> being t.v gives <span class=\"math\">a + c + b</span> being t.v is enough.</p>\n<p>I think you could rewrite this slightly:</p>\n<ul>\n<li>Chunk to <span class=\"math\">(c_0, .., c_n)</span> normally, pick <span class=\"math\">t</span>.</li>\n<li>Note that fee rate of <span class=\"math\">c_0 \\le f</span> (is it?) and the feerate of <span class=\"math\">c_i \\ge c_{i+1}</span> as a property of chunking.</li>\n<li>Construct <span class=\"math\">c^\\prime_t</span> by reordering <span class=\"math\">c_t</span> to ensure the good txs are at the start.</li>\n<li>If <span class=\"math\">c_{t-1}</span> has feerate less than <span class=\"math\">f</span> or <span class=\"math\">c_t \\cap T \\ne T</span> then the good txs at that start of <span class=\"math\">c^\\prime_t</span> will have higher feerate than <span class=\"math\">c_{t-1}</span> (because every tail of <span class=\"math\">T</span> has higher feerate than <span class=\"math\">f</span>) and the final good txs will appear in chunk <span class=\"math\">t-1</span> or lower on the next round.</li>\n<li>Otherwise, the good txs at the start of <span class=\"math\">c^\\prime_t</span> are precisely <span class=\"math\">T</span>, those txs and each of <span class=\"math\">c_0, .., c_{t-1}</span> have feerate <span class=\"math\">f</span> (as <span class=\"math\">c_0</span>'s feerate is <span class=\"math\">f_0 \\le f</span> by assumption, and by feerate <span class=\"math\">c_i \\ge c_{i+1}</span> due to the chunking algorithm, and <span class=\"math\">T</span> has feerate <span class=\"math\">f</span> by definition). But in that case reordering to be <span class=\"math\">T, c_0, .., c_{t-1}</span> doesn\u2019t change the diagram, because all the reordered chunks have precisely the same feerate.</li>\n</ul>\n<p>Note that your good txs will never get split up once you\u2019ve moved them, so <span class=\"math\">c_0</span> will have the same composition and feerate it had originally until <span class=\"math\">t=0</span> and <span class=\"math\">c_0 \\cap T = T</span>, and merging some subset of the good txs into <span class=\"math\">c_{t-1}</span> will mean all of them are merged.</p>\n<p>Also, I think your theorem needs a tweak: if you have equal size txs with feerates <span class=\"math\">a=0,b=6,c=9,d=0,e=5</span>, and start with <span class=\"math\">L=[a,b,c,d,e]</span> and <span class=\"math\">T=[a,e]</span>, then your original chunks were <span class=\"math\">[a,b,c], [d,e]</span> with both those chunks and <span class=\"math\">T</span> having a feerate of 5. But your new linearisation of <span class=\"math\">[a,e,b,c,d]</span> chunks to <span class=\"math\">[a,e,b,c] [d]</span> with feerates 6.25 and 0. Which is fine, it\u2019s just that <span class=\"math\">T</span> doesn\u2019t actually become the first chunk, since we end up finding a chunk with feerate greater than <span class=\"math\">f</span> instead.</p>",
  "post_number": 25,
  "post_type": 1,
  "posts_count": 46,
  "updated_at": "2023-11-28T08:12:11.857Z",
  "reply_count": 1,
  "reply_to_post_number": 24,
  "quote_count": 1,
  "incoming_link_count": 0,
  "reads": 30,
  "readers_count": 29,
  "score": 11.0,
  "yours": false,
  "topic_id": 209,
  "topic_slug": "merging-incomparable-linearizations",
  "topic_title": "Merging incomparable linearizations",
  "topic_html_title": "Merging incomparable linearizations",
  "category_id": 8,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"sipa, post:24, topic:209\"]\nThe highest chunk feerate of the bad transactions, again retaining the order of $L$, does not exceed $f$.\n[/quote]\n\nI don't like that assumption; you can only check it after you've done all the work, rather than beforehand, and it conceivably could turn out to be false. I think a better assumption would be \"The first chunk of $L$ has a feerate $f_0$ which does not exceed $f$\"\n\n[quote=\"sipa, post:24, topic:209\"]\nthere must be some topologically valid subset\n[/quote]\n\nI think by \"topologically valid\" you're meaning that no parents follow their child, **and** that all parents are included; ie if you have $c$ spends $p$ spends $gp$, then $[gp, p, c]$ and $[gp, p]$ are topologically valid, but $[p,c]$ is not. This lets you say that if $b$ is topologically valid, then for any $a,x$, if $a + b$ is topologically valid, then $b + a$ is also topologically valid. You also have $a + b$ being t.v implies $a$ is t.v, and that gives you $b_1 + b_2 + .. + b_n$ being t.v and $a_0 + b_1 + .. + b_n + a_n$ being t.v gives $b_1 + .. + b_n + a_0 + .. + a_n$ being t.v. \n\n[quote=\"sipa, post:24, topic:209\"]\nModify the linearization by reordering the $c_t$ transactions such that all of $c_t \\cap T$ are at the start of $c_t$.\n[/quote]\n\nFor the intermediate steps, you're not moving txs all the way to the front, though, so I think you want something slightly cleverer still; perhaps $a + b + c$ and $a + c$ being t.v gives $a + c + b$ being t.v is enough.\n\nI think you could rewrite this slightly:\n\n * Chunk to $(c_0, .., c_n)$ normally, pick $t$.\n * Note that fee rate of $c_0 \\le f$ (is it?) and the feerate of $c_i \\ge c_{i+1}$ as a property of chunking.\n * Construct $c^\\prime_t$ by reordering $c_t$ to ensure the good txs are at the start.\n * If $c_{t-1}$ has feerate less than $f$ or $c_t \\cap T \\ne T$ then the good txs at that start of $c^\\prime_t$ will have higher feerate than $c_{t-1}$ (because every tail of $T$ has higher feerate than $f$) and the final good txs will appear in chunk $t-1$ or lower on the next round.\n * Otherwise, the good txs at the start of $c^\\prime_t$ are precisely $T$, those txs and each of $c_0, .., c_{t-1}$ have feerate $f$ (as $c_0$'s feerate is $f_0 \\le f$ by assumption, and by feerate $c_i \\ge c_{i+1}$ due to the chunking algorithm, and $T$ has feerate $f$ by definition). But in that case reordering to be $T, c_0, .., c_{t-1}$ doesn't change the diagram, because all the reordered chunks have precisely the same feerate.\n\nNote that your good txs will never get split up once you've moved them, so $c_0$ will have the same composition and feerate it had originally until $t=0$ and $c_0 \\cap T = T$, and merging some subset of the good txs into $c_{t-1}$ will mean all of them are merged.\n\nAlso, I think your theorem needs a tweak: if you have equal size txs with feerates $a=0,b=6,c=9,d=0,e=5$, and start with $L=[a,b,c,d,e]$ and $T=[a,e]$, then your original chunks were $[a,b,c], [d,e]$ with both those chunks and $T$ having a feerate of 5. But your new linearisation of $[a,e,b,c,d]$ chunks to $[a,e,b,c] [d]$ with feerates 6.25 and 0. Which is fine, it's just that $T$ doesn't actually become the first chunk, since we end up finding a chunk with feerate greater than $f$ instead.",
  "actions_summary": [],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "I don\u2019t like that assumption; you can only check it after you\u2019ve done all the work, rather than beforehand, and it conceivably could turn out to be false. I think a better assumption would be \u201cThe first chunk of L has a feerate f_0 which does not exceed f\u201d \n\nI think by \u201ctopologically valid\u201d you\u2019re &hellip;",
  "truncated": true,
  "post_url": "/t/merging-incomparable-linearizations/209/25",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}