{
  "id": 419,
  "name": "Gregory Sanders",
  "username": "instagibbs",
  "avatar_template": "/user_avatar/delvingbitcoin.org/instagibbs/{size}/28_2.png",
  "created_at": "2023-11-15T18:52:01.084Z",
  "cooked": "<p>this all seems reasonable, though I\u2019m getting flashbacks to 26711 <img src=\"https://delvingbitcoin.org/images/emoji/twitter/smiling_face_with_tear.png?v=12\" title=\":smiling_face_with_tear:\" class=\"emoji\" alt=\":smiling_face_with_tear:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<aside class=\"quote no-group\" data-username=\"sdaftuar\" data-post=\"5\" data-topic=\"190\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/s/0ea827/48.png\" class=\"avatar\"> sdaftuar:</div>\n<blockquote>\n<p>So my overall view on this is that we should just restrict our validation logic to operating on single chunks</p>\n</blockquote>\n</aside>\n<p>I think this also goes back to what I think you phrased something like \u201cwe pick our most incentive compatible thing, then do DoS checks to accept/reject\u201d. The alternative strategy strikes me as the other direction, where we search for something DoS-compatible, then pick the most incentive compatible of that.</p>\n<p>Like 26711, this proposed per-chunk evaluation would allow easier \u201ccatch-up\u201d even if the relayed package was somehow too large for the cluster itself.</p>\n<p>For a first-cut we could limit ourselves to a single RBF attempt per package, catching more RBFs could be punted for future work if diagram check is expensive.</p>\n<aside class=\"quote no-group quote-modified\" data-username=\"sipa\" data-post=\"1\" data-topic=\"190\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/1100_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p><strong>Verification</strong>: verify all transactions in <code>PKG</code> under standard/policy rules (including script verification). If this fails, continue with the next chunk. Otherwise, the chunk is a valid and desirable addition/replacement to the mempool.</p>\n</blockquote>\n</aside>\n<p>If we get some \u201cmalicious\u201d failure like signature failure I think it makes sense to drop the rest of the package potentially. ala 26711.</p>",
  "post_number": 6,
  "post_type": 1,
  "posts_count": 16,
  "updated_at": "2023-11-15T18:54:49.092Z",
  "reply_count": 2,
  "reply_to_post_number": null,
  "quote_count": 2,
  "incoming_link_count": 3,
  "reads": 30,
  "readers_count": 29,
  "score": 60.8,
  "yours": false,
  "topic_id": 190,
  "topic_slug": "post-clustermempool-package-rbf-per-chunk-processing",
  "topic_title": "Post-clustermempool package RBF: per-chunk processing",
  "topic_html_title": "Post-clustermempool package RBF: per-chunk processing",
  "category_id": 8,
  "display_username": "Gregory Sanders",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "this all seems reasonable, though I'm getting flashbacks to 26711 :smiling_face_with_tear:\n\n[quote=\"sdaftuar, post:5, topic:190\"]\nSo my overall view on this is that we should just restrict our validation logic to operating on single chunks\n[/quote]\n\nI think this also goes back to what I think you phrased something like \"we pick our most incentive compatible thing, then do DoS checks to accept/reject\". The alternative strategy strikes me as the other direction, where we search for something DoS-compatible, then pick the most incentive compatible of that.\n\nLike 26711, this proposed per-chunk evaluation would allow easier \"catch-up\" even if the relayed package was somehow too large for the cluster itself.\n\nFor a first-cut we could limit ourselves to a single RBF attempt per package, catching more RBFs could be punted for future work if diagram check is expensive.\n\n[quote=\"sipa, post:1, topic:190\"]\n**Verification**: verify all transactions in `PKG` under standard/policy rules (including script verification). If this fails, continue with the next chunk. Otherwise, the chunk is a valid and desirable addition/replacement to the mempool.\n[/quote]\nIf we get some \"malicious\" failure like signature failure I think it makes sense to drop the rest of the package potentially. ala 26711.",
  "actions_summary": [
    {
      "id": 2,
      "count": 2
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 31,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "this all seems reasonable, though I\u2019m getting flashbacks to 26711 :smiling_face_with_tear: \n\nI think this also goes back to what I think you phrased something like \u201cwe pick our most incentive compatible thing, then do DoS checks to accept/reject\u201d. The alternative strategy strikes me as the other dir&hellip;",
  "truncated": true,
  "post_url": "/t/post-clustermempool-package-rbf-per-chunk-processing/190/6",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 2
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 2,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}