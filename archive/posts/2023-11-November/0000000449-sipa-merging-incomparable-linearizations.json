{
  "id": 449,
  "name": "Pieter Wuille",
  "username": "sipa",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/1100_2.png",
  "created_at": "2023-11-19T04:12:15.113Z",
  "cooked": "<h1><a name=\"introduction-1\" class=\"anchor\" href=\"#introduction-1\"></a>Introduction</h1>\n<p>While we have several ways for computing good linearizations for a cluster from scratch, sometimes we don\u2019t start from scratch. We may have our own linearization already, but receive (through so far unspecified means) another linearization from a peer. If it\u2019s strictly better, we could just switch to it. But what if our linearization is better in some places, and theirs is better in other places? Can we somehow combine the \u201csmarts\u201d that they\u2019re based on, to construct an even better linearization?</p>\n<p>As a reminder, we compare linearizations by computing all cumulative (size, fee) points after every chunk, and connecting them by straight lines. Each linearization has such a segmented line, which we call the fee-size diagram. If a linearization A has a diagram that is nowhere below that of linearization B, and at least in some places above it, we say A is strictly better than B. If the diagrams coincide everywhere, they\u2019re equal. If one diagram is on top in some place(s) and the other is on top in others, we call them incomparable.</p>\n<p>Due to the (<s>so far unproven, but accepted</s> EDIT: now proven, thanks to this thread) property that every cluster has a well-defined non-empty set of optimal linearizations (which are all equal to each other, and all strictly better than all other linearizations), it must be the case that if two incomparable linearizations exist, there <em>must</em> exist at least one linearization that\u2019s strictly better than both. This topic is about finding such combined linearizations.</p>\n<h1><a name=\"algorithms-2\" class=\"anchor\" href=\"#algorithms-2\"></a>Algorithms</h1>\n<h2><a name=\"best-chunk-merging-3\" class=\"anchor\" href=\"#best-chunk-merging-3\"></a>Best-chunk merging</h2>\n<p>We\u2019ve known a simple merging algorithm for a while:</p>\n<ul>\n<li>Given two linearizations <em>L<sub>1</sub></em> and <em>L<sub>2</sub></em>:\n<ul>\n<li>While not all transactions have been processed:\n<ul>\n<li>Find highest-feerate prefix <em>P<sub>1</sub></em> among all unprocessed transactions in <em>L<sub>1</sub></em>.</li>\n<li>Find highest-feerate prefix <em>P<sub>2</sub></em> among all unprocessed transactions in <em>L<sub>2</sub></em>.</li>\n<li>Include the transactions from the higher-feerate of <em>P<sub>1</sub></em> and <em>P<sub>2</sub></em> in output linearization.</li>\n<li>Mark the included transactions as processed</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>This algorithm can have <span class=\"math\">\\mathcal{O}(n^2)</span> runtime in the number of transactions, because there can be <em>n</em> iterations, and each can require <span class=\"math\">\\mathcal{O}(n)</span> work to find the highest-feerate prefix. In <span class=\"math\">\\mathcal{O}(n)</span> time we can of course also compute the full chunking of <em>L<sub>1</sub></em> and <em>L<sub>2</sub></em> (rather than just the first chunk), and it may be possible to reuse part of that computation across iterations; that may enable a lower complexity, but it seems nontrivial. And given the fact that in every case we\u2019ll probably want to run at least an ancestor-set based linearization from scratch ourselves (which is also <span class=\"math\">\\mathcal{O}(n^2)</span>), it\u2019s probably fine to target the same complexity for a merging algorithm.</p>\n<p>Sadly, this algorithm doesn\u2019t always produce an output that\u2019s better or equal than both inputs. It will produce a linearization whose diagram is at no point below the <em>lowest</em> of the two input diagrams, but that\u2019s not a particularly high bar. We could instead just stick with either one of the inputs instead to achieve that level of quality. In typical cases it\u2019ll be better of course, but there are no guarantees. And it is easy to find examples where the result is just one of the inputs, and thus still incomparable to the other one.</p>\n<p>See the example below (labels are <code>fee/size</code>):</p>\n<pre data-code-height=\"147\" data-code-wrap=\"mermaid\"><code class=\"lang-mermaid\">graph BT\n   T0[\"A: 1/3\"];\n   T1[\"B: 2/1\"];\n   T2[\"C: 2/1\"] --&gt; T0;\n   T3[\"D: 7/1\"] --&gt; T0;\n   T4[\"E: 6/1\"] --&gt; T0;\n   T4 --&gt; T1;\n   T5[\"F: 7/3\"] --&gt; T1;\n</code></pre>\n<ul>\n<li>The first input linearization is the ancestor set sort: [B,F,A,D,E,C], which is chunked as [BFADE,C].</li>\n<li>The second input is [B,A,E,C,D,F], which is chunked as [BAECD,F]. The BAECD chunk has higher feerate (18/7=2.571) than BFADE (23/9=2.556), but during the F part it is overtaken by BFADE.</li>\n<li>The result of merging is just the second input again.</li>\n<li>The optimal linearization would be [B,A,D,E,F,C], chunked as [BADE,F,C].</li>\n</ul>\n<p>What we observe is that there is actually a common subset (BADE) of the two initial chunks that can be moved to the front, but the merging algorithm does not consider this.</p>\n<h2><a name=\"intersection-merging-4\" class=\"anchor\" href=\"#intersection-merging-4\"></a>Intersection merging</h2>\n<p>In an attempt to address that, let\u2019s add a step to the merging algorithm to consider intersections:</p>\n<ul>\n<li>Given two linearizations <em>L<sub>1</sub></em> and <em>L<sub>2</sub></em>:\n<ul>\n<li>While not all transactions have been processed:\n<ul>\n<li>Find highest-feerate prefix <em>P<sub>1</sub></em> among all unprocessed transactions in <em>L<sub>1</sub></em>.</li>\n<li>Find highest-feerate prefix <em>P<sub>2</sub></em> among all unprocessed transactions in <em>L<sub>2</sub></em>.</li>\n<li>Let <em>P<sub>3</sub></em> be the intersection of <em>P<sub>1</sub></em> and <em>P<sub>2</sub></em>. This is necessarily topologically valid.</li>\n<li>Include the transactions from the highest-feerate of <em>P<sub>1</sub></em>, <em>P<sub>2</sub></em>, and <em>P<sub>3</sub></em> in output linearization.</li>\n<li>Mark the included transactions as processed</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>While it adds a step, the complexity is unchanged. Unfortunately, it still doesn\u2019t always result in a better linearization:</p>\n<pre data-code-height=\"234\" data-code-wrap=\"mermaid\"><code class=\"lang-mermaid\">graph BT\n   T0[\"D: 1\"] \n   T1[\"F: 11\"];\n   T2[\"G: 22\"];\n   T3[\"A: 1\"];\n   T4[\"E: 21\"];\n   T5[\"C: 20\"];\n   T6[\"B: 13\"];\n   T2 --&gt; T0;\n   T2 --&gt; T4;\n   T1 --&gt; T5 --&gt; T3;\n   T4 --&gt; T3;\n   T4 --&gt; T6;\n</code></pre>\n<ul>\n<li>The first input linearization is the ancestor set sort: [B,A,E,D,G,C,F], which is chunked as [B,AEDGC,F].</li>\n<li>The second input is [B,A,C,F,E,D,G], which is chunked as [BACFE,DG]. The BACFE chunk has higher feerate (66/5=13.5) than B (13) initially, but gets overtaken by the AEDGC chunk.</li>\n<li>The result of merging is equal to the second input.</li>\n<li>The optimal linearization would be [B,A,C,E,D,G,F], chunked as [BACE,DG,F].</li>\n</ul>\n<p>Again the crux is discovering an intersection (BACE), but this time between the BACFE chunk and not one but two chunks of the other input (B and AEDGC).</p>\n<h2><a name=\"prefix-intersection-merging-5\" class=\"anchor\" href=\"#prefix-intersection-merging-5\"></a>Prefix-intersection merging</h2>\n<p>The solution is to attempt more intersections. Observe that a linearization is really a way of constraining the search for subsets to just prefixes of the linearization. Given the intuition gained above that incomparabilities always seem to be due to a non-considered intersection between the two linearizations, it seems worthwhile try all intersections between prefixes of the first with prefixes of the second linearization. There can be a quadratic number of such intersections however, but maybe we can limit ourselves to just intersections that involve the best chunk of one of both linearizations at least:</p>\n<ul>\n<li>Given two linearizations <em>L<sub>1</sub></em> and <em>L<sub>2</sub></em>:\n<ul>\n<li>While not all transactions have been processed:\n<ul>\n<li>Find highest-feerate prefix <em>P<sub>1</sub></em> among all unprocessed transactions in <em>L<sub>1</sub></em>.</li>\n<li>Find highest-feerate prefix <em>P<sub>2</sub></em> among all unprocessed transactions in <em>L<sub>2</sub></em>.</li>\n<li>Find the highest-feerate set among all these:\n<ul>\n<li>Intersections between <em>P<sub>1</sub></em> and all prefixes of <em>L<sub>2</sub></em>.</li>\n<li>Intersections between <em>P<sub>2</sub></em> and all prefixes of <em>L<sub>1</sub></em>.</li>\n</ul>\n</li>\n<li>Include the transactions from that set in the output linearization.</li>\n<li>Mark the included transactions as processed</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>The various intersections between <em>P<sub>1</sub></em> and prefixes of <em>L<sub>2</sub></em> can be computed incrementally (keep adding transactions from <em>L<sub>2</sub></em> if they\u2019re in <em>P<sub>1</sub></em>, and remember the best one), and similarly for <em>P<sub>2</sub></em> with prefixes of <em>L<sub>1</sub></em>. This, like finding the <em>P<sub>i</sub></em> in the first place, can be done in <span class=\"math\">\\mathcal{O}(n)</span> time. The result is still an <span class=\"math\">\\mathcal{O}(n^2)</span> algorithm.</p>\n<p>Surprisingly, this algorithm seems powerful enough to always find a linearization that\u2019s strictly better than both inputs if they\u2019re incomparable (and at least as good as the best of the two if they are comparable). This works regardless of the quality of the input linearizations (e.g. they don\u2019t need to be ancestor sort or better), and does not require connected chunks (see <a href=\"https://delvingbitcoin.org/t/linearization-post-processing-o-n-2-fancy-chunking/201/6\">linearization post-processing</a>). No proof, though.</p>\n<h2><a name=\"update-simpler-and-proven-merging-6\" class=\"anchor\" href=\"#update-simpler-and-proven-merging-6\"></a>Update: simpler and proven merging</h2>\n<p>See the discussion further in this thread (thanks, <a class=\"mention\" href=\"/u/ajtowns\">@ajtowns</a>).</p>\n<p>It appears that it suffices to only consider the intersections between the higher-feerate out of <span class=\"math\">P_1</span> and <span class=\"math\">P_2</span>, with all prefixes of the linearization of the other input:</p>\n<ul>\n<li>Given two linearizations <span class=\"math\">L_1</span> and <span class=\"math\">L_2</span>:\n<ul>\n<li>While not all transactions have been processed:\n<ul>\n<li>Find highest-feerate prefix <em>P<sub>1</sub></em> among all unprocessed transactions in <em>L<sub>1</sub></em>.</li>\n<li>Find highest-feerate prefix <em>P<sub>2</sub></em> among all unprocessed transactions in <em>L<sub>2</sub></em>.</li>\n<li>If <span class=\"math\">P_1</span> has lower feerate than <span class=\"math\">P_2</span>, swap <span class=\"math\">P_1</span> with <span class=\"math\">P_2</span> and <span class=\"math\">L_1</span> with <span class=\"math\">L_2</span>.</li>\n<li>Find the highest-feerate set among all intersections between <span class=\"math\">P_1</span> and the prefixes of <span class=\"math\">L_1</span>.</li>\n<li>Include the transactions from that set in the output linearization.</li>\n<li>Mark the included transactions as processed</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Instead of describing the resulting set as an intersection, it can also be seen as the highest-feerate prefix of <span class=\"math\">P_2</span>, reordered according to the order these transactions have in <span class=\"math\">L_1</span>.</p>\n<p>A proof for this scheme can be found in <a href=\"https://delvingbitcoin.org/t/cluster-mempool-definitions-theory/202\">this thread</a>.</p>",
  "post_number": 1,
  "post_type": 1,
  "posts_count": 46,
  "updated_at": "2024-04-25T20:26:03.884Z",
  "reply_count": 2,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 58,
  "reads": 61,
  "readers_count": 60,
  "score": 327.2,
  "yours": false,
  "topic_id": 209,
  "topic_slug": "merging-incomparable-linearizations",
  "topic_title": "Merging incomparable linearizations",
  "topic_html_title": "Merging incomparable linearizations",
  "category_id": 8,
  "display_username": "Pieter Wuille",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 16,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "# Introduction\n\nWhile we have several ways for computing good linearizations for a cluster from scratch, sometimes we don't start from scratch. We may have our own linearization already, but receive (through so far unspecified means) another linearization from a peer. If it's strictly better, we could just switch to it. But what if our linearization is better in some places, and theirs is better in other places? Can we somehow combine the \"smarts\" that they're based on, to construct an even better linearization?\n\nAs a reminder, we compare linearizations by computing all cumulative (size, fee) points after every chunk, and connecting them by straight lines. Each linearization has such a segmented line, which we call the fee-size diagram. If a linearization A has a diagram that is nowhere below that of linearization B, and at least in some places above it, we say A is strictly better than B. If the diagrams coincide everywhere, they're equal. If one diagram is on top in some place(s) and the other is on top in others, we call them incomparable.\n\nDue to the (~~so far unproven, but accepted~~ EDIT: now proven, thanks to this thread) property that every cluster has a well-defined non-empty set of optimal linearizations (which are all equal to each other, and all strictly better than all other linearizations), it must be the case that if two incomparable linearizations exist, there *must* exist at least one linearization that's strictly better than both. This topic is about finding such combined linearizations.\n\n# Algorithms\n\n## Best-chunk merging\n\nWe've known a simple merging algorithm for a while:\n\n* Given two linearizations *L<sub>1</sub>* and *L<sub>2</sub>*:\n  * While not all transactions have been processed:\n    * Find highest-feerate prefix *P<sub>1</sub>* among all unprocessed transactions in *L<sub>1</sub>*.\n    * Find highest-feerate prefix *P<sub>2</sub>* among all unprocessed transactions in *L<sub>2</sub>*.\n    * Include the transactions from the higher-feerate of *P<sub>1</sub>* and *P<sub>2</sub>* in output linearization.\n    * Mark the included transactions as processed\n\nThis algorithm can have $\\mathcal{O}(n^2)$ runtime in the number of transactions, because there can be *n* iterations, and each can require $\\mathcal{O}(n)$ work to find the highest-feerate prefix. In $\\mathcal{O}(n)$ time we can of course also compute the full chunking of *L<sub>1</sub>* and *L<sub>2</sub>* (rather than just the first chunk), and it may be possible to reuse part of that computation across iterations; that may enable a lower complexity, but it seems nontrivial. And given the fact that in every case we'll probably want to run at least an ancestor-set based linearization from scratch ourselves (which is also $\\mathcal{O}(n^2)$), it's probably fine to target the same complexity for a merging algorithm.\n\nSadly, this algorithm doesn't always produce an output that's better or equal than both inputs. It will produce a linearization whose diagram is at no point below the *lowest* of the two input diagrams, but that's not a particularly high bar. We could instead just stick with either one of the inputs instead to achieve that level of quality. In typical cases it'll be better of course, but there are no guarantees. And it is easy to find examples where the result is just one of the inputs, and thus still incomparable to the other one.\n\nSee the example below (labels are `fee/size`):\n\n```mermaid height=147,auto\ngraph BT\n   T0[\"A: 1/3\"];\n   T1[\"B: 2/1\"];\n   T2[\"C: 2/1\"] --> T0;\n   T3[\"D: 7/1\"] --> T0;\n   T4[\"E: 6/1\"] --> T0;\n   T4 --> T1;\n   T5[\"F: 7/3\"] --> T1;\n```\n\n* The first input linearization is the ancestor set sort: [B,F,A,D,E,C], which is chunked as [BFADE,C].\n* The second input is [B,A,E,C,D,F], which is chunked as [BAECD,F]. The BAECD chunk has higher feerate (18/7=2.571) than BFADE (23/9=2.556), but during the F part it is overtaken by BFADE.\n* The result of merging is just the second input again.\n* The optimal linearization would be [B,A,D,E,F,C], chunked as [BADE,F,C].\n\nWhat we observe is that there is actually a common subset (BADE) of the two initial chunks that can be moved to the front, but the merging algorithm does not consider this.\n\n## Intersection merging\n\nIn an attempt to address that, let's add a step to the merging algorithm to consider intersections:\n\n* Given two linearizations *L<sub>1</sub>* and *L<sub>2</sub>*:\n  * While not all transactions have been processed:\n    * Find highest-feerate prefix *P<sub>1</sub>* among all unprocessed transactions in *L<sub>1</sub>*.\n    * Find highest-feerate prefix *P<sub>2</sub>* among all unprocessed transactions in *L<sub>2</sub>*.\n    * Let *P<sub>3</sub>* be the intersection of *P<sub>1</sub>* and *P<sub>2</sub>*. This is necessarily topologically valid.\n    * Include the transactions from the highest-feerate of *P<sub>1</sub>*, *P<sub>2</sub>*, and *P<sub>3</sub>* in output linearization.\n    * Mark the included transactions as processed\n\nWhile it adds a step, the complexity is unchanged. Unfortunately, it still doesn't always result in a better linearization:\n\n```mermaid height=234,auto\ngraph BT\n   T0[\"D: 1\"] \n   T1[\"F: 11\"];\n   T2[\"G: 22\"];\n   T3[\"A: 1\"];\n   T4[\"E: 21\"];\n   T5[\"C: 20\"];\n   T6[\"B: 13\"];\n   T2 --> T0;\n   T2 --> T4;\n   T1 --> T5 --> T3;\n   T4 --> T3;\n   T4 --> T6;\n```\n\n* The first input linearization is the ancestor set sort: [B,A,E,D,G,C,F], which is chunked as [B,AEDGC,F].\n* The second input is [B,A,C,F,E,D,G], which is chunked as [BACFE,DG]. The BACFE chunk has higher feerate (66/5=13.5) than B (13) initially, but gets overtaken by the AEDGC chunk.\n* The result of merging is equal to the second input.\n* The optimal linearization would be [B,A,C,E,D,G,F], chunked as [BACE,DG,F].\n\nAgain the crux is discovering an intersection (BACE), but this time between the BACFE chunk and not one but two chunks of the other input (B and AEDGC).\n\n## Prefix-intersection merging\n\nThe solution is to attempt more intersections. Observe that a linearization is really a way of constraining the search for subsets to just prefixes of the linearization. Given the intuition gained above that incomparabilities always seem to be due to a non-considered intersection between the two linearizations, it seems worthwhile try all intersections between prefixes of the first with prefixes of the second linearization. There can be a quadratic number of such intersections however, but maybe we can limit ourselves to just intersections that involve the best chunk of one of both linearizations at least:\n\n* Given two linearizations *L<sub>1</sub>* and *L<sub>2</sub>*:\n  * While not all transactions have been processed:\n    * Find highest-feerate prefix *P<sub>1</sub>* among all unprocessed transactions in *L<sub>1</sub>*.\n    * Find highest-feerate prefix *P<sub>2</sub>* among all unprocessed transactions in *L<sub>2</sub>*.\n    * Find the highest-feerate set among all these:\n      * Intersections between *P<sub>1</sub>* and all prefixes of *L<sub>2</sub>*.\n      * Intersections between *P<sub>2</sub>* and all prefixes of *L<sub>1</sub>*.\n    * Include the transactions from that set in the output linearization.\n    * Mark the included transactions as processed\n \nThe various intersections between *P<sub>1</sub>* and prefixes of *L<sub>2</sub>* can be computed incrementally (keep adding transactions from *L<sub>2</sub>* if they're in *P<sub>1</sub>*, and remember the best one), and similarly for *P<sub>2</sub>* with prefixes of *L<sub>1</sub>*. This, like finding the *P<sub>i</sub>* in the first place, can be done in $\\mathcal{O}(n)$ time. The result is still an $\\mathcal{O}(n^2)$ algorithm.\n\nSurprisingly, this algorithm seems powerful enough to always find a linearization that's strictly better than both inputs if they're incomparable (and at least as good as the best of the two if they are comparable). This works regardless of the quality of the input linearizations (e.g. they don't need to be ancestor sort or better), and does not require connected chunks (see [linearization post-processing](https://delvingbitcoin.org/t/linearization-post-processing-o-n-2-fancy-chunking/201/6)). No proof, though.\n\n## Update: simpler and proven merging\n\nSee the discussion further in this thread (thanks, @ajtowns).\n\nIt appears that it suffices to only consider the intersections between the higher-feerate out of $P_1$ and $P_2$, with all prefixes of the linearization of the other input:\n\n* Given two linearizations $L_1$ and $L_2$:\n  * While not all transactions have been processed:\n    * Find highest-feerate prefix *P<sub>1</sub>* among all unprocessed transactions in *L<sub>1</sub>*.\n    * Find highest-feerate prefix *P<sub>2</sub>* among all unprocessed transactions in *L<sub>2</sub>*.\n    * If $P_1$ has lower feerate than $P_2$, swap $P_1$ with $P_2$ and $L_1$ with $L_2$.\n    * Find the highest-feerate set among all intersections between $P_1$ and the prefixes of $L_1$.\n    * Include the transactions from that set in the output linearization.\n    * Mark the included transactions as processed\n\nInstead of describing the resulting set as an intersection, it can also be seen as the highest-feerate prefix of $P_2$, reordered according to the order these transactions have in $L_1$.\n\nA proof for this scheme can be found in [this thread](https://delvingbitcoin.org/t/cluster-mempool-definitions-theory/202).",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 96,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "<a name=\"introduction-1\" class=\"anchor\" href=\"#introduction-1\"></a>Introduction\nWhile we have several ways for computing good linearizations for a cluster from scratch, sometimes we don\u2019t start from scratch. We may have our own linearization already, but receive (through so far unspecified means) another linearization from a peer. If it\u2019s strictly better, we could &hellip;",
  "truncated": true,
  "post_url": "/t/merging-incomparable-linearizations/209/1",
  "reactions": [
    {
      "id": "rocket",
      "type": "emoji",
      "count": 2
    },
    {
      "id": "heart",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 3,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null,
  "can_vote": false
}