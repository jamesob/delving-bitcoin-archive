{
  "id": 4198,
  "name": "Stefanwouldgo",
  "username": "stefanwouldgo",
  "avatar_template": "/user_avatar/delvingbitcoin.org/stefanwouldgo/{size}/664_2.png",
  "created_at": "2025-02-06T15:37:45.461Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>I have posted a topic about the algorithm we had been working on before these min-cut based approaches were discovered: <a href=\"https://delvingbitcoin.org/t/spanning-forest-cluster-linearization/1419\">Spanning-forest cluster linearization</a>. Perhaps some of the insights there carry over still.</p>\n</blockquote>\n</aside>\n<p>Thank you for the in-depth writeup. It\u2019s certainly full of interesting observations.  It appears you have independently rediscovered a lot of the theory that applies here.</p>\n<aside class=\"quote no-group quote-modified\" data-username=\"sipa\" data-post=\"24\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>My belief was that since there can exist O(2^n)O(2n)O(2^n) different-feerate chunks, an algorithm like this needs extra work to remove previous chunks to avoid the blowup, but what you\u2019re saying is that maximizing weight for a given minimum \\lambda\u03bb\\lambda already accomplishes that?</p>\n</blockquote>\n</aside>\n<p>I\u2019m not quite sure I understand your question. What I am saying is that for any <span class=\"math\">\\lambda</span>, a min-cut calculation gives us a chunk/closure of at least feerate <span class=\"math\">\\lambda</span> (or possibly the empty set if there is no such chunk). For a very low <span class=\"math\">\\lambda</span> (say the lowest feerate of any transaction), it might just give us the entire cluster. If we increase <span class=\"math\">\\lambda</span> from there, we will get better chunks until we overshoot to a <span class=\"math\">\\lambda</span> that is higher than the optimum feerate (after that we might just get the empty set). But the nested cut property means that in every step we get a subset of the earlier chunks. So if we search in the other direction, starting with a high <span class=\"math\">\\lambda</span>, we get bigger and bigger chunks and can just remove the better chunks we have found before.</p>\n<p>In particular, the min-cuts/optimal chunks we find this way form a sub-lattice of the lattice of closures/topogical subsets, that is, they are closed under union and intersection. Even more astoundingly, if <span class=\"math\">X_1</span> is a min-cut for <span class=\"math\">\\lambda_1</span>  and  <span class=\"math\">X_2</span> a min-cut for <span class=\"math\">\\lambda_2</span> with <span class=\"math\">\\lambda_1 \\geq \\lambda_2</span>, then <span class=\"math\">X_1 \\cap X_2</span>  is a min-cut for <span class=\"math\">\\lambda_1</span> and <span class=\"math\">X_1 \\cup X_2</span> is a min-cut for <span class=\"math\">\\lambda_2</span>. This is sometimes called the ascending property. And I believe it is exactly this structure that you have been rediscovering with the cluster diagrams and guides.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>Determining if an RBF is an improvement isn\u2019t just a question of whether the first chunk is better, but whether the diagram is better everywhere (RBFs can conflict with transactions in other clusters even, and we care about the combined diagram in this case).</p>\n</blockquote>\n</aside>\n<p>I know. But the structure that I have just tried to explain appears to guarantee that we can check if we can find a better diagram for the cluster including the new RBF tx by calculating a min-cut at the breakpoints of the combined conflicting diagram. In this way we might not find the optimal chunking, but we can decide if it is better than what we already have.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>Unfortunately, because we work in an adverserial setting, the real question isn\u2019t (just) about real-life clusters we see today, but also worst-case clusters that attackers can construct.</p>\n</blockquote>\n</aside>\n<p>Yes, that is why I think it\u2019s very important to find good worst-case bounds.</p>\n<p>The CPFP example you give is very interesting. I\u2019ll have to think more about the implications.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>We probably need an algorithm that can run with a time limit, and produce a valid (possibly non-optimal) linearization still.</p>\n</blockquote>\n</aside>\n<p>I think the minimum unit of time in which this kind of algorithm can be useful is the time it takes to calculate a min-cut. But it is always easy to get a linearization of any cluster by simply sorting it topologically. From there, with every min-cut we calculate, we can find an optimal chunk to put at the beginning of a linearization. It will be really interesting to find out how fast we can calculate these min-cuts in practice. As I said, in theory this can be done linearly in the number of edges, but that\u2019s not how it will be done in practice. Also in theory, it doesn\u2019t help for our graphs to be DAGs, because any flow network can be transformed into an equivalent DAG in linear time, but in practice it might be very fast. Unless an attacker can construct a bad graph \u2026\nso designing how to deploy these algorithms in a secure way might be another challenge.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"24\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>It would be nice if the algorithm can incorporate \u201cexternally\u201d found good topologically-valid sets, like LIMO can with ancestor sets, guaranteeing them as a minimum quality level.</p>\n</blockquote>\n</aside>\n<p>In a way, this helps, because like in the RBF case mentioned above, it gives us feerates that can be a good starting point. Unfortunately, the nice ascending property from above doesn\u2019t apply to just any chunking we get from anywhere. So if we take the union or intersection of, say, an ancestor set and an optimal min-cut, we will get a closure, but it could have arbitrarily bad feerate. Your LIMO algorithm might help here, but I haven\u2019t fully understood that yet.</p>",
  "post_number": 25,
  "post_type": 1,
  "updated_at": "2025-02-06T15:37:45.461Z",
  "reply_count": 1,
  "reply_to_post_number": 24,
  "quote_count": 1,
  "incoming_link_count": 1,
  "reads": 16,
  "readers_count": 15,
  "score": 73.0,
  "yours": false,
  "topic_id": 303,
  "topic_slug": "how-to-linearize-your-cluster",
  "topic_title": "How to linearize your cluster",
  "topic_html_title": "How to linearize your cluster",
  "category_id": 8,
  "display_username": "Stefanwouldgo",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"sipa, post:24, topic:303\"]\nI have posted a topic about the algorithm we had been working on before these min-cut based approaches were discovered: [Spanning-forest cluster linearization](https://delvingbitcoin.org/t/spanning-forest-cluster-linearization/1419). Perhaps some of the insights there carry over still.\n[/quote]\n\nThank you for the in-depth writeup. It's certainly full of interesting observations.  It appears you have independently rediscovered a lot of the theory that applies here.\n\n[quote=\"sipa, post:24, topic:303\"]\nMy belief was that since there can exist O(2^n)O(2n)O(2^n) different-feerate chunks, an algorithm like this needs extra work to remove previous chunks to avoid the blowup, but what you\u2019re saying is that maximizing weight for a given minimum \\lambda\u03bb\\lambda already accomplishes that?\n[/quote]\n\nI'm not quite sure I understand your question. What I am saying is that for any $\\lambda$, a min-cut calculation gives us a chunk/closure of at least feerate $\\lambda$ (or possibly the empty set if there is no such chunk). For a very low $\\lambda$ (say the lowest feerate of any transaction), it might just give us the entire cluster. If we increase $\\lambda$ from there, we will get better chunks until we overshoot to a $\\lambda$ that is higher than the optimum feerate (after that we might just get the empty set). But the nested cut property means that in every step we get a subset of the earlier chunks. So if we search in the other direction, starting with a high $\\lambda$, we get bigger and bigger chunks and can just remove the better chunks we have found before. \n\nIn particular, the min-cuts/optimal chunks we find this way form a sub-lattice of the lattice of closures/topogical subsets, that is, they are closed under union and intersection. Even more astoundingly, if $X_1$ is a min-cut for $\\lambda_1$  and  $X_2$ a min-cut for $\\lambda_2$ with $\\lambda_1 \\geq \\lambda_2$, then $X_1 \\cap X_2$  is a min-cut for $\\lambda_1$ and $X_1 \\cup X_2$ is a min-cut for $\\lambda_2$. This is sometimes called the ascending property. And I believe it is exactly this structure that you have been rediscovering with the cluster diagrams and guides.\n\n[quote=\"sipa, post:24, topic:303\"]\nDetermining if an RBF is an improvement isn\u2019t just a question of whether the first chunk is better, but whether the diagram is better everywhere (RBFs can conflict with transactions in other clusters even, and we care about the combined diagram in this case).\n[/quote]\n\nI know. But the structure that I have just tried to explain appears to guarantee that we can check if we can find a better diagram for the cluster including the new RBF tx by calculating a min-cut at the breakpoints of the combined conflicting diagram. In this way we might not find the optimal chunking, but we can decide if it is better than what we already have.\n\n[quote=\"sipa, post:24, topic:303\"]\nUnfortunately, because we work in an adverserial setting, the real question isn\u2019t (just) about real-life clusters we see today, but also worst-case clusters that attackers can construct.\n[/quote]\n\nYes, that is why I think it's very important to find good worst-case bounds. \n\nThe CPFP example you give is very interesting. I'll have to think more about the implications.\n\n[quote=\"sipa, post:24, topic:303\"]\nWe probably need an algorithm that can run with a time limit, and produce a valid (possibly non-optimal) linearization still.\n[/quote]\n\nI think the minimum unit of time in which this kind of algorithm can be useful is the time it takes to calculate a min-cut. But it is always easy to get a linearization of any cluster by simply sorting it topologically. From there, with every min-cut we calculate, we can find an optimal chunk to put at the beginning of a linearization. It will be really interesting to find out how fast we can calculate these min-cuts in practice. As I said, in theory this can be done linearly in the number of edges, but that's not how it will be done in practice. Also in theory, it doesn't help for our graphs to be DAGs, because any flow network can be transformed into an equivalent DAG in linear time, but in practice it might be very fast. Unless an attacker can construct a bad graph ...\nso designing how to deploy these algorithms in a secure way might be another challenge.\n\n[quote=\"sipa, post:24, topic:303\"]\nIt would be nice if the algorithm can incorporate \u201cexternally\u201d found good topologically-valid sets, like LIMO can with ancestor sets, guaranteeing them as a minimum quality level.\n[/quote]\n\nIn a way, this helps, because like in the RBF case mentioned above, it gives us feerates that can be a good starting point. Unfortunately, the nice ascending property from above doesn't apply to just any chunking we get from anywhere. So if we take the union or intersection of, say, an ancestor set and an optimal min-cut, we will get a closure, but it could have arbitrarily bad feerate. Your LIMO algorithm might help here, but I haven't fully understood that yet.",
  "actions_summary": [
    {
      "id": 2,
      "count": 2
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 479,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 2
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 2,
  "current_user_used_main_reaction": false
}