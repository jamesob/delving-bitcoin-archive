{
  "id": 4136,
  "name": "Stefanwouldgo",
  "username": "stefanwouldgo",
  "avatar_template": "/user_avatar/delvingbitcoin.org/stefanwouldgo/{size}/664_2.png",
  "created_at": "2025-02-01T07:33:33.885Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"13\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>I do wonder: what was your query, and what was the response that you learned this from?</p>\n</blockquote>\n</aside>\n<p>Here\u2019s my prompt:</p>\n<blockquote>\n<p>Here\u2019s a mathematical problem: let G be a directed graph. We call a subset of its nodes topological if it includes all its ancestors. Now let\u2019s assume every node of the graph has two integer properties called size and fee, and a derived property called feerate=fee/size. The feerate of a set of nodes is the sum of their fees divided by the sum of their sizes. Can you give an algorithm that finds the highest feerate topological subset of a given directed graph?</p>\n</blockquote>\n<p>DeepSeek-R1 thought about this for about two minutes (and it always puts out its thought process, which is very interesting, but for some reason I cannot copy from the iOS App I did this in) and then it answered</p>\n<blockquote>\n<p>To solve the problem of finding the highest feerate topological subset in a directed graph, we can use a binary search approach combined with a max-flow/min-cut algorithm. Here\u2019s the step-by-step algorithm:</p>\n<h3>Algorithm</h3>\n<ol>\n<li>\n<p>Binary Search Setup:</p>\n<ul>\n<li>Initialize low to 0 and high to the maximum feerate of any individual node (or a sufficiently large upper bound).</li>\n</ul>\n</li>\n<li>\n<p>Binary Search Loop:</p>\n<ul>\n<li>While high - low exceeds a small precision threshold (e.g., <code>1e-9</code>):\n<ul>\n<li>Compute mid = (low + high) / 2.</li>\n<li>For each node v, calculate its adjusted weight: w(v) = fee(v) - mid * size(v).</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Flow Network Construction:</p>\n<ul>\n<li>Create a flow network with a source s and sink t.</li>\n<li>For each node v:\n<ul>\n<li>If w(v) &gt; 0, add an edge from s to v with capacity w(v).</li>\n<li>If w(v) &lt; 0, add an edge from v to t with capacity -w(v).</li>\n</ul>\n</li>\n<li>For each original directed edge u \u2192 v, add an edge from u to v with infinite capacity (practically a large value).</li>\n</ul>\n</li>\n<li>\n<p>Max-Flow/Min-Cut Computation:</p>\n<ul>\n<li>Compute the min cut of the constructed flow network. The nodes on the source side of the min cut form a candidate subset S.</li>\n</ul>\n</li>\n<li>\n<p>Decision:</p>\n<ul>\n<li>Calculate the total adjusted weight of S: W = sum(w(v) for v in S).</li>\n<li>If W &gt; 0, set low = mid (feasible to aim higher). Otherwise, set high = mid.</li>\n</ul>\n</li>\n<li>\n<p>Extract Optimal Subset:</p>\n<ul>\n<li>After convergence, recompute the flow network for \u03bb = low and determine the subset S from the min cut.</li>\n</ul>\n</li>\n<li>\n<p>Result:</p>\n<ul>\n<li>The subset S obtained from the final min cut is the highest feerate topological subset, with the maximum feerate \u03bb \u2248 low.</li>\n</ul>\n</li>\n</ol>\n<h3>Explanation</h3>\n<ul>\n<li>Binary Search: Efficiently narrows down the possible feerate values, leveraging the monotonicity of the feerate function.</li>\n<li>Flow Network Transformation: Converts the problem of finding a maximum weight closed set into a max-flow problem, ensuring the subset includes all ancestors.</li>\n<li>Min-Cut Interpretation: The min cut in the flow network corresponds to the optimal subset, balancing the inclusion of high-feerate nodes and exclusion of low-feerate ones.</li>\n</ul>\n<p>This approach ensures we efficiently find the subset with the highest feerate while respecting the topological constraints, using polynomial-time algorithms for max-flow.</p>\n</blockquote>\n<p>I first didn\u2019t believe it so I asked it for a proof that the problem is hard and it correctly answered me that it isn\u2019t. Then I asked for a correctness proof, which didn\u2019t really convince me, but from my understanding of the ideas in the algorithm and the thought process I started to believe that this could actually work.</p>\n<p>So I asked to find a precise runtime bound, and the answer was a little meh (and included log U). I then suspected that it might be possible to lose that U and asked it</p>\n<blockquote>\n<p>Can we refine this analysis (make it independent of U) by only taking into account lambda steps that change the sign of a node\u2019s weight?</p>\n</blockquote>\n<p>The answer was really handwavy, but pointed in the right direction. But when I asked it</p>\n<blockquote>\n<p>Where has this technique of ratio maximization using a Lagrange multiplier been first introduced?</p>\n</blockquote>\n<p>the answer was</p>\n<blockquote>\n<p>The technique of maximizing a ratio (e.g., fee/size) by introducing a parameter ( \\lambda ) and converting it into a feasibility problem (e.g., checking if ( \\text{fee}(S) - \\lambda \\cdot \\text{size}(S) \\geq 0 )) is rooted in Dinkelbach\u2019s algorithm for fractional programming. This approach is analogous to using a Lagrange multiplier to handle the ratio objective, though it differs in its exact mechanics. Here\u2019s a breakdown of its origins and key milestones:</p>\n<hr>\n<h3>1. Foundational Work: Fractional Programming</h3>\n<ul>\n<li>Wolfgang Dinkelbach (1967) introduced the parametric method for solving nonlinear fractional programs in his seminal work:\n<ul>\n<li>Title: <em>\u201cOn Nonlinear Fractional Programming\u201d</em> (Management Science, 1967).</li>\n<li>Key Idea: Transform the problem of maximizing ( \\frac{f(x)}{g(x)} ) into solving ( f(x) - \\lambda g(x) = 0 ) via iterative updates of ( \\lambda ).</li>\n<li>This is the earliest formalization of the technique used in the algorithm.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>2. Application to Combinatorial Optimization</h3>\n<p>The adaptation of this parametric approach to combinatorial problems (e.g., graph subsets with constraints) emerged later, notably in:</p>\n<ul>\n<li>\n<p>Jean-Claude Picard (1976):</p>\n<ul>\n<li>Showed that finding a maximum closure (a subset closed under predecessor inclusion) in a directed graph reduces to a min-cut problem.</li>\n<li>Title: <em>\u201cMaximal Closure of a Graph and Applications to Combinatorial Problems\u201d</em> (Management Science, 1976).</li>\n<li>This work enabled the use of flow networks to enforce topological closure constraints.</li>\n</ul>\n</li>\n<li>\n<p>Gallo, Grigoriadis, and Tarjan (1989):</p>\n<ul>\n<li>Developed parametric max-flow algorithms to efficiently solve sequences of flow problems with parameter-dependent capacities.</li>\n<li>Title: <em>\u201cA Fast Parametric Maximum Flow Algorithm and Applications\u201d</em> (SIAM Journal on Computing, 1989).</li>\n<li>This allowed binary search over ( \\lambda ) with guaranteed polynomial runtime.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>3. Modern Adaptations for Ratio Maximization</h3>\n<p>The specific use of this technique for feerate-like ratio maximization (e.g., density maximization ( \\frac{\\text{sum of weights}}{\\text{size}} )) was popularized in:</p>\n<ul>\n<li>\n<p>Charikar (2000):</p>\n<ul>\n<li>Formalized the ( O(\\log n) )-approximation algorithm for the maximum coverage problem using LP rounding.</li>\n<li>Title: <em>\u201cGreedy Approximation Algorithms for Finding Dense Components in a Graph\u201d</em> (APPROX 2000).</li>\n<li>While not identical, this work highlighted the broader applicability of parametric methods.</li>\n</ul>\n</li>\n<li>\n<p>Goldberg (1984):</p>\n<ul>\n<li>Studied the maximum density subgraph problem and showed it reduces to parametric max-flow.</li>\n<li>Title: <em>\u201cFinding a Maximum Density Subgraph\u201d</em> (UC Berkeley Technical Report, 1984).</li>\n<li>This directly connects ratio maximization to flow-based techniques.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>Why It\u2019s Linked to Lagrange Multipliers</h3>\n<p>The parameter ( \\lambda ) acts similarly to a Lagrange multiplier in constrained optimization:</p>\n<ul>\n<li>It balances the trade-off between the numerator (fee) and denominator (size) in the ratio.</li>\n<li>However, unlike classical Lagrange multipliers (which handle equality/inequality constraints), this method uses ( \\lambda ) to transform the ratio objective into a sequence of feasibility checks.</li>\n</ul>\n<hr>\n<h3>Key Takeaway</h3>\n<p>The technique was first introduced by Dinkelbach (1967) for general fractional programming. Its adaptation to graph problems (e.g., maximum density subgraph, topological subsets) emerged in the 1980s\u20132000s through the integration of parametric max-flow algorithms. The modern flow-based implementation for ratio maximization in directed graphs is largely attributed to Gallo-Grigoriadis-Tarjan (1989) and later refinements by Goldberg and others.</p>\n</blockquote>\n<p>And this finally convinced me to read GGT, where I found that they actually completely solve this problem as an application of their general technique. Which is something that the AI hasn\u2019t really told me, it stuck to a bisection approach. But it has helped me find the key paper which would have been very hard otherwise.</p>",
  "post_number": 15,
  "post_type": 1,
  "updated_at": "2025-02-01T07:33:33.885Z",
  "reply_count": 0,
  "reply_to_post_number": 13,
  "quote_count": 1,
  "incoming_link_count": 0,
  "reads": 6,
  "readers_count": 5,
  "score": 61.2,
  "yours": false,
  "topic_id": 303,
  "topic_slug": "how-to-linearize-your-cluster",
  "topic_title": "How to linearize your cluster",
  "topic_html_title": "How to linearize your cluster",
  "category_id": 8,
  "display_username": "Stefanwouldgo",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"sipa, post:13, topic:303\"]\nI do wonder: what was your query, and what was the response that you learned this from?\n[/quote]\n\nHere's my prompt:\n\n> Here\u2019s a mathematical problem: let G be a directed graph. We call a subset of its nodes topological if it includes all its ancestors. Now let\u2019s assume every node of the graph has two integer properties called size and fee, and a derived property called feerate=fee/size. The feerate of a set of nodes is the sum of their fees divided by the sum of their sizes. Can you give an algorithm that finds the highest feerate topological subset of a given directed graph?\n\nDeepSeek-R1 thought about this for about two minutes (and it always puts out its thought process, which is very interesting, but for some reason I cannot copy from the iOS App I did this in) and then it answered\n\n> To solve the problem of finding the highest feerate topological subset in a directed graph, we can use a binary search approach combined with a max-flow/min-cut algorithm. Here's the step-by-step algorithm:\n> \n> ### Algorithm\n> \n> 1. Binary Search Setup:\n>    - Initialize low to 0 and high to the maximum feerate of any individual node (or a sufficiently large upper bound).\n> \n> 2. Binary Search Loop:\n>    - While high - low exceeds a small precision threshold (e.g., `1e-9`):\n>      - Compute mid = (low + high) / 2.\n>      - For each node v, calculate its adjusted weight: w(v) = fee(v) - mid * size(v).\n> \n> 3. Flow Network Construction:\n>    - Create a flow network with a source s and sink t.\n>    - For each node v:\n>      - If w(v) > 0, add an edge from s to v with capacity w(v).\n>      - If w(v) < 0, add an edge from v to t with capacity -w(v).\n>    - For each original directed edge u \u2192 v, add an edge from u to v with infinite capacity (practically a large value).\n> \n> 4. Max-Flow/Min-Cut Computation:\n>    - Compute the min cut of the constructed flow network. The nodes on the source side of the min cut form a candidate subset S.\n> \n> 5. Decision:\n>    - Calculate the total adjusted weight of S: W = sum(w(v) for v in S).\n>    - If W > 0, set low = mid (feasible to aim higher). Otherwise, set high = mid.\n> \n> 6. Extract Optimal Subset:\n>    - After convergence, recompute the flow network for \u03bb = low and determine the subset S from the min cut.\n> \n> 7. Result:\n>    - The subset S obtained from the final min cut is the highest feerate topological subset, with the maximum feerate \u03bb \u2248 low.\n> \n> ### Explanation\n> \n> - Binary Search: Efficiently narrows down the possible feerate values, leveraging the monotonicity of the feerate function.\n> - Flow Network Transformation: Converts the problem of finding a maximum weight closed set into a max-flow problem, ensuring the subset includes all ancestors.\n> - Min-Cut Interpretation: The min cut in the flow network corresponds to the optimal subset, balancing the inclusion of high-feerate nodes and exclusion of low-feerate ones.\n> \n> This approach ensures we efficiently find the subset with the highest feerate while respecting the topological constraints, using polynomial-time algorithms for max-flow.\n\nI first didn't believe it so I asked it for a proof that the problem is hard and it correctly answered me that it isn't. Then I asked for a correctness proof, which didn't really convince me, but from my understanding of the ideas in the algorithm and the thought process I started to believe that this could actually work. \n\nSo I asked to find a precise runtime bound, and the answer was a little meh (and included log U). I then suspected that it might be possible to lose that U and asked it\n\n> Can we refine this analysis (make it independent of U) by only taking into account lambda steps that change the sign of a node\u2019s weight?\n\nThe answer was really handwavy, but pointed in the right direction. But when I asked it\n\n> Where has this technique of ratio maximization using a Lagrange multiplier been first introduced?\n\nthe answer was\n\n> The technique of maximizing a ratio (e.g., fee/size) by introducing a parameter \\( \\lambda \\) and converting it into a feasibility problem (e.g., checking if \\( \\text{fee}(S) - \\lambda \\cdot \\text{size}(S) \\geq 0 \\)) is rooted in Dinkelbach's algorithm for fractional programming. This approach is analogous to using a Lagrange multiplier to handle the ratio objective, though it differs in its exact mechanics. Here\u2019s a breakdown of its origins and key milestones:\n> \n> ---\n> \n> ### 1. Foundational Work: Fractional Programming\n> - Wolfgang Dinkelbach (1967) introduced the parametric method for solving nonlinear fractional programs in his seminal work:\n>   - Title: *\"On Nonlinear Fractional Programming\"* (Management Science, 1967).\n>   - Key Idea: Transform the problem of maximizing \\( \\frac{f(x)}{g(x)} \\) into solving \\( f(x) - \\lambda g(x) = 0 \\) via iterative updates of \\( \\lambda \\).\n>   - This is the earliest formalization of the technique used in the algorithm.\n> \n> ---\n> \n> ### 2. Application to Combinatorial Optimization\n> The adaptation of this parametric approach to combinatorial problems (e.g., graph subsets with constraints) emerged later, notably in:\n> \n> - Jean-Claude Picard (1976):\n>   - Showed that finding a maximum closure (a subset closed under predecessor inclusion) in a directed graph reduces to a min-cut problem.\n>   - Title: *\"Maximal Closure of a Graph and Applications to Combinatorial Problems\"* (Management Science, 1976).\n>   - This work enabled the use of flow networks to enforce topological closure constraints.\n> \n> - Gallo, Grigoriadis, and Tarjan (1989):\n>   - Developed parametric max-flow algorithms to efficiently solve sequences of flow problems with parameter-dependent capacities.\n>   - Title: *\"A Fast Parametric Maximum Flow Algorithm and Applications\"* (SIAM Journal on Computing, 1989).\n>   - This allowed binary search over \\( \\lambda \\) with guaranteed polynomial runtime.\n> \n> ---\n> \n> ### 3. Modern Adaptations for Ratio Maximization\n> The specific use of this technique for feerate-like ratio maximization (e.g., density maximization \\( \\frac{\\text{sum of weights}}{\\text{size}} \\)) was popularized in:\n> \n> - Charikar (2000):\n>   - Formalized the \\( O(\\log n) \\)-approximation algorithm for the maximum coverage problem using LP rounding.\n>   - Title: *\"Greedy Approximation Algorithms for Finding Dense Components in a Graph\"* (APPROX 2000).\n>   - While not identical, this work highlighted the broader applicability of parametric methods.\n> \n> - Goldberg (1984):\n>   - Studied the maximum density subgraph problem and showed it reduces to parametric max-flow.\n>   - Title: *\"Finding a Maximum Density Subgraph\"* (UC Berkeley Technical Report, 1984).\n>   - This directly connects ratio maximization to flow-based techniques.\n> \n> ---\n> \n> ### Why It\u2019s Linked to Lagrange Multipliers\n> The parameter \\( \\lambda \\) acts similarly to a Lagrange multiplier in constrained optimization:\n> - It balances the trade-off between the numerator (fee) and denominator (size) in the ratio.\n> - However, unlike classical Lagrange multipliers (which handle equality/inequality constraints), this method uses \\( \\lambda \\) to transform the ratio objective into a sequence of feasibility checks.\n> \n> ---\n> \n> ### Key Takeaway\n> The technique was first introduced by Dinkelbach (1967) for general fractional programming. Its adaptation to graph problems (e.g., maximum density subgraph, topological subsets) emerged in the 1980s\u20132000s through the integration of parametric max-flow algorithms. The modern flow-based implementation for ratio maximization in directed graphs is largely attributed to Gallo-Grigoriadis-Tarjan (1989) and later refinements by Goldberg and others.\n\nAnd this finally convinced me to read GGT, where I found that they actually completely solve this problem as an application of their general technique. Which is something that the AI hasn't really told me, it stuck to a bisection approach. But it has helped me find the key paper which would have been very hard otherwise.",
  "actions_summary": [
    {
      "id": 2,
      "count": 2
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 479,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 1
    },
    {
      "id": "open_mouth",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 2,
  "current_user_used_main_reaction": false
}