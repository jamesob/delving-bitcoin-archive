{
  "id": 4281,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2025-02-11T15:48:05.020Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"stefanwouldgo\" data-post=\"43\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/stefanwouldgo/48/664_2.png\" class=\"avatar\"> stefanwouldgo:</div>\n<blockquote>\n<p>In this case the weights are 100-50=50 for A, 3980-2500=1480 for B, and 920-2450=-1530 for C. So the min-cut will pick AB as first subset/chunk.</p>\n</blockquote>\n</aside>\n<p>Oh, I think I follow now; I was missing something super basic just as I thought. So you have the network:</p>\n<pre data-code-height=\"330\" data-code-wrap=\"mermaid\"><code class=\"lang-mermaid\">flowchart TB\n         s --50--&gt; A\n         s --1480--&gt; B\n         C --1530--&gt; t\n         subgraph txs\n         C --\u221e--&gt; B --\u221e--&gt; A\n         end\n</code></pre>\n<p>and your max flow is 0, which means the residual network is the same as the original network, and the min cut sets are {s,A,B} (the nodes reachable from the source) and {C,t} (the nodes that can reach the sink). With a less trivial example you might have some flow from s to B to A to t (where B pays for its parent A whose feerate is below <span class=\"math\">\\lambda</span>) in which case you\u2019d do some actual work.</p>\n<p>So\u2026 is the essence of the idea really just:</p>\n<ul>\n<li>take your collection of txs, and its overall feerate <span class=\"math\">\\lambda</span></li>\n<li>calculate a min cut of <span class=\"math\">S</span> (higher feerate) and <span class=\"math\">T</span> (lower feerate) on a network with <span class=\"math\">n+m</span> edges using <span class=\"math\">f-\\lambda s</span> and <span class=\"math\">\\infty</span> as the capacities</li>\n<li>repeat the algorithm on both <span class=\"math\">S</span> and <span class=\"math\">T</span> to further improve things, prioritising <span class=\"math\">S</span></li>\n<li>run the algorithm at most <span class=\"math\">2k-1</span> times where <span class=\"math\">k</span> is the final/optimal number of chunks \u2013 each run will either split a chunk into two, or tell us we no longer need to do any more processing of that chunk</li>\n</ul>\n<p>And I guess that means the different variants are simply about reusing info from the previous step (eg of ABC with <span class=\"math\">\\lambda_0=50</span>) to make the next step (eg of AB with <span class=\"math\">\\lambda_1=80</span>) faster than doing it from scratch, since the nature of the network is really restricted \u2013 all you\u2019re doing is changing the value of <span class=\"math\">\\lambda</span> and getting either a subset of S as you increase it, or a subset of T as you decrease it?</p>",
  "post_number": 44,
  "post_type": 1,
  "updated_at": "2025-02-11T15:48:05.020Z",
  "reply_count": 0,
  "reply_to_post_number": 43,
  "quote_count": 1,
  "incoming_link_count": 0,
  "reads": 4,
  "readers_count": 3,
  "score": 0.8,
  "yours": false,
  "topic_id": 303,
  "topic_slug": "how-to-linearize-your-cluster",
  "topic_title": "How to linearize your cluster",
  "topic_html_title": "How to linearize your cluster",
  "category_id": 8,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"stefanwouldgo, post:43, topic:303\"]\nIn this case the weights are 100-50=50 for A, 3980-2500=1480 for B, and 920-2450=-1530 for C. So the min-cut will pick AB as first subset/chunk.\n[/quote]\n\nOh, I think I follow now; I was missing something super basic just as I thought. So you have the network:\n\n```mermaid height=330,auto\nflowchart TB\n         s --50--> A\n         s --1480--> B\n         C --1530--> t\n         subgraph txs\n         C --\u221e--> B --\u221e--> A\n         end\n ```\n\nand your max flow is 0, which means the residual network is the same as the original network, and the min cut sets are {s,A,B} (the nodes reachable from the source) and {C,t} (the nodes that can reach the sink). With a less trivial example you might have some flow from s to B to A to t (where B pays for its parent A whose feerate is below $\\lambda$) in which case you'd do some actual work.\n\nSo... is the essence of the idea really just:\n\n * take your collection of txs, and its overall feerate $\\lambda$\n * calculate a min cut of $S$ (higher feerate) and $T$ (lower feerate) on a network with $n+m$ edges using $f-\\lambda s$ and $\\infty$ as the capacities\n * repeat the algorithm on both $S$ and $T$ to further improve things, prioritising $S$\n * run the algorithm at most $2k-1$ times where $k$ is the final/optimal number of chunks -- each run will either split a chunk into two, or tell us we no longer need to do any more processing of that chunk\n\nAnd I guess that means the different variants are simply about reusing info from the previous step (eg of ABC with $\\lambda_0=50$) to make the next step (eg of AB with $\\lambda_1=80$) faster than doing it from scratch, since the nature of the network is really restricted -- all you're doing is changing the value of $\\lambda$ and getting either a subset of S as you increase it, or a subset of T as you decrease it?",
  "actions_summary": [],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}