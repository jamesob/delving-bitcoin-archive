{
  "id": 4260,
  "name": "Stefanwouldgo",
  "username": "stefanwouldgo",
  "avatar_template": "/user_avatar/delvingbitcoin.org/stefanwouldgo/{size}/664_2.png",
  "created_at": "2025-02-10T08:54:13.077Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"34\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>To demonstrate what I mean above:</p>\n</blockquote>\n</aside>\n<p>Wow, this is a brilliant visualization of what\u2019s happening here.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"26\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>You can think of LIMO as repeatedly doing:</p>\n<ul>\n<li>Given a cluster with an existing linearization L for it\n<ul>\n<li>Loop:\n<ul>\n<li>Find a topological subset S with good feerate to move to the front.</li>\n<li>Compute L\u2019, which is L with with S moved to the front (leaving the order of transactions within S, and outside of S, unchanged from L).</li>\n<li>Compute L\u2019\u2019 as a merge of L and L\u2019, which has a diagram that\u2019s at least as good as the best of both everywhere.</li>\n<li>Output the first chunk of L\u2019\u2018, and continue with L as what remains of L\u2019'.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>I suspect this can be done in combination with the GGT approach, but the more interesting combination is if it can feed back too, i.e. the S set finding algorithm can be bootstrapped by using the first chunk of L at that point. This may be harder</p>\n</blockquote>\n</aside>\n<p>This sounds as if LIMO is a good solution for improving an existing linearization in combination with a min-cut approach. The existing best chunk gives a great starting <span class=\"math\">\\lambda</span>, and from there, a min-cut will find a better chunk if there is one, which yields a better linearization. Every min-cut calculation will then either improve a chunk or show that it cannot be improved.</p>\n<aside class=\"quote no-group\" data-username=\"sipa\" data-post=\"32\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/sipa/48/102_2.png\" class=\"avatar\"> sipa:</div>\n<blockquote>\n<p>It also means that the breakpoints GGT finds each correspond with chunk boundaries of the diagram already, but not all of them. To find all of them, one needs to rerun the search in the \u201cother half\u201d of the bisections cut off as well?</p>\n</blockquote>\n</aside>\n<p>Yes, and that is why the GGT algorithm for finding all breakpoints (3.3) is so involved. In order to get the same runtime bound, it needs to contract the s- or t- components. Because the sizes of the s- and t-sides might be badly distributed, it needs to run the flow calculation on the reverse graph from t to s in parallel, and only use the result of the calculation that finishes first. This is obviously wasteful and complicated, and in practice, a simpler algorithm is always better. The PBST-algorithm avoids this waste and seems even faster in reality (and just as good in the worst case), and it finds all the breakpoints in ascending order (descending <span class=\"math\">\\lambda</span> for our case), which might be a desirable property. However, it is also pretty involved. But, we already have code for it.</p>",
  "post_number": 35,
  "post_type": 1,
  "updated_at": "2025-02-10T10:59:31.538Z",
  "reply_count": 1,
  "reply_to_post_number": 34,
  "quote_count": 3,
  "incoming_link_count": 0,
  "reads": 11,
  "readers_count": 10,
  "score": 7.2,
  "yours": false,
  "topic_id": 303,
  "topic_slug": "how-to-linearize-your-cluster",
  "topic_title": "How to linearize your cluster",
  "topic_html_title": "How to linearize your cluster",
  "category_id": 8,
  "display_username": "Stefanwouldgo",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"sipa, post:34, topic:303\"]\nTo demonstrate what I mean above:\n[/quote]\n\nWow, this is a brilliant visualization of what's happening here.\n\n[quote=\"sipa, post:26, topic:303\"]\nYou can think of LIMO as repeatedly doing:\n\n* Given a cluster with an existing linearization L for it\n  * Loop:\n    * Find a topological subset S with good feerate to move to the front.\n    * Compute L\u2019, which is L with with S moved to the front (leaving the order of transactions within S, and outside of S, unchanged from L).\n    * Compute L\u2019\u2019 as a merge of L and L\u2019, which has a diagram that\u2019s at least as good as the best of both everywhere.\n    * Output the first chunk of L\u2019\u2018, and continue with L as what remains of L\u2019'.\n\nI suspect this can be done in combination with the GGT approach, but the more interesting combination is if it can feed back too, i.e. the S set finding algorithm can be bootstrapped by using the first chunk of L at that point. This may be harder\n[/quote]\n\nThis sounds as if LIMO is a good solution for improving an existing linearization in combination with a min-cut approach. The existing best chunk gives a great starting $\\lambda$, and from there, a min-cut will find a better chunk if there is one, which yields a better linearization. Every min-cut calculation will then either improve a chunk or show that it cannot be improved.\n\n[quote=\"sipa, post:32, topic:303\"]\nIt also means that the breakpoints GGT finds each correspond with chunk boundaries of the diagram already, but not all of them. To find all of them, one needs to rerun the search in the \u201cother half\u201d of the bisections cut off as well?\n[/quote]\n\nYes, and that is why the GGT algorithm for finding all breakpoints (3.3) is so involved. In order to get the same runtime bound, it needs to contract the s- or t- components. Because the sizes of the s- and t-sides might be badly distributed, it needs to run the flow calculation on the reverse graph from t to s in parallel, and only use the result of the calculation that finishes first. This is obviously wasteful and complicated, and in practice, a simpler algorithm is always better. The PBST-algorithm avoids this waste and seems even faster in reality (and just as good in the worst case), and it finds all the breakpoints in ascending order (descending $\\lambda$ for our case), which might be a desirable property. However, it is also pretty involved. But, we already have code for it.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 479,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}