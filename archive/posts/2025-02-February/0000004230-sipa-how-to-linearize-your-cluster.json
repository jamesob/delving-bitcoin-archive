{
  "id": 4230,
  "name": "Pieter Wuille",
  "username": "sipa",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/102_2.png",
  "created_at": "2025-02-09T12:38:03.598Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"Lagrang3\" data-post=\"30\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/lagrang3/48/377_2.png\" class=\"avatar\"> Lagrang3:</div>\n<blockquote>\n<p>or alternatively one can simply use a queue to process <em>active</em> nodes in FIFO order leading to a provable <span class=\"math\">O(n^3)</span> complexity</p>\n</blockquote>\n</aside>\n<p>Or, from what I understand so far, one can use maximum-label as a selection strategy (<span class=\"math\">O(n^2 \\sqrt{m})</span>), which also means a <span class=\"math\">O(n^3)</span> worst-case provably complexity, but only <span class=\"math\">O(n^{2.5})</span> when the number of dependencies scales linearly with the number of transactions (which is probably somewhat true in practice, as dependencies cost input vsize).</p>\n<aside class=\"quote no-group\" data-username=\"Lagrang3\" data-post=\"31\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/lagrang3/48/377_2.png\" class=\"avatar\"> Lagrang3:</div>\n<blockquote>\n<p>The other take away points from GGT is that the same preflow-push algorithm can be extended to parametric problems (like the maximum-rate-closure problem that we are interested in) and still keep the same runtime complexity of <span class=\"math\">O(n^3)</span> for our FIFO-preflow-push case</p>\n</blockquote>\n</aside>\n<p>That\u2019s good to know. My guess would be that the dynamic trees version (which would be also <span class=\"math\">O(n^3)</span> in the worst case, but <span class=\"math\">O(n^2 \\log n)</span> for a linear number of dependencies) might be not worth it for us for the small problem sizes.</p>\n<aside class=\"quote no-group\" data-username=\"Lagrang3\" data-post=\"31\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/lagrang3/48/377_2.png\" class=\"avatar\"> Lagrang3:</div>\n<blockquote>\n<p>There is another interesting point to remember, which is the fact that we are interested in the min-cut set and not on the maxflow itself. So we may stop the algorithm execution earlier and possibly save half of the running time by doing so.</p>\n</blockquote>\n</aside>\n<p>That\u2019s surprising to me, because if you computed the min-cut, in our setting, you know the closure, whose total fee and size you can determine in <span class=\"math\">O(n)</span> time (just sum them up), and the max flow of the problem you just solved will be <span class=\"math\">\\operatorname{fee} - \\lambda \\operatorname{size}</span>, with <span class=\"math\">\\lambda</span> the parameter value you just solved for. So it seems to me that not computing the actual max flow can at best save you <span class=\"math\">O(n)</span> work.</p>\n<hr>\n<p>I also had the following realization (see diagram posted <a href=\"https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303/34\">below</a>). Solving for the closure with maximal <span class=\"math\">\\operatorname{fee} - \\lambda \\operatorname{size}</span> can be visualized on the feerate diagram (diagram with cumulative size on X axis, cumulative fee on Y axis, dots for all optimal chunk boundaries, straight lines between them).</p>\n<p>In the initial step, where you set <span class=\"math\">\\lambda</span> to the feerate of the entire cluster, draw a line L from the origin to the end point of the diagram (whose slope will be <span class=\"math\">\\lambda</span>). The min cut found will the point on the diagram whose highest point lies most <em>above</em> L, in vertical distance. And from this it is clear that point must be on a chunk boundary (if it wasn\u2019t, and was on or below a line segment of the diagram, then depending on the slope of L, one of the two segment end points must lie higher above L).</p>\n<p>In a second iteration (which in GGT does not require starting over from scratch), one does the same thing, but with <span class=\"math\">\\lambda</span> now set to the feerate of the previously-found solution, and L a line from the origin to the point found there. The next min-cut will now found us the point that lies most above <em>that</em> L, etc.</p>\n<p>From this it is clear that there can at most be N steps, because there can be at most N chunks, and each min-cut step is sort of a bisection search, cutting off one or more bad chunks of the solution.</p>\n<p>It also means that the breakpoints GGT finds each correspond with chunk boundaries of the diagram already, but not all of them. To find all of them, one needs to rerun the search in the \u201cother half\u201d of the bisections cut off as well?</p>",
  "post_number": 32,
  "post_type": 1,
  "updated_at": "2025-02-09T16:37:28.652Z",
  "reply_count": 2,
  "reply_to_post_number": 30,
  "quote_count": 2,
  "incoming_link_count": 0,
  "reads": 11,
  "readers_count": 10,
  "score": 27.2,
  "yours": false,
  "topic_id": 303,
  "topic_slug": "how-to-linearize-your-cluster",
  "topic_title": "How to linearize your cluster",
  "topic_html_title": "How to linearize your cluster",
  "category_id": 8,
  "display_username": "Pieter Wuille",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 4,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"Lagrang3, post:30, topic:303\"]\nor alternatively one can simply use a queue to process *active* nodes in FIFO order leading to a provable $O(n^3)$ complexity\n[/quote]\n\nOr, from what I understand so far, one can use maximum-label as a selection strategy ($O(n^2 \\sqrt{m})$), which also means a $O(n^3)$ worst-case provably complexity, but only $O(n^{2.5})$ when the number of dependencies scales linearly with the number of transactions (which is probably somewhat true in practice, as dependencies cost input vsize).\n\n[quote=\"Lagrang3, post:31, topic:303\"]\nThe other take away points from GGT is that the same preflow-push algorithm can be extended to parametric problems (like the maximum-rate-closure problem that we are interested in) and still keep the same runtime complexity of $O(n^3)$ for our FIFO-preflow-push case\n[/quote]\n\nThat's good to know. My guess would be that the dynamic trees version (which would be also $O(n^3)$ in the worst case, but $O(n^2 \\log n)$ for a linear number of dependencies) might be not worth it for us for the small problem sizes.\n\n[quote=\"Lagrang3, post:31, topic:303\"]\nThere is another interesting point to remember, which is the fact that we are interested in the min-cut set and not on the maxflow itself. So we may stop the algorithm execution earlier and possibly save half of the running time by doing so.\n[/quote]\n\n\nThat's surprising to me, because if you computed the min-cut, in our setting, you know the closure, whose total fee and size you can determine in $O(n)$ time (just sum them up), and the max flow of the problem you just solved will be $\\operatorname{fee} - \\lambda \\operatorname{size}$, with $\\lambda$ the parameter value you just solved for. So it seems to me that not computing the actual max flow can at best save you $O(n)$ work.\n\n---\n\nI also had the following realization (see diagram posted [below](https://delvingbitcoin.org/t/how-to-linearize-your-cluster/303/34)). Solving for the closure with maximal $\\operatorname{fee} - \\lambda \\operatorname{size}$ can be visualized on the feerate diagram (diagram with cumulative size on X axis, cumulative fee on Y axis, dots for all optimal chunk boundaries, straight lines between them).\n\nIn the initial step, where you set $\\lambda$ to the feerate of the entire cluster, draw a line L from the origin to the end point of the diagram (whose slope will be $\\lambda$). The min cut found will the point on the diagram whose highest point lies most *above* L, in vertical distance. And from this it is clear that point must be on a chunk boundary (if it wasn't, and was on or below a line segment of the diagram, then depending on the slope of L, one of the two segment end points must lie higher above L).\n\nIn a second iteration (which in GGT does not require starting over from scratch), one does the same thing, but with $\\lambda$ now set to the feerate of the previously-found solution, and L a line from the origin to the point found there. The next min-cut will now found us the point that lies most above *that* L, etc.\n\nFrom this it is clear that there can at most be N steps, because there can be at most N chunks, and each min-cut step is sort of a bisection search, cutting off one or more bad chunks of the solution.\n\nIt also means that the breakpoints GGT finds each correspond with chunk boundaries of the diagram already, but not all of them. To find all of them, one needs to rerun the search in the \"other half\" of the bisections cut off as well?",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 96,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false
}