{
  "id": 5124,
  "name": "ZmnSCPxj jxPCSnmZ",
  "username": "ZmnSCPxj",
  "avatar_template": "/letter_avatar_proxy/v4/letter/z/ee7513/{size}.png",
  "created_at": "2025-05-26T20:21:05.893Z",
  "cooked": "<p>Last month I had a discussion about this what a few people.  Somebody pointed out that we deployed \u201cHTTPS Everywhere\u201d to improve the privacy of everyone on the web.</p>\n<p>My counterpoint at the time was that \u201cHTTPS Everywhere\u201d could be imposed by user-agents and their operators, but there is nothing that would force forwarding nodes to create randomized forwarding times; senders and receivers cannot force forwarding nodes to perform the randomization.  This is equivalent to the observation by carla that it is the senders and receivers who have an incentive to randomize, not forwarding nodes.</p>\n<p>My counterproposal was:</p>\n<ul>\n<li>Make <em><strong>batching of HTLCs</strong></em> the primitive, not individual <code>update_add_htlc</code>s.</li>\n<li>Create a new forwarding \u201creceiver-enforced forwarding randomization\u201d protocol:\n<ul>\n<li>New message <code>you_have_incoming_htlcs</code>.  This is sent if a node wants to <em>eventually</em> <code>update_add_htlc</code> <em><strong>one or more</strong></em> HTLCs.  The message has no body, and is replayed on reconnection.</li>\n<li>New response <code>gimme_the_incoming_htlcs</code>.  This is sent after receiving <code>you_have_incoming_htlcs</code>.</li>\n<li>New rules for <code>update_add_htlc</code>:\n<ul>\n<li>it is an error for a node to send <code>update_add_htlc</code> unless it has received <code>gimme_the_incoming_htlcs</code>. (because it is an error, you should <code>error</code> if you receive an <code>update_add_htlc</code> without having sent <code>gimme_the_incoming_htlcs</code> first and drop all channels with that peer onchain)</li>\n<li>A \u201cbatch\u201d of <code>update_add_htlc</code>s MUST be sent in response to <code>gimme_the_incoming_htlcs</code>.  The batch is ended by a <code>commitment_signed</code>.  After sending <code>commitment_signed</code>, it is once again an error for the node to send <code>update_add_htlc</code> until it has received a new <code>gimme_the_incoming_htlcs</code>.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>The above adds increased latency to the forwarding protocol, due to the additional <code>you_have_incoming_htlcs</code>/<code>gimme_the_incoming_htlcs</code> exchange.  A counter to this is that this protocol can be restricted to use only on endpoint receivers (i.e. receivers can use an even feature bit to enforce that this protocol is used in an \u201cHTTPS Everywhere\u201d-style campaign, while forwarders can provide an odd feature bit to indicate to new peers that they support this protocol, and if both of you use the odd feature bit you don\u2019t follow this protocol after all), and pure forwarders can use the original low-latency forwarding protocol with each other.</p>\n<p>A receiver can, on receiving a <code>you_have_incoming_htlcs</code> message, then randomize the delay before sending <code>gimme_the_incoming_htlcs</code>.  This also allows the LSP of the receiver to batch multiple HTLCs to the receiver (e.g. probably helpful to improve throughput for multipath payments, which carla also noted would probably also help privacy in practice).</p>",
  "post_number": 4,
  "post_type": 1,
  "posts_count": 40,
  "updated_at": "2025-05-26T20:23:54.347Z",
  "reply_count": 0,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 0,
  "reads": 42,
  "readers_count": 41,
  "score": 8.4,
  "yours": false,
  "topic_id": 1723,
  "topic_slug": "latency-and-privacy-in-lightning",
  "topic_title": "Latency and Privacy in Lightning",
  "topic_html_title": "Latency and Privacy in Lightning",
  "category_id": 7,
  "display_username": "ZmnSCPxj jxPCSnmZ",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "Last month I had a discussion about this what a few people.  Somebody pointed out that we deployed \"HTTPS Everywhere\" to improve the privacy of everyone on the web.\n\nMy counterpoint at the time was that \"HTTPS Everywhere\" could be imposed by user-agents and their operators, but there is nothing that would force forwarding nodes to create randomized forwarding times; senders and receivers cannot force forwarding nodes to perform the randomization.  This is equivalent to the observation by carla that it is the senders and receivers who have an incentive to randomize, not forwarding nodes.\n\nMy counterproposal was:\n\n* Make ***batching of HTLCs*** the primitive, not individual `update_add_htlc`s.\n* Create a new forwarding \"receiver-enforced forwarding randomization\" protocol:\n  * New message `you_have_incoming_htlcs`.  This is sent if a node wants to *eventually* `update_add_htlc` ***one or more*** HTLCs.  The message has no body, and is replayed on reconnection.\n  * New response `gimme_the_incoming_htlcs`.  This is sent after receiving `you_have_incoming_htlcs`.\n  * New rules for `update_add_htlc`:\n    *  it is an error for a node to send `update_add_htlc` unless it has received `gimme_the_incoming_htlcs`. (because it is an error, you should `error` if you receive an `update_add_htlc` without having sent `gimme_the_incoming_htlcs` first and drop all channels with that peer onchain)\n    * A \"batch\" of `update_add_htlc`s MUST be sent in response to `gimme_the_incoming_htlcs`.  The batch is ended by a `commitment_signed`.  After sending `commitment_signed`, it is once again an error for the node to send `update_add_htlc` until it has received a new `gimme_the_incoming_htlcs`.\n\nThe above adds increased latency to the forwarding protocol, due to the additional `you_have_incoming_htlcs`/`gimme_the_incoming_htlcs` exchange.  A counter to this is that this protocol can be restricted to use only on endpoint receivers (i.e. receivers can use an even feature bit to enforce that this protocol is used in an \"HTTPS Everywhere\"-style campaign, while forwarders can provide an odd feature bit to indicate to new peers that they support this protocol, and if both of you use the odd feature bit you don't follow this protocol after all), and pure forwarders can use the original low-latency forwarding protocol with each other.\n\nA receiver can, on receiving a `you_have_incoming_htlcs` message, then randomize the delay before sending `gimme_the_incoming_htlcs`.  This also allows the LSP of the receiver to batch multiple HTLCs to the receiver (e.g. probably helpful to improve throughput for multipath payments, which carla also noted would probably also help privacy in practice).",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 104,
  "hidden": false,
  "trust_level": 2,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Last month I had a discussion about this what a few people.  Somebody pointed out that we deployed \u201cHTTPS Everywhere\u201d to improve the privacy of everyone on the web. \nMy counterpoint at the time was that \u201cHTTPS Everywhere\u201d could be imposed by user-agents and their operators, but there is nothing that&hellip;",
  "truncated": true,
  "post_url": "/t/latency-and-privacy-in-lightning/1723/4",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}