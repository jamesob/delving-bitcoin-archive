{
  "id": 6239,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2025-11-13T22:19:50.673Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"instagibbs\" data-post=\"4\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/instagibbs/48/28_2.png\" class=\"avatar\"> instagibbs:</div>\n<blockquote>\n<p>TIL it was that slow. I worry that benchmarking against the <em>worst case</em> as the new \u201caverage\u201d is the wrong goal</p>\n</blockquote>\n</aside>\n<p>Signatures are also cached, meaning that if we have seen the tx recently, re-verifying the signature for the block is much faster; whereas all the other logic isn\u2019t cached (there is a script cache, but that is only reused mempool-to-mempool and block-to-block, eg in a reorg, not mempool-to-block). So a high budget for non-signature operations likely has a worst impact on average validation time than a nominally-equivalent budget for signature operations.</p>\n<p>Also, you can only have ~62k distinct signatures in 4MB of witness data, so using the full budget would presumably mean ~22% of your operations should/could be cache hits even if none of the data had been seen before.</p>\n<p>(80k sigops is, of course, the figure from segwit v0/BIP141 which is 4x the original number of sigops per block. Taproot/BIP340-342 preserves that figure pretty closely, so that I think you could get about 79,988 BIP340 verify ops in a block, though it also introduces the potential for combining sig operations into a single validation to reduce computation time)</p>\n<p>(Also, there\u2019s probably a difference between single-core cpu time and wall-clock time when multiple validatation threads are in operation, at least for average blocks (versus worst-case blocks where all the work is in a single 4MB witness script). 1000ms of cpu time, divided between 4 or 8 threads is already perhaps 150ms-300ms of wall clock time, after all)</p>\n<aside class=\"quote no-group\" data-username=\"Julian\" data-post=\"5\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/j/74df32/48.png\" class=\"avatar\"> Julian:</div>\n<blockquote>\n<p>doing some benchmarks on real blocks would be interesting</p>\n</blockquote>\n</aside>\n<p>Doing benchmarks on the more powerful logic new opcodes enable might be more interesting; eg the <a href=\"https://bitcoinmagazine.com/technical/a-zero-knowledge-proof-is-verified-on-bitcoin-for-the-first-time-in-history\">OP_CAT based zkp verifier</a>? How many zkps (implemented that way) could we verify in a block, if 100ms (or whatever) of cpu time were the only constraint? Seems to have some 223k operations per script, 30k ADD/DUP, 20k IF/ENDIF/SUB, 10k SWAP/LESSTHAN/TOALT/FROMALT, 400 CAT/1SUB/DEPTH/SHA256, 1 CHECKSIG, etc.</p>",
  "post_number": 6,
  "post_type": 1,
  "posts_count": 6,
  "updated_at": "2025-11-13T22:22:48.956Z",
  "reply_count": 0,
  "reply_to_post_number": 4,
  "quote_count": 2,
  "incoming_link_count": 1,
  "reads": 3,
  "readers_count": 2,
  "score": 5.6,
  "yours": false,
  "topic_id": 2094,
  "topic_slug": "benchmarking-bitcoin-script-evaluation-for-the-varops-budget-great-script-restoration",
  "topic_title": "Benchmarking Bitcoin Script Evaluation for the Varops Budget (Great Script Restoration)",
  "topic_html_title": "Benchmarking Bitcoin Script Evaluation for the Varops Budget (Great Script Restoration)",
  "category_id": 7,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"instagibbs, post:4, topic:2094\"]\nTIL it was that slow. I worry that benchmarking against the *worst case* as the new \u201caverage\u201d is the wrong goal\n[/quote]\n\nSignatures are also cached, meaning that if we have seen the tx recently, re-verifying the signature for the block is much faster; whereas all the other logic isn't cached (there is a script cache, but that is only reused mempool-to-mempool and block-to-block, eg in a reorg, not mempool-to-block). So a high budget for non-signature operations likely has a worst impact on average validation time than a nominally-equivalent budget for signature operations.\n\nAlso, you can only have ~62k distinct signatures in 4MB of witness data, so using the full budget would presumably mean ~22% of your operations should/could be cache hits even if none of the data had been seen before.\n\n(80k sigops is, of course, the figure from segwit v0/BIP141 which is 4x the original number of sigops per block. Taproot/BIP340-342 preserves that figure pretty closely, so that I think you could get about 79,988 BIP340 verify ops in a block, though it also introduces the potential for combining sig operations into a single validation to reduce computation time)\n\n(Also, there's probably a difference between single-core cpu time and wall-clock time when multiple validatation threads are in operation, at least for average blocks (versus worst-case blocks where all the work is in a single 4MB witness script). 1000ms of cpu time, divided between 4 or 8 threads is already perhaps 150ms-300ms of wall clock time, after all)\n\n[quote=\"Julian, post:5, topic:2094\"]\ndoing some benchmarks on real blocks would be interesting\n[/quote]\n\nDoing benchmarks on the more powerful logic new opcodes enable might be more interesting; eg the [OP_CAT based zkp verifier](https://bitcoinmagazine.com/technical/a-zero-knowledge-proof-is-verified-on-bitcoin-for-the-first-time-in-history)? How many zkps (implemented that way) could we verify in a block, if 100ms (or whatever) of cpu time were the only constraint? Seems to have some 223k operations per script, 30k ADD/DUP, 20k IF/ENDIF/SUB, 10k SWAP/LESSTHAN/TOALT/FROMALT, 400 CAT/1SUB/DEPTH/SHA256, 1 CHECKSIG, etc.",
  "actions_summary": [],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Signatures are also cached, meaning that if we have seen the tx recently, re-verifying the signature for the block is much faster; whereas all the other logic isn\u2019t cached (there is a script cache, but that is only reused mempool-to-mempool and block-to-block, eg in a reorg, not mempool-to-block). &hellip;",
  "truncated": true,
  "post_url": "/t/benchmarking-bitcoin-script-evaluation-for-the-varops-budget-great-script-restoration/2094/6",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}