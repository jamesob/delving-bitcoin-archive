{
  "id": 6212,
  "name": "",
  "username": "Julian",
  "avatar_template": "/letter_avatar_proxy/v4/letter/j/74df32/{size}.png",
  "created_at": "2025-11-10T20:57:20.688Z",
  "cooked": "<p>Hi aj, thanks for taking the time,</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Probably want to specify the build options more completely if you want benchmark results to be comparable? (<code>CMAKE_BUILD_TYPE</code> as something other than <code>Debug</code> in particular)</p>\n</blockquote>\n</aside>\n<p>Yes I have been using the default <code>CMAKE_BUILD_TYPE=RelWithDebInfo</code>, since this is probably what most use. I am not sure if the binaries on <a href=\"http://bitcoincore.org\" rel=\"noopener nofollow ugc\">bitcoincore.org</a> are built in release instead, anyways the performance difference between the two seems to be negligible.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Probably should provide a git repo to add the CSV\u2019s to via PR?</p>\n</blockquote>\n</aside>\n<p>That\u2019s a great idea, I have opened a repo here and will update the post: <a href=\"https://github.com/jmoik/varopsData\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - jmoik/varopsData: Collection of csv files produced by the bench_varops bitcoin core benchmark.</a></p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>I\u2019m seeing errors, which look like they lead to useless data, fwiw:</p>\n<pre><code class=\"lang-auto\">\n</code></pre>\n</blockquote>\n</aside>\n<p>The script errors are expected for some benchmarks and can be ignored since they produce a time of 0 seconds and we are interested only in the worst times, but you are correct, I will add more specific stacks/scripts to benchmark OP_DIV / OP_MOD properly.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Capping at 100% varops budget seems to make the data less useful in evaluating whether the varops ratios are accurate, than if no capping was in place? eg these XOR tests:</p>\n<pre><code class=\"lang-auto\">\n</code></pre>\n</blockquote>\n</aside>\n<p>With 20.8 B compute units, the scripts are already fairly long, so you don\u2019t gain much from not capping here, of course you lose the reference on how many ops were executed and larger stack element sizes might be cut of early and therefore the time / input bytes might be shifted downwards slightly.</p>\n<p>If no capping was in place, some scripts would run extremely long.</p>\n<p>If we want to measure performance relative to input bytes, we don\u2019t need to call EvalScript() at all and remove all the noise from restoring the stack and the rest of the script interpreter (duplicating a large stack element is quite slow).</p>\n<p>This benchmark is not designed to measure time / input size, I wanted to ensure that the budget is sufficient for any input size and having similar values for those XOR script tells me that the XOR cost scales appropriately.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>I would have expected to be able to use the data generated either to produce per-hardware calculations of the constant-and-per-byte factors for each opcode (and thus review the hardcoded varops factors)</p>\n</blockquote>\n</aside>\n<p>If we take the 5,200 compute units per weight as constant or renormalize this is interesting indeed, but there are too many free variables, the 5,200 was initially derived from the 10x hashing factor (520 bytes for a single script element x 10, such that one hashing opcode could always pay for a current max size element).</p>\n<p>Therefore, I assumed the 10x for hashing (as well as the other costs) as constant and kept the 5,200 as the free parameter.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Those compare to current varops figures of constant=0, per byte=10, I believe. I\u2019m surprised that ripemd seems to be faster than sha256 for me.</p>\n</blockquote>\n</aside>\n<p>Yes that seems reasonable, although a bit slow, did you get those values through a linear fit of the different input sizes? I am also surprised, on my machine RIPEMD is the slowest hashing algorithm by far and the slowest script overall, the only one going above 80,000 Schnorrs. But unlike SHA, RIPEMD is still limited to 520 bytes in tapscript v2, maybe your machine is very slow with SHA on large inputs?</p>\n<p>I don\u2019t think we want to assign different costs to different hashing algorithms, since this is highly dependent on the implementation.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>FWIW DUP/DROP benchmarks seems to imply figures of 276 compute units per operation plus 0.05 compute units per byte for me (as opposed to 0 + 1 per byte).</p>\n</blockquote>\n</aside>\n<p>I have also experimented with a flat cost for each operation, since we do have interpreter overhead and acting on an empty input is obviously more expensive than zero, but it does not seem to be that important since we do have the block size limit.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"2\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Or normalized from \u201cseconds per block over-filled with repeating script\u201d to \u201cschnorr ops per op\u201d, perhaps:</p>\n</blockquote>\n</aside>\n<p>We have actually worked with this normalization initially and it is helpful when there is no varops limit, but felt like it is simpler to discuss these benchmarks by using the block sized script and comparing it to the known time of 80,000 Schnorrs.</p>",
  "post_number": 3,
  "post_type": 1,
  "posts_count": 3,
  "updated_at": "2025-11-10T20:57:20.688Z",
  "reply_count": 0,
  "reply_to_post_number": 2,
  "quote_count": 1,
  "incoming_link_count": 0,
  "reads": 5,
  "readers_count": 4,
  "score": 0.8,
  "yours": false,
  "topic_id": 2094,
  "topic_slug": "benchmarking-bitcoin-script-evaluation-for-the-varops-budget-great-script-restoration",
  "topic_title": "Benchmarking Bitcoin Script Evaluation for the Varops Budget (Great Script Restoration)",
  "topic_html_title": "Benchmarking Bitcoin Script Evaluation for the Varops Budget (Great Script Restoration)",
  "category_id": 7,
  "display_username": "",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "Hi aj, thanks for taking the time,\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nProbably want to specify the build options more completely if you want benchmark results to be comparable? (`CMAKE_BUILD_TYPE` as something other than `Debug` in particular)\n\n[/quote]\n\nYes I have been using the default `CMAKE_BUILD_TYPE=RelWithDebInfo`, since this is probably what most use. I am not sure if the binaries on bitcoincore.org are built in release instead, anyways the performance difference between the two seems to be negligible.\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nProbably should provide a git repo to add the CSV\u2019s to via PR?\n\n[/quote]\n\nThat\u2019s a great idea, I have opened a repo here and will update the post: https://github.com/jmoik/varopsData\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nI\u2019m seeing errors, which look like they lead to useless data, fwiw:\n\n```\n\n```\n\n[/quote]\n\nThe script errors are expected for some benchmarks and can be ignored since they produce a time of 0 seconds and we are interested only in the worst times, but you are correct, I will add more specific stacks/scripts to benchmark OP_DIV / OP_MOD properly.\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nCapping at 100% varops budget seems to make the data less useful in evaluating whether the varops ratios are accurate, than if no capping was in place? eg these XOR tests:\n\n```\n\n```\n\n[/quote]\n\nWith 20.8 B compute units, the scripts are already fairly long, so you don\u2019t gain much from not capping here, of course you lose the reference on how many ops were executed and larger stack element sizes might be cut of early and therefore the time / input bytes might be shifted downwards slightly.\n\nIf no capping was in place, some scripts would run extremely long.\n\nIf we want to measure performance relative to input bytes, we don\u2019t need to call EvalScript() at all and remove all the noise from restoring the stack and the rest of the script interpreter (duplicating a large stack element is quite slow).\n\nThis benchmark is not designed to measure time / input size, I wanted to ensure that the budget is sufficient for any input size and having similar values for those XOR script tells me that the XOR cost scales appropriately.\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nI would have expected to be able to use the data generated either to produce per-hardware calculations of the constant-and-per-byte factors for each opcode (and thus review the hardcoded varops factors)\n\n[/quote]\n\nIf we take the 5,200 compute units per weight as constant or renormalize this is interesting indeed, but there are too many free variables, the 5,200 was initially derived from the 10x hashing factor (520 bytes for a single script element x 10, such that one hashing opcode could always pay for a current max size element).\n\nTherefore, I assumed the 10x for hashing (as well as the other costs) as constant and kept the 5,200 as the free parameter.\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nThose compare to current varops figures of constant=0, per byte=10, I believe. I\u2019m surprised that ripemd seems to be faster than sha256 for me.\n\n[/quote]\n\nYes that seems reasonable, although a bit slow, did you get those values through a linear fit of the different input sizes? I am also surprised, on my machine RIPEMD is the slowest hashing algorithm by far and the slowest script overall, the only one going above 80,000 Schnorrs. But unlike SHA, RIPEMD is still limited to 520 bytes in tapscript v2, maybe your machine is very slow with SHA on large inputs?\n\nI don\u2019t think we want to assign different costs to different hashing algorithms, since this is highly dependent on the implementation.\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nFWIW DUP/DROP benchmarks seems to imply figures of 276 compute units per operation plus 0.05 compute units per byte for me (as opposed to 0 + 1 per byte).\n\n[/quote]\n\nI have also experimented with a flat cost for each operation, since we do have interpreter overhead and acting on an empty input is obviously more expensive than zero, but it does not seem to be that important since we do have the block size limit.\n\n[quote=\"ajtowns, post:2, topic:2094\"]\nOr normalized from \u201cseconds per block over-filled with repeating script\u201d to \u201cschnorr ops per op\u201d, perhaps:\n\n[/quote]\n\nWe have actually worked with this normalization initially and it is helpful when there is no varops limit, but felt like it is simpler to discuss these benchmarks by using the block sized script and comparing it to the known time of 80,000 Schnorrs.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 962,
  "hidden": false,
  "trust_level": 0,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Hi aj, thanks for taking the time, \n\nYes I have been using the default CMAKE_BUILD_TYPE=RelWithDebInfo, since this is probably what most use. I am not sure if the binaries on <a href=\"http://bitcoincore.org\" rel=\"noopener nofollow ugc\">bitcoincore.org</a> are built in release instead, anyways the performance difference between the two seems to be negligible. \n\nTh&hellip;",
  "truncated": true,
  "post_url": "/t/benchmarking-bitcoin-script-evaluation-for-the-varops-budget-great-script-restoration/2094/3",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}