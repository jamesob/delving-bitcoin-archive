{
  "id": 3967,
  "name": "Zawy",
  "username": "zawy",
  "avatar_template": "/user_avatar/delvingbitcoin.org/zawy/{size}/750_2.png",
  "created_at": "2025-01-04T23:06:46.356Z",
  "cooked": "<aside class=\"quote no-group quote-modified\" data-username=\"ajtowns\" data-post=\"15\" data-topic=\"1331\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>I think it would be interesting to analyse this both as a difficulty adjustment for a standalone consensus system [and for Braidpool]</p>\n</blockquote>\n</aside>\n<p>This is what I\u2019m doing. Braidpool\u2019s specifics aren\u2019t on my mind yet.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"15\" data-topic=\"1331\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>With the same latency applying to a global braidpool, but an expected block rate of 100 blocks per ten minutes (10% hashrate at 1/1000th of the difficulty), then the expected \u201corphan\u201d rate is about 4%. Conversely, if you target an expected \u201corphan\u201d rate of 44%, with 10% hashrate, that means beads are 14,500 times easier than blocks, rather than 1000 times easier?</p>\n</blockquote>\n</aside>\n<p>Nb/Nc = 2.42 (approx parents = 1.44) results in solvetimes 2.9x mean latency if latency varies randomly from 0 to 2x the mean. It\u2019s independent of hashrate. It targets a solvetime in units of latency, but affected by latency distribution.  So if mean latency in a Braidpool = 0.5 seconds, block time is 1.45 s, 417 blocks in 600 s. At 10% hashrate, that\u2019s 4,000x easier.</p>\n<p>Using 1-e^(-0.5/1.45), I get a 29.2% orphan rate for Nb/Nc = 2.42 and a uniformly random latency variation around that mean. This equation for orphan rate is approximate. There\u2019s a paper from way back that derives something precise. Looking at it another way, 1/2.42 is the fraction of blocks without any sibling according to any parents or children. If half the remaining 1.42 blocks would have been orphaned then 0.71/2.42 = 29.3% orphan rate.</p>\n<aside class=\"quote no-group\" data-username=\"mcelrath\" data-post=\"8\" data-topic=\"1331\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/mcelrath/48/521_2.png\" class=\"avatar\"> mcelrath:</div>\n<blockquote>\n<p>The above idea is contrary to Zawy\u2019s suggestion to orphan high latency beads, I want to include them but not pay them.</p>\n</blockquote>\n</aside>\n<p>To me, \u201cnot paying them\u201d = orphaning, whether or not they\u2019re included in the DAA calculation.</p>\n<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"15\" data-topic=\"1331\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>I think/conjecture the look-back/latency constraints are probably critical for this approach\u2019s ability to come to consensus between subsets of hashrate with very different latency properties \u2013 the 200:1 latency ratio I suggested would (I think) make it difficult for the latest beads from the two groups to have sufficiently common ancestry that they get merged; whereas I\u2019d expect a 2:1 latency ratio to be more-or-less fine.</p>\n</blockquote>\n</aside>\n<p>The Nb/Nc DAA doesn\u2019t seem to have any problem with widely-varying latency. For example, if 5% have 200x longer latency, the solvetime per latency is still in the 2 to 3 range. The Nb/Nc DAA is pretty incredible at how well it handles topology and random variations in latency.</p>\n<aside class=\"quote no-group\" data-username=\"mcelrath\" data-post=\"12\" data-topic=\"1331\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/mcelrath/48/521_2.png\" class=\"avatar\"> mcelrath:</div>\n<blockquote>\n<p>I\u2019m fairly skeptical of using graph structure alone and the DAA here to handle high latency. High latency is already observed and accounted for using the Nc/Nb method (because high latency generates large cohorts). I don\u2019t want to create incentives for miners to do anything other than naming all known tips. So, I think we need to pull in another timing measurement to decide whether beads have abnormally high latency or not. Remember that just due to the statistics of the Poisson distribution, large cohorts and excessive grandparents will naturally be generated some calculable fraction of the time, and doesn\u2019t represent a problem for the system or evidence of an attack. Adjusting the difficulty due to these infrequent large naturally-occurring cohorts biases the difficulty algorithm relative to the naive Nb/Nc=2.42 algorithm.</p>\n</blockquote>\n</aside>\n<p>I was adjusting the difficulty based on \u201cparents who were supposed to be grandparents\u201d only because the Parent DAA needed it.</p>\n<p>The statistical problem of accidentally not rewarding also applies if you use a hard 5 s limit: there could be a natural network delay and you don\u2019t want to enforce a 5 second limit if half the miners are having that kind of delay, or if they\u2019re unlucky and it\u2019s taking 5 s to find a solution. The only way to determine that you\u2019re not having either problem is to confirm there was a sufficient number of other blocks in that time. This is just a great grandparent check that might be able to be used instead. (The \u201cgreat grandparent method\u201d is not rewarding a block if he sees a parent that all his siblings see as a great grandparent.)  Are the timestamps needed or are both be useful?  The time limit check has false positives on slow blocks while the great grandparent method has false positives if they\u2019re too fast.</p>\n<p>Using a &gt;= great^4 grandparent rule never has a false positive if latency is a uniform distribution. This is at the 5 s level when median latency = 0.25 s.  If 10% of the hashrate has 4x the median, there\u2019s a false positive on 2% of their mined blocks.  At 10% with 10x latency, it\u2019s 15%. 10x latency is at 2.5 seconds so they aren\u2019t far from not meeting the 5 s limit. But 0.1% hashrate with 40x latency (10 s) has only 35% of it\u2019s blocks rejected. So a combination of the two methods might be good.</p>",
  "post_number": 18,
  "post_type": 1,
  "posts_count": 21,
  "updated_at": "2025-01-04T23:43:19.353Z",
  "reply_count": 0,
  "reply_to_post_number": 15,
  "quote_count": 3,
  "incoming_link_count": 2,
  "reads": 31,
  "readers_count": 30,
  "score": 16.2,
  "yours": false,
  "topic_id": 1331,
  "topic_slug": "fastest-possible-pow-via-simple-dag",
  "topic_title": "Fastest-possible PoW via Simple DAG",
  "topic_html_title": "Fastest-possible PoW via Simple DAG",
  "category_id": 7,
  "display_username": "Zawy",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 3,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"ajtowns, post:15, topic:1331\"]\nI think it would be interesting to analyse this both as a difficulty adjustment for a standalone consensus system [and for Braidpool]\n[/quote]\n\nThis is what I'm doing. Braidpool's specifics aren't on my mind yet.\n\n[quote=\"ajtowns, post:15, topic:1331\"]\nWith the same latency applying to a global braidpool, but an expected block rate of 100 blocks per ten minutes (10% hashrate at 1/1000th of the difficulty), then the expected \u201corphan\u201d rate is about 4%. Conversely, if you target an expected \u201corphan\u201d rate of 44%, with 10% hashrate, that means beads are 14,500 times easier than blocks, rather than 1000 times easier?\n[/quote]\nNb/Nc = 2.42 (approx parents = 1.44) results in solvetimes 2.9x mean latency if latency varies randomly from 0 to 2x the mean. It's independent of hashrate. It targets a solvetime in units of latency, but affected by latency distribution.  So if mean latency in a Braidpool = 0.5 seconds, block time is 1.45 s, 417 blocks in 600 s. At 10% hashrate, that's 4,000x easier. \n\nUsing 1-e^(-0.5/1.45), I get a 29.2% orphan rate for Nb/Nc = 2.42 and a uniformly random latency variation around that mean. This equation for orphan rate is approximate. There's a paper from way back that derives something precise. Looking at it another way, 1/2.42 is the fraction of blocks without any sibling according to any parents or children. If half the remaining 1.42 blocks would have been orphaned then 0.71/2.42 = 29.3% orphan rate. \n\n[quote=\"mcelrath, post:8, topic:1331\"]\nThe above idea is contrary to Zawy\u2019s suggestion to orphan high latency beads, I want to include them but not pay them.\n[/quote]\n\nTo me, \"not paying them\" = orphaning, whether or not they're included in the DAA calculation. \n\n[quote=\"ajtowns, post:15, topic:1331\"]\nI think/conjecture the look-back/latency constraints are probably critical for this approach\u2019s ability to come to consensus between subsets of hashrate with very different latency properties \u2013 the 200:1 latency ratio I suggested would (I think) make it difficult for the latest beads from the two groups to have sufficiently common ancestry that they get merged; whereas I\u2019d expect a 2:1 latency ratio to be more-or-less fine.\n[/quote]\n\nThe Nb/Nc DAA doesn't seem to have any problem with widely-varying latency. For example, if 5% have 200x longer latency, the solvetime per latency is still in the 2 to 3 range. The Nb/Nc DAA is pretty incredible at how well it handles topology and random variations in latency.\n\n[quote=\"mcelrath, post:12, topic:1331\"]\nI\u2019m fairly skeptical of using graph structure alone and the DAA here to handle high latency. High latency is already observed and accounted for using the Nc/Nb method (because high latency generates large cohorts). I don\u2019t want to create incentives for miners to do anything other than naming all known tips. So, I think we need to pull in another timing measurement to decide whether beads have abnormally high latency or not. Remember that just due to the statistics of the Poisson distribution, large cohorts and excessive grandparents will naturally be generated some calculable fraction of the time, and doesn\u2019t represent a problem for the system or evidence of an attack. Adjusting the difficulty due to these infrequent large naturally-occurring cohorts biases the difficulty algorithm relative to the naive Nb/Nc=2.42 algorithm.\n[/quote]\n\nI was adjusting the difficulty based on \"parents who were supposed to be grandparents\" only because the Parent DAA needed it. \n\nThe statistical problem of accidentally not rewarding also applies if you use a hard 5 s limit: there could be a natural network delay and you don't want to enforce a 5 second limit if half the miners are having that kind of delay, or if they're unlucky and it's taking 5 s to find a solution. The only way to determine that you're not having either problem is to confirm there was a sufficient number of other blocks in that time. This is just a great grandparent check that might be able to be used instead. (The \"great grandparent method\" is not rewarding a block if he sees a parent that all his siblings see as a great grandparent.)  Are the timestamps needed or are both be useful?  The time limit check has false positives on slow blocks while the great grandparent method has false positives if they're too fast. \n\nUsing a >= great^4 grandparent rule never has a false positive if latency is a uniform distribution. This is at the 5 s level when median latency = 0.25 s.  If 10% of the hashrate has 4x the median, there's a false positive on 2% of their mined blocks.  At 10% with 10x latency, it's 15%. 10x latency is at 2.5 seconds so they aren't far from not meeting the 5 s limit. But 0.1% hashrate with 40x latency (10 s) has only 35% of it's blocks rejected. So a combination of the two methods might be good.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 502,
  "hidden": false,
  "trust_level": 2,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "This is what I\u2019m doing. Braidpool\u2019s specifics aren\u2019t on my mind yet. \n\nNb/Nc = 2.42 (approx parents = 1.44) results in solvetimes 2.9x mean latency if latency varies randomly from 0 to 2x the mean. It\u2019s independent of hashrate. It targets a solvetime in units of latency, but affected by latency dis&hellip;",
  "truncated": true,
  "post_url": "/t/fastest-possible-pow-via-simple-dag/1331/18",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}