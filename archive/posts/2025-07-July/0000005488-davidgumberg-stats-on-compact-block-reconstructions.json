{
  "id": 5488,
  "name": "David Gumberg",
  "username": "davidgumberg",
  "avatar_template": "/user_avatar/delvingbitcoin.org/davidgumberg/{size}/378_2.png",
  "created_at": "2025-07-15T23:51:00.050Z",
  "cooked": "<blockquote>\n<p>An interactive/modifiable version of all the data and plots are in a jupyter notebook here: <a href=\"https://davidgumberg.github.io/logkicker/lab/index.html?path=2025-07-11-first-report%2FPrefilling.ipynb\" rel=\"noopener nofollow ugc\">https://davidgumberg.github.io/logkicker/lab/index.html?path=2025-07-11-first-report%2FPrefilling.ipynb</a></p>\n</blockquote>\n<h1><a name=\"p-5488-summary-1\" class=\"anchor\" href=\"#p-5488-summary-1\"></a>Summary</h1>\n<p>I connected two Bitcoin Core nodes running on mainnet, one prefilling transactions to a node that only received <code>CMPCTBLOCK</code> announcements from its prefilling peer. Even though the intended effects of prefilling transactions are network-wide, and it would be nice to have some more complicated topologies and scenarios tested in e.g. <a href=\"https://github.com/bitcoin-dev-project/warnet\" rel=\"noopener nofollow ugc\">Warnet</a>, this basic setup can be used to validate some of the basic assumptions of the effects of prefilling:</p>\n<ol>\n<li>Does prefilling work to prevent failed block reconstructions that otherwise require <code>GETBLOCKTXN-&gt;BLOCKTXN</code> roundtrips, irrespective of the cost of prefilling?</li>\n<li>Does prefilling result in a net reduction on block propagation times?</li>\n</ol>\n<p>The results indicate that the answer to 1. is definitively yes. The metric used by <a href=\"https://github.com/0xB10C/bitcoin/commits/2025-03-prefill-compactblocks/\" rel=\"noopener nofollow ugc\">0xB10C/2025-03-prefill-compactblocks</a> of prefilling the transactions we were missing from our mempool when performing block reconstruction resulted in an observed reconstruction rate of 98.25% for a node receiving prefilled CMPCTBLOCK announcements when both the prefilling node and the prefill-receiving node are running similar builds of Bitcoin Core, compared to the observed reconstruction rate on a node not receiving prefilled blocks of of 61.81%. Some of those prefills, as pointed out by <a class=\"mention\" href=\"/u/crypt-iq\">@Crypt-iQ</a> and <a class=\"mention\" href=\"/u/gmaxwell\">@gmaxwell</a>  above, exceeded the TCP window, and likely resulted in an additional round-trip, negating the benefit of prefilling. But, in my measurements, 85.78% of the prefills would have fit in the partially occupied TCP window a prefilling node sent the <code>CMPCTBLOCK</code>\u2019s in. Projecting out, these measurements indicate that if all Bitcoin Core nodes had been prefilling during the period which I measured data, the reconstruction rate would have been 93.07% and we can likely do better taking advantage of the fact, pointed out by <a class=\"mention\" href=\"/u/andrewtoth\">@andrewtoth</a> <a href=\"https://delvingbitcoin.org/t/stats-on-compact-block-reconstructions/1052/25\">above</a> that similar peers will likely have similar <code>vExtraTxn</code>.</p>\n<p>I think the following improvements should be made to <a href=\"https://github.com/0xB10C/bitcoin/commits/2025-03-prefill-compactblocks/\" rel=\"noopener nofollow ugc\">0xB10C/2025-03-prefill-compactblocks</a>:</p>\n<h5><a name=\"p-5488-definitely-2\" class=\"anchor\" href=\"#p-5488-definitely-2\"></a>Definitely:</h5>\n<ul>\n<li>Only prefill up to the next TCP window boundary.</li>\n<li>Always insert candidates from <code>vExtraTxn</code> last.</li>\n</ul>\n<h5><a name=\"p-5488-maybe-3\" class=\"anchor\" href=\"#p-5488-maybe-3\"></a>Maybe:</h5>\n<ul>\n<li>Within DoS limits (maybe a limit of 4 MiB per valid header), temporarily store a per-block cache of prefilled transactions you hear about, increasing the chances that you successfully reconstruct without having to wait for an RTT.</li>\n<li>If the send window can\u2019t fit all of the prefill candidates, prefill a random selection of candidates, always prefilling transactions not in <code>vExtraTxn</code> first.</li>\n</ul>\n<p>Future investigations should:</p>\n<ol>\n<li>Use prefill-receiving nodes to measure the amount of duplicate / redundant data in the prefill.</li>\n<li>Use two peers with stable and high (maybe artificial?) latencies to easily estimate the number of round-trips that messages take to pass between them, there is also probably external tooling that can measure this.</li>\n<li>Measure / reason about effects of prefilling at a distance of more than one hop.</li>\n<li>Measure data about the <code>GETBLOCKTXN</code> messages that a prefilling node receives from random peers.</li>\n</ol>\n<h1><a name=\"p-5488-latency-and-bandwidth-4\" class=\"anchor\" href=\"#p-5488-latency-and-bandwidth-4\"></a>Latency and Bandwidth</h1>\n<p><strong>Feel free to skip the math in this section or to <a href=\"#Observations\">skip</a> reading this section entirely.</strong></p>\n<p>Taking a simplified view, the latency for a receiver to hear an unsolicited message (the scenario we care about in block relay) consists of\ntransmission delay plus propagation delay:</p>\n<div class=\"math\">\n\\text{Latency} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}} * \\text{Round-trip time}\n</div>\n<p>Any time compact block reconstruction fails because the receiver was missing transactions, an additional round-trip-time (RTT) of requesting missing transactions and receiving them (<code>GETBLOCKTXN-&gt;BLOCKTXN</code>) must be paid in order to complete reconstruction, but at this point the amount of data that needs to be transmitted for reconstruction to succeed does not change. Where <span class=\"math\">f</span> is the probability for a block to fail reconstruction:</p>\n<div class=\"math\">\n\\text{Latency} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}}\\text{RTT} + f * \\text{RTT}\n</div>\n<p>If we had perfect information about the transactions our peer will be missing, we should always send these along with the block announcements since we will pay basically the same transmission delay, minus the unnecessary round-trip. If we don\u2019t have perfect information, then the worst we can do is send transactions which our peer already knew about, while not sending them transactions they didn\u2019t know about, incurring the RTT anyways, plus the transmission time of the redundant data. Let\u2019s say we send <span class=\"math\">p</span> extra prefill bytes, with each byte having a probability <span class=\"math\">n</span> of being redundant and prefilling <span class=\"math\">p</span> bytes gets us a reconstruction failure probability of <span class=\"math\">f_{p}</span>, then:</p>\n<div class=\"math\">\n\\text{Latency}_\\text{Prefilling} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\frac{p * n}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}}\\text{RTT} + f_p * \\text{RTT}\n</div>\n<h2><a name=\"p-5488-criterion-for-deciding-if-prefilling-is-advantageous-5\" class=\"anchor\" href=\"#p-5488-criterion-for-deciding-if-prefilling-is-advantageous-5\"></a>Criterion for deciding if prefilling is advantageous</h2>\n<p>In order for prefilling latency to be better than or equal to no-prefilling latency, the following inequality must be satisfied:</p>\n<div class=\"math\">\n\\frac{p * n}{\\text{Bandwidth}*\\text{RTT}} \\leq f_0 - f_p\n</div>\n<details>\n<summary> \n<h4><a name=\"p-5488-derivation-6\" class=\"anchor\" href=\"#p-5488-derivation-6\"></a>Derivation</h4>\n</summary>\n<p>If latency while prefilling is less than or equal to latency without prefilling, where <span class=\"math\">b</span> is bandwidth, <span class=\"math\">r</span> is the RTT, <span class=\"math\">d</span> is the size of the CMPCTBLOCK without prefill, <span class=\"math\">p</span> is the size of the prefill, and <span class=\"math\">f_p</span> is the reconstruction failure rate at a given prefill size <span class=\"math\">p</span>:</p>\n<div class=\"math\">\n\\frac{d}{b} + \\frac{pn}{b} + \\frac{1}{2}r + {f_p}{r} \\leq \\frac{d}{b} + \\frac{1}{2}r + {f_0}{r}\n</div>\n<p>Subtracting the common terms <span class=\"math\">\\frac{d}{b}</span> and <span class=\"math\">\\frac{1}{2}r</span> from both sides:</p>\n<div class=\"math\">\n\\frac{pn}{b} + {f_p}{r} \\leq {f_0}{r}\n</div>\n<p>Subtracting <span class=\"math\">{f_p}{r}</span> from both sides:</p>\n<div class=\"math\">\n\\frac{pn}{b} \\leq {f_0}{r} - {f_p}{r}\n</div>\n<p>Dividing both sides by <span class=\"math\">r</span>:</p>\n<div class=\"math\">\n\\frac{pn}{{b} {r}} \\leq {f_0} - {f_p}\n</div>\n</details>\n<p>If we plug in some example values, prefilling 10KiB with a bandwidth of 5 MiB/s and an RTT of 50ms (.050s) and use a worst case <span class=\"math\">n</span> of 1</p>\n<div class=\"math\">\n\\frac{10\\text{KiB}*1}{5 \\text{MiB/s} * 0.050\\text{s}} = 0.039\n</div>\n<p>In this case, if prefilling improves reconstruction rates by at least 3.9% it is definitely better than not prefilling.</p>\n<h2><a name=\"p-5488-latency-cost-of-prefilling-7\" class=\"anchor\" href=\"#p-5488-latency-cost-of-prefilling-7\"></a>Latency Cost of Prefilling</h2>\n<p>And we can quantify the latency cost of prefilling over not prefilling as:</p>\n<div class=\"math\">\n\\text{Latency}_\\text{Prefilling} - \\text{Latency}_\\text{Not prefilling} = \\frac{p*n}{\\text{Bandwidth}} - r(f_0 - f_p)\n</div>\n<h2><a name=\"p-5488-tcp-windows-and-the-costs-of-prefilling-8\" class=\"anchor\" href=\"#p-5488-tcp-windows-and-the-costs-of-prefilling-8\"></a>TCP windows and the costs of prefilling.</h2>\n<p>But, the use of TCP in the Bitcoin P2P protocol complicates this, because a sender will not send data exceeding the TCP window size in a single round-trip. Instead, they will send up to the window size in data, wait for an <code>ACK</code> from the receiver, and then send up to <code>window</code> bytes after the data which was <code>ACK</code>ed. That means that if we exceed a single TCP window, we will have to pay an additional RTT in propagation latency (and a little bit of transmission latency for the overhead). And for each additional window we overflow, we will pay another RTT:</p>\n<div class=\"math\">\n\\text{TCP Latency} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}}\\text{RTT} + f * \\text{RTT} + \\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor\\text{RTT}\n</div>\n<p>Note <span class=\"math\">\\lfloor a \\rfloor</span> meaning <code>std::floor(a)</code></p>\n<p>Doing a similar dance as above, where <span class=\"math\">p</span> is the prefill size and <span class=\"math\">f_p</span> is the probability of reconstruction failure at prefill size <span class=\"math\">p</span>, and <span class=\"math\">n</span> is the probability of a prefill byte being redundant:</p>\n<div class=\"math\">\n\\frac{p*n}{\\text{Bandwidth}*\\text{RTT}} \\leq f_0 - f_p + \\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor - \\lfloor{\\frac{\\text{Data}+p}{\\text{Window Size}}}\\rfloor\n</div>\n<p>The \u201cTCP window\u201d is the smaller of two values: the receiver advertised window (<code>rwnd</code>) and the sender-calculated congestion window (<code>cwnd</code>).</p>\n<h3><a name=\"p-5488-overflowing-current-tcp-window-is-always-worse-than-doing-nothing-9\" class=\"anchor\" href=\"#p-5488-overflowing-current-tcp-window-is-always-worse-than-doing-nothing-9\"></a>Overflowing current TCP window is always worse than doing nothing</h3>\n<p>The above formula establishes as a rule something which might have been intuited, that if the prefill causes us to exceed the current TCP window, then we will always do worse than if we hadn\u2019t prefilled, since:</p>\n<ol>\n<li><span class=\"math\">f_0 - f_p \\leq 1</span> since the smallest number <span class=\"math\">f_0</span> can be is 0, and the largest number <span class=\"math\">f_p</span> can be is 1.</li>\n<li><span class=\"math\">\\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor - \\lfloor{\\frac{\\text{Data}+p}{\\text{Window Size}}}\\rfloor \\leq -1</span> if the prefill overflows the current partially filled TCP window.</li>\n<li>If <span class=\"math\">a \\leq 1</span> and <span class=\"math\">b \\leq -1</span>, then <span class=\"math\">a + b \\leq 0</span>, so the right hand side of the formula is <span class=\"math\">\\leq 0</span>.</li>\n<li>The left hand side of the equation will always be <span class=\"math\">\\geq 0</span>, since none of the variables on the left side can ever be negative.</li>\n<li>If <span class=\"math\">lhs \\geq 0</span> and <span class=\"math\">0 \\geq rhs</span>, then <span class=\"math\">lhs \\geq rhs</span>, so the left hand side will never be less than the right hand side, therefore prefilling will never be beneficial.</li>\n</ol>\n<p>But, if we bound our prefill <span class=\"math\">p</span> so that we never increase the number of TCP windows used, i.e.: <span class=\"math\">\\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor - \\lfloor{\\frac{\\text{Data}+p}{\\text{Window Size}}}\\rfloor = 0</span> which, I believe is <a href=\"https://delvingbitcoin.org/t/stats-on-compact-block-reconstructions/1052/29\">easy</a> to do, we can use the exact same formula as above to decide whether or not prefilling is effective:</p>\n<div class=\"math\">\n\\frac{p * n}{\\text{Bandwidth}*\\text{RTT}} \\leq f_0 - f_p\n</div>\n<h3><a name=\"p-5488-complication-tcp-retransmission-10\" class=\"anchor\" href=\"#p-5488-complication-tcp-retransmission-10\"></a>Complication: TCP Retransmission</h3>\n<p>So far, I have assumed perfectly reliable networks and this isn\u2019t always the case, packets get lost, and in TCP that means waiting for a timeout, and then retransmitting. But, I believe the problem above I\u2019ve described in relation to prefilling is very similar to the problem that the designers of TCP had in selecting a static window size, and later, dynamic window sizes through congestion control algorithms like those described in <a href=\"https://datatracker.ietf.org/doc/html/rfc5681\" rel=\"noopener nofollow ugc\">RFC 5681</a> and <a href=\"https://datatracker.ietf.org/doc/html/rfc9438\" rel=\"noopener nofollow ugc\">RFC 9438</a>. Instead of the probability that a block reconstruction will fail, they deal with the probability that a packet will not arrive, in both cases, the consequence is an additional round-trip, and a core question is whether the marginal value of potentially saving a round-trip by packing in more data is worth the risk that retransmission will be necessary anyways. The analogy is imperfect, as there are many more concerns that TCP congestion control algorithms deal with, but I argue that the node can outsource the question: \u201cHow large of a message can we send and reasonably expect everything to arrive?\u201d to its operating system\u2019s congestion control implementation.</p>\n<h3><a name=\"p-5488-complication-cost-of-bandwidth-11\" class=\"anchor\" href=\"#p-5488-complication-cost-of-bandwidth-11\"></a>Complication: Cost of Bandwidth</h3>\n<p>In all of the above, I have assumed the cost of using bandwidth is 0 outside of the latency cost. I\u2019ve done this because I believe the cost of the redundant transactions sent in compact block prefills is negligible, the data I measured below suggests that prefills will be on the order of ~20KiB, so worst case monthly bandwidth usage of prefilling, assuming every byte is redundant and did not need to be sent, and that you always receive a prefilled CMPCTBLOCK from three HB peers, is ~300 MiB. (3 HB Peers * 20 KiB * 6 * 24 * 31)</p>\n<h2><a name=\"p-5488-takeaways-12\" class=\"anchor\" href=\"#p-5488-takeaways-12\"></a>Takeaways</h2>\n<p>I don\u2019t think proving that the above inequality being satisfied is necessary for a prefilling solution, what I think it\u2019s useful for is building an intuition of the problem, and setting theoretical boundaries on how effective prefilling needs to be to be worth it.</p>\n<ul>\n<li>Nodes are likelier to suffer rather than benefit from prefilling that have smaller <span class=\"math\">Bandwidth * RTT</span> (See <a href=\"https://en.wikipedia.org/wiki/Bandwidth-delay_product\" rel=\"noopener nofollow ugc\">Bandwidth-delay product (BDP)</a>) connections: e.g. nodes with low bandwidth and low ping. And nodes that have connections with large BDP\u2019s are likelier to benefit, e.g. high-bandwidth, high-latency connections(\u201cLong Fat Networks\u201d as described in <a href=\"https://datatracker.ietf.org/doc/html/rfc7323#section-1.1\" rel=\"noopener nofollow ugc\">RFC 7323</a>)</li>\n<li>If the redundant broadcast probability <span class=\"math\">n</span> is zero, prefilling is always worth it.</li>\n</ul>\n<h1><a name=\"p-5488-data-13\" class=\"anchor\" href=\"#p-5488-data-13\"></a>Data</h1>\n<p>The data was all taken from <code>debug.log</code>\u2019s generated by the nodes and parsed with this python script: <a href=\"https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/logsparser.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">logkicker/compactblocks/logsparser.py at 285034d6833e34dfcb058ce37b30affede0333be \u00b7 davidgumberg/logkicker \u00b7 GitHub</a></p>\n<ul>\n<li>Statistics: <a href=\"https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/stats.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">logkicker/compactblocks/stats.py at 285034d6833e34dfcb058ce37b30affede0333be \u00b7 davidgumberg/logkicker \u00b7 GitHub</a></li>\n<li>Plots: <a href=\"https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/plots.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">logkicker/compactblocks/plots.py at 285034d6833e34dfcb058ce37b30affede0333be \u00b7 davidgumberg/logkicker \u00b7 GitHub</a></li>\n</ul>\n<p>CSV\u2019s from the data collected can be found here: <a href=\"https://github.com/davidgumberg/logkicker/tree/main/compactblocks/2025-07-11-first-report\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">logkicker/compactblocks/2025-07-11-first-report at main \u00b7 davidgumberg/logkicker \u00b7 GitHub</a></p>\n<ul>\n<li>Statistics: <a href=\"https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/stats.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">logkicker/compactblocks/stats.py at 285034d6833e34dfcb058ce37b30affede0333be \u00b7 davidgumberg/logkicker \u00b7 GitHub</a></li>\n<li>Plots: <a href=\"https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/plots.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">logkicker/compactblocks/plots.py at 285034d6833e34dfcb058ce37b30affede0333be \u00b7 davidgumberg/logkicker \u00b7 GitHub</a></li>\n</ul>\n<h2><a name=\"p-5488-summary-14\" class=\"anchor\" href=\"#p-5488-summary-14\"></a>Summary</h2>\n<p>The node receiving not prefilled blocks had a reconstruction rate of 61.81%, the node receiving prefilled blocks had a reconstruction rate of 98.25%, but only 85.78% of those would have fit in the current TCP window of the CMPCTBLOCK being announced, so projecting from those two figures, 93.07% of blocks could have been reconstructed without an additional TCP round trip. The vast majority of TCP windows observed were around ~15KiB. For a lot of the data around prefills, the averages are massive because of a few extreme outliers, but the vast majority of the time, a very small amount of prefill data is needed to prevent a <code>GETBLOCKTXN-&gt;BLOCKTXN</code> round trip, 65% of blocks observed needed 1KiB or less of prefill.</p>\n<h2><a name=\"p-5488-prefill-receiving-node-stats-on-cmpctblocks-received-15\" class=\"anchor\" href=\"#p-5488-prefill-receiving-node-stats-on-cmpctblocks-received-15\"></a>Prefill-Receiving Node: stats on CMPCTBLOCK\u2019s received</h2>\n<p>This data was gathered from a node configured so that it would only receive CMPCTBLOCK announcements from our prefilling node, the main thing to see here is that reconstruction generally succeeds, the average reconstruction time metric is misleading, since we don\u2019t count extra RTT\u2019s that happen in the TCP layer in reconstruction time, just the time we receive the <code>CMPCTBLOCK</code> until the time we have reconstructed it.</p>\n<pre><code class=\"lang-auto\">49 out of 2793 blocks received failed reconstruction. (1.75%)\nReconstruction rate was 98.25%\nAvg size of received block: 55851.93 bytes\nAvg bytes missing from received blocks: 603.40 bytes\nAvg bytes missing from blocks that failed reconstruction: 34393.55 bytes\nAvg reconstruction time: 7.821697ms\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/3/36f78c8b30be7324787469c3942c822c5fdc9e7c.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/36f78c8b30be7324787469c3942c822c5fdc9e7c\" title=\"Figure 1a\"><img src=\"https://delvingbitcoin.org/uploads/default/optimized/2X/3/36f78c8b30be7324787469c3942c822c5fdc9e7c_2_690x344.png\" alt=\"Figure 1a\" data-base62-sha1=\"7Qg9ACyfr129UFUHmzHLe1D7Weo\" width=\"690\" height=\"344\" srcset=\"https://delvingbitcoin.org/uploads/default/optimized/2X/3/36f78c8b30be7324787469c3942c822c5fdc9e7c_2_690x344.png, https://delvingbitcoin.org/uploads/default/original/2X/3/36f78c8b30be7324787469c3942c822c5fdc9e7c.png 1.5x, https://delvingbitcoin.org/uploads/default/original/2X/3/36f78c8b30be7324787469c3942c822c5fdc9e7c.png 2x\" data-dominant-color=\"F7F8F9\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 1a</span><span class=\"informations\">1000\u00d7499 22.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/5/503c0e36a1f3b3db5373d2d8abe448d33e500dd3.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/503c0e36a1f3b3db5373d2d8abe448d33e500dd3\" title=\"Figure 1b\"><img src=\"https://delvingbitcoin.org/uploads/default/optimized/2X/5/503c0e36a1f3b3db5373d2d8abe448d33e500dd3_2_690x346.png\" alt=\"Figure 1b\" data-base62-sha1=\"brMRGTdFTnYB8Rv5sqntWzi5FeP\" width=\"690\" height=\"346\" srcset=\"https://delvingbitcoin.org/uploads/default/optimized/2X/5/503c0e36a1f3b3db5373d2d8abe448d33e500dd3_2_690x346.png, https://delvingbitcoin.org/uploads/default/original/2X/5/503c0e36a1f3b3db5373d2d8abe448d33e500dd3.png 1.5x, https://delvingbitcoin.org/uploads/default/original/2X/5/503c0e36a1f3b3db5373d2d8abe448d33e500dd3.png 2x\" data-dominant-color=\"FBFBFB\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 1b</span><span class=\"informations\">1000\u00d7502 26.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<h2><a name=\"p-5488-prefilling-node-stats-on-cmpctblocks-received-16\" class=\"anchor\" href=\"#p-5488-prefilling-node-stats-on-cmpctblocks-received-16\"></a>Prefilling Node: stats on CMPCTBLOCK\u2019s received</h2>\n<p>This data was gathered from the node that sends prefilled compact blocks to its peers. Because this node is otherwise unmodified, we can use its measurements on the receiving side as a baseline for block reconstruction on nodes today.</p>\n<pre><code class=\"lang-auto\">1101 out of 2883 blocks received failed reconstruction. (38.19%)\nReconstruction rate was 61.81%\nAvg size of received block: 15957.20 bytes\nAvg bytes missing from received blocks: 47849.36 bytes\nAvg bytes missing from blocks that failed reconstruction: 125294.91 bytes\nAvg reconstruction time: 25.741588ms\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/0/0e968d26fdcfb0bfbb9efcc6ef8b0f286bfa8004.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/0e968d26fdcfb0bfbb9efcc6ef8b0f286bfa8004\" title=\"Figure 2\"><img src=\"https://delvingbitcoin.org/uploads/default/original/2X/0/0e968d26fdcfb0bfbb9efcc6ef8b0f286bfa8004.png\" alt=\"Figure 2\" data-base62-sha1=\"253eQl15AmXesNwzMf6qiehdygQ\" width=\"640\" height=\"480\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 2</span><span class=\"informations\">640\u00d7480 25.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/d/d782f73b39d34627004bd62a1a73d114f0bdf710.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/d782f73b39d34627004bd62a1a73d114f0bdf710\" title=\"Figure 3a\"><img src=\"https://delvingbitcoin.org/uploads/default/optimized/2X/d/d782f73b39d34627004bd62a1a73d114f0bdf710_2_690x343.png\" alt=\"Figure 3a\" data-base62-sha1=\"uKvfr1FkC8SU5dXCBdkDI5wD0yI\" width=\"690\" height=\"343\" srcset=\"https://delvingbitcoin.org/uploads/default/optimized/2X/d/d782f73b39d34627004bd62a1a73d114f0bdf710_2_690x343.png, https://delvingbitcoin.org/uploads/default/original/2X/d/d782f73b39d34627004bd62a1a73d114f0bdf710.png 1.5x, https://delvingbitcoin.org/uploads/default/original/2X/d/d782f73b39d34627004bd62a1a73d114f0bdf710.png 2x\" data-dominant-color=\"F6F7F7\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 3a</span><span class=\"informations\">1000\u00d7498 21.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/7/7e404b61486ae96c3fe1c9d46a4154c84ef14ef0.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/7e404b61486ae96c3fe1c9d46a4154c84ef14ef0\" title=\"Figure 3b\"><img src=\"https://delvingbitcoin.org/uploads/default/optimized/2X/7/7e404b61486ae96c3fe1c9d46a4154c84ef14ef0_2_690x347.png\" alt=\"Figure 3b\" data-base62-sha1=\"i0RUvPGCCAC1cYh6Hqh5xPObOx2\" width=\"690\" height=\"347\" srcset=\"https://delvingbitcoin.org/uploads/default/optimized/2X/7/7e404b61486ae96c3fe1c9d46a4154c84ef14ef0_2_690x347.png, https://delvingbitcoin.org/uploads/default/original/2X/7/7e404b61486ae96c3fe1c9d46a4154c84ef14ef0.png 1.5x, https://delvingbitcoin.org/uploads/default/original/2X/7/7e404b61486ae96c3fe1c9d46a4154c84ef14ef0.png 2x\" data-dominant-color=\"F8F9F9\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 3b</span><span class=\"informations\">1000\u00d7503 53.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<h3><a name=\"p-5488-tcp-window-data-17\" class=\"anchor\" href=\"#p-5488-tcp-window-data-17\"></a>TCP Window data</h3>\n<p>There is a flaw in the window available bytes metric I have used, pointed out to me by <a class=\"mention\" href=\"/u/hodlinator\">@hodlinator</a>, which is that I only did <code>window_size - cmpctblock_size</code>, and did not factor existing bytes queued to send to peers in <code>vSendMsg</code>. I anticipate this will have a small effect, but a branch which prefills up to the TCP window limit should take this into account.</p>\n<p><strong>Edit:</strong></p>\n<p><a class=\"mention\" href=\"/u/andrewtoth\">@andrewtoth</a> has pointed out more complications in the available bytes metric: it will also have to take into account the current in-flight segments to the peer. On Linux, for example, this is <a href=\"https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/tcp.h#L244\" rel=\"noopener nofollow ugc\"><code>tcpi_unacked</code></a> (Multiplied by  <a href=\"https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/tcp.h#L241\" rel=\"noopener nofollow ugc\"><code>tcpi_snd_mss</code></a> to get size in bytes). It will also have to account for bytes that are in the operating system\u2019s send queue (<a href=\"https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/tcp.h#L278\" rel=\"noopener nofollow ugc\"><code>tcpi_notsent_bytes</code></a>). But I believe that because Bitcoin Core <a href=\"https://github.com/bitcoin/bitcoin/pull/6867\" rel=\"noopener nofollow ugc\">uses</a> <code>TCP_NODELAY</code> the OS send buffer should generally be empty. On Linux, the sum of these two values can be obtained with <code>SIOCOUTQ</code><sup class=\"footnote-ref\"><a href=\"#footnote-5488-1\" id=\"footnote-ref-5488-1\">[1]</a></sup>:</p>\n<pre data-code-wrap=\"c\"><code class=\"lang-c\">int bytes_inflight_and_unsent, err;\nerr = ioctl(socket, SIOCOUTQ, &amp;bytes_inflight_and_unsent)\n</code></pre>\n<p>I found this article helpful: <a href=\"https://tiebing.blogspot.com/2019/05/tcp-socket-send-buffer-deep-dive.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Journey of Life: TCP socket send buffer deep dive</a> (<a href=\"https://web.archive.org/web/20250716165959/https://tiebing.blogspot.com/2019/05/tcp-socket-send-buffer-deep-dive.html\" rel=\"noopener nofollow ugc\">archive link</a>)</p>\n<pre><code class=\"lang-auto\">TCP Window Size: Avg: 16128.76 bytes, Median: 14480.0, Mode: 14480\nThe mode represented 13076/26392 windows. (49.55%)\nAvg. TCP window bytes used: 7449.62 bytes\nAvg. TCP window bytes available: 8679.14 bytes\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/3/33a2065dd97c7908a55f22224818fd88487b8343.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/33a2065dd97c7908a55f22224818fd88487b8343\" title=\"Figure 4\"><img src=\"https://delvingbitcoin.org/uploads/default/original/2X/3/33a2065dd97c7908a55f22224818fd88487b8343.png\" alt=\"Figure 4\" data-base62-sha1=\"7mLueCA5voJgqidteSvgsOYmRYn\" width=\"640\" height=\"480\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 4</span><span class=\"informations\">640\u00d7480 18.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<h2><a name=\"p-5488-prefilling-node-stats-on-cmpctblocks-sent-18\" class=\"anchor\" href=\"#p-5488-prefilling-node-stats-on-cmpctblocks-sent-18\"></a>Prefilling node: stats on CMPCTBLOCK\u2019s sent</h2>\n<pre><code class=\"lang-auto\">The average CMPCTBLOCK we sent was 65732.80 bytes.\nThe average prefilled CMPCTBLOCK we sent was 91614.48 bytes.\nThe average not-prefilled CMPCTBLOCK we sent was 14483.78 bytes.\n17536/26392 blocks were sent with prefills. (66.44%)\nAvg available prefill bytes for all CMPCTBLOCK's we sent: 8679.14 bytes\nAvg available prefill bytes for prefilled CMPCTBLOCK's we sent: 8362.04 bytes\nAvg total prefill size for CMPCTBLOCK's we prefilled: 74593.04 bytes\n15042/17536 prefilled blocks sent fit in the available bytes. (85.78%)\n</code></pre>\n<p>The average prefill size is notably large, but this is a consequence of some outlier blocks.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/5/54cf3c52cfb703edf43d5765f6add18a1bdb1677.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/54cf3c52cfb703edf43d5765f6add18a1bdb1677\" title=\"Figure 5a\"><img src=\"https://delvingbitcoin.org/uploads/default/optimized/2X/5/54cf3c52cfb703edf43d5765f6add18a1bdb1677_2_690x273.png\" alt=\"Figure 5a\" data-base62-sha1=\"c6g6GtT1abGvQoJ2lIwvub20hyT\" width=\"690\" height=\"273\" srcset=\"https://delvingbitcoin.org/uploads/default/optimized/2X/5/54cf3c52cfb703edf43d5765f6add18a1bdb1677_2_690x273.png, https://delvingbitcoin.org/uploads/default/original/2X/5/54cf3c52cfb703edf43d5765f6add18a1bdb1677.png 1.5x, https://delvingbitcoin.org/uploads/default/original/2X/5/54cf3c52cfb703edf43d5765f6add18a1bdb1677.png 2x\" data-dominant-color=\"F9F9FA\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 5a</span><span class=\"informations\">1000\u00d7397 27.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://delvingbitcoin.org/uploads/default/original/2X/6/65f67128f3b57f9993f1a722a5f910f3fda223d8.png\" data-download-href=\"https://delvingbitcoin.org/uploads/default/65f67128f3b57f9993f1a722a5f910f3fda223d8\" title=\"Figure 5b\"><img src=\"https://delvingbitcoin.org/uploads/default/optimized/2X/6/65f67128f3b57f9993f1a722a5f910f3fda223d8_2_690x277.png\" alt=\"Figure 5b\" data-base62-sha1=\"ey0dTyUOAHoq9LQgvDcgLitDyhq\" width=\"690\" height=\"277\" srcset=\"https://delvingbitcoin.org/uploads/default/optimized/2X/6/65f67128f3b57f9993f1a722a5f910f3fda223d8_2_690x277.png, https://delvingbitcoin.org/uploads/default/original/2X/6/65f67128f3b57f9993f1a722a5f910f3fda223d8.png 1.5x, https://delvingbitcoin.org/uploads/default/original/2X/6/65f67128f3b57f9993f1a722a5f910f3fda223d8.png 2x\" data-dominant-color=\"EDF1F4\"><div class=\"meta\"><svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Figure 5b</span><span class=\"informations\">1000\u00d7402 27.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg></div></a></div></p>\n<h3><a name=\"p-5488-vextratxnforcompact-19\" class=\"anchor\" href=\"#p-5488-vextratxnforcompact-19\"></a><code>vExtraTxnForCompact</code></h3>\n<p>But, we can probably do even better, since the above statistics are for prefilling <em>with</em> all of the transactions in <code>vExtraTxnForCompactBlock</code>, and as I understand, it is very likely for peers running the same branch of Bitcoin Core to have a similar <code>vExtraTxnForCompactBlock</code>\u2019s to one another. So it is likely that reconstruction will often succeed even without these transactions, so they should be the first candidates for not being included in the prefill. Unfortunately, their size is not something that Bitcoin Core logs, although I tried to compute it with a heuristic: <code>prefill_size - missing_txns_we_requested_size</code>, but it turned out this was very incorrect.</p>\n<h3><a name=\"p-5488-overflowing-window-before-pre-fill-20\" class=\"anchor\" href=\"#p-5488-overflowing-window-before-pre-fill-20\"></a>Overflowing window before pre-fill.</h3>\n<p>Interestingly, some compact blocks were already so large <em>before</em> prefilling that they required more than one TCP round-trip to be sent, while this circumstance is not ideal, prefilling performs better by taking advantage of this.</p>\n<pre><code class=\"lang-auto\">1432/26392 CMPCTBLOCK's sent were already over the window for a single RTT before prefilling. (5.43%)\nAvg. available bytes for prefill in blocks that were already over a single RTT: 8555.57 bytes\n1432/1432 excessively large blocks had prefills that fit. (100.00%)\n</code></pre>\n<hr class=\"footnotes-sep\">\n\n<ol class=\"footnotes-list\">\n<li id=\"footnote-5488-1\" class=\"footnote-item\"><p><code>man tcp</code> incorrectly documents <code>SIOCOUTQ</code> as only the unsent bytes, but it\u2019s <a href=\"https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/sockios.h#L27\" rel=\"noopener nofollow ugc\">both unsent and unacked</a> <a href=\"#footnote-ref-5488-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>",
  "post_number": 34,
  "post_type": 1,
  "posts_count": 42,
  "updated_at": "2025-07-16T17:24:20.751Z",
  "reply_count": 0,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 168,
  "reads": 68,
  "readers_count": 67,
  "score": 963.6,
  "yours": false,
  "topic_id": 1052,
  "topic_slug": "stats-on-compact-block-reconstructions",
  "topic_title": "Stats on compact block reconstructions",
  "topic_html_title": "Stats on compact block reconstructions",
  "category_id": 7,
  "display_username": "David Gumberg",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 6,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "> An interactive/modifiable version of all the data and plots are in a jupyter notebook here: [https://davidgumberg.github.io/logkicker/lab/index.html?path=2025-07-11-first-report%2FPrefilling.ipynb](https://davidgumberg.github.io/logkicker/lab/index.html?path=2025-07-11-first-report%2FPrefilling.ipynb)\n\n# Summary\n\nI connected two Bitcoin Core nodes running on mainnet, one prefilling transactions to a node that only received `CMPCTBLOCK` announcements from its prefilling peer. Even though the intended effects of prefilling transactions are network-wide, and it would be nice to have some more complicated topologies and scenarios tested in e.g. [Warnet](https://github.com/bitcoin-dev-project/warnet), this basic setup can be used to validate some of the basic assumptions of the effects of prefilling:\n1. Does prefilling work to prevent failed block reconstructions that otherwise require `GETBLOCKTXN->BLOCKTXN` roundtrips, irrespective of the cost of prefilling?\n2. Does prefilling result in a net reduction on block propagation times?\n\nThe results indicate that the answer to 1. is definitively yes. The metric used by [0xB10C/2025-03-prefill-compactblocks](https://github.com/0xB10C/bitcoin/commits/2025-03-prefill-compactblocks/) of prefilling the transactions we were missing from our mempool when performing block reconstruction resulted in an observed reconstruction rate of 98.25% for a node receiving prefilled CMPCTBLOCK announcements when both the prefilling node and the prefill-receiving node are running similar builds of Bitcoin Core, compared to the observed reconstruction rate on a node not receiving prefilled blocks of of 61.81%. Some of those prefills, as pointed out by @Crypt-iQ and @gmaxwell  above, exceeded the TCP window, and likely resulted in an additional round-trip, negating the benefit of prefilling. But, in my measurements, 85.78% of the prefills would have fit in the partially occupied TCP window a prefilling node sent the `CMPCTBLOCK`'s in. Projecting out, these measurements indicate that if all Bitcoin Core nodes had been prefilling during the period which I measured data, the reconstruction rate would have been 93.07% and we can likely do better taking advantage of the fact, pointed out by @andrewtoth [above](https://delvingbitcoin.org/t/stats-on-compact-block-reconstructions/1052/25) that similar peers will likely have similar `vExtraTxn`.\n\nI think the following improvements should be made to [0xB10C/2025-03-prefill-compactblocks](https://github.com/0xB10C/bitcoin/commits/2025-03-prefill-compactblocks/):\n\n##### Definitely:\n- Only prefill up to the next TCP window boundary.\n- Always insert candidates from `vExtraTxn` last.\n\n##### Maybe:\n- Within DoS limits (maybe a limit of 4 MiB per valid header), temporarily store a per-block cache of prefilled transactions you hear about, increasing the chances that you successfully reconstruct without having to wait for an RTT.\n- If the send window can't fit all of the prefill candidates, prefill a random selection of candidates, always prefilling transactions not in `vExtraTxn` first.\n\nFuture investigations should:\n1. Use prefill-receiving nodes to measure the amount of duplicate / redundant data in the prefill.\n2. Use two peers with stable and high (maybe artificial?) latencies to easily estimate the number of round-trips that messages take to pass between them, there is also probably external tooling that can measure this.\n3. Measure / reason about effects of prefilling at a distance of more than one hop.\n4. Measure data about the `GETBLOCKTXN` messages that a prefilling node receives from random peers. \n\n# Latency and Bandwidth\n\n**Feel free to skip the math in this section or to [skip](#Observations) reading this section entirely.**\n\nTaking a simplified view, the latency for a receiver to hear an unsolicited message (the scenario we care about in block relay) consists of\ntransmission delay plus propagation delay: \n$$\n\\text{Latency} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}} * \\text{Round-trip time}\n$$\n\nAny time compact block reconstruction fails because the receiver was missing transactions, an additional round-trip-time (RTT) of requesting missing transactions and receiving them (`GETBLOCKTXN->BLOCKTXN`) must be paid in order to complete reconstruction, but at this point the amount of data that needs to be transmitted for reconstruction to succeed does not change. Where $f$ is the probability for a block to fail reconstruction:\n\n$$\n\\text{Latency} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}}\\text{RTT} + f * \\text{RTT}\n$$\n\nIf we had perfect information about the transactions our peer will be missing, we should always send these along with the block announcements since we will pay basically the same transmission delay, minus the unnecessary round-trip. If we don't have perfect information, then the worst we can do is send transactions which our peer already knew about, while not sending them transactions they didn't know about, incurring the RTT anyways, plus the transmission time of the redundant data. Let's say we send $p$ extra prefill bytes, with each byte having a probability $n$ of being redundant and prefilling $p$ bytes gets us a reconstruction failure probability of $f_{p}$, then:\n\n$$\n\\text{Latency}_\\text{Prefilling} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\frac{p * n}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}}\\text{RTT} + f_p * \\text{RTT}\n$$\n\n## Criterion for deciding if prefilling is advantageous\n\nIn order for prefilling latency to be better than or equal to no-prefilling latency, the following inequality must be satisfied:\n\n$$\n\\frac{p * n}{\\text{Bandwidth}*\\text{RTT}} \\leq f_0 - f_p\n$$\n\n<details>\n<summary> \n    \n#### Derivation\n</summary>\n\nIf latency while prefilling is less than or equal to latency without prefilling, where $b$ is bandwidth, $r$ is the RTT, $d$ is the size of the CMPCTBLOCK without prefill, $p$ is the size of the prefill, and $f_p$ is the reconstruction failure rate at a given prefill size $p$:\n\n$$\n\\frac{d}{b} + \\frac{pn}{b} + \\frac{1}{2}r + {f_p}{r} \\leq \\frac{d}{b} + \\frac{1}{2}r + {f_0}{r}\n$$\n\nSubtracting the common terms $\\frac{d}{b}$ and $\\frac{1}{2}r$ from both sides:\n\n$$\n\\frac{pn}{b} + {f_p}{r} \\leq {f_0}{r}\n$$\n\nSubtracting ${f_p}{r}$ from both sides:\n\n$$\n\\frac{pn}{b} \\leq {f_0}{r} - {f_p}{r}\n$$\n\nDividing both sides by $r$:\n\n$$\n\\frac{pn}{{b} {r}} \\leq {f_0} - {f_p}\n$$\n\n</details>\n\n\nIf we plug in some example values, prefilling 10KiB with a bandwidth of 5 MiB/s and an RTT of 50ms (.050s) and use a worst case $n$ of 1\n\n$$\n\\frac{10\\text{KiB}*1}{5 \\text{MiB/s} * 0.050\\text{s}} = 0.039\n$$\n\nIn this case, if prefilling improves reconstruction rates by at least 3.9% it is definitely better than not prefilling.\n\n## Latency Cost of Prefilling\n\nAnd we can quantify the latency cost of prefilling over not prefilling as:\n\n$$\n\\text{Latency}_\\text{Prefilling} - \\text{Latency}_\\text{Not prefilling} = \\frac{p*n}{\\text{Bandwidth}} - r(f_0 - f_p)\n$$\n\n## TCP windows and the costs of prefilling.\n\nBut, the use of TCP in the Bitcoin P2P protocol complicates this, because a sender will not send data exceeding the TCP window size in a single round-trip. Instead, they will send up to the window size in data, wait for an `ACK` from the receiver, and then send up to `window` bytes after the data which was `ACK`ed. That means that if we exceed a single TCP window, we will have to pay an additional RTT in propagation latency (and a little bit of transmission latency for the overhead). And for each additional window we overflow, we will pay another RTT:\n\n$$\n\\text{TCP Latency} \\approx \\frac{\\text{Data}}{\\text{Bandwidth}} + \\sim{\\frac{1}{2}}\\text{RTT} + f * \\text{RTT} + \\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor\\text{RTT}\n$$\n\nNote $\\lfloor a \\rfloor$ meaning `std::floor(a)`\n\nDoing a similar dance as above, where $p$ is the prefill size and $f_p$ is the probability of reconstruction failure at prefill size $p$, and $n$ is the probability of a prefill byte being redundant:\n\n$$\n\\frac{p*n}{\\text{Bandwidth}*\\text{RTT}} \\leq f_0 - f_p + \\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor - \\lfloor{\\frac{\\text{Data}+p}{\\text{Window Size}}}\\rfloor\n$$\n\nThe \"TCP window\" is the smaller of two values: the receiver advertised window (`rwnd`) and the sender-calculated congestion window (`cwnd`).\n\n### Overflowing current TCP window is always worse than doing nothing\n\nThe above formula establishes as a rule something which might have been intuited, that if the prefill causes us to exceed the current TCP window, then we will always do worse than if we hadn't prefilled, since:\n1. $f_0 - f_p \\leq 1$ since the smallest number $f_0$ can be is 0, and the largest number $f_p$ can be is 1.\n2. $\\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor - \\lfloor{\\frac{\\text{Data}+p}{\\text{Window Size}}}\\rfloor \\leq -1$ if the prefill overflows the current partially filled TCP window.\n3. If $a \\leq 1$ and $b \\leq -1$, then $a + b \\leq 0$, so the right hand side of the formula is $\\leq 0$.\n4. The left hand side of the equation will always be $\\geq 0$, since none of the variables on the left side can ever be negative.\n5. If $lhs \\geq 0$ and $0 \\geq rhs$, then $lhs \\geq rhs$, so the left hand side will never be less than the right hand side, therefore prefilling will never be beneficial.\n\nBut, if we bound our prefill $p$ so that we never increase the number of TCP windows used, i.e.: $\\lfloor{\\frac{\\text{Data}}{\\text{Window Size}}}\\rfloor - \\lfloor{\\frac{\\text{Data}+p}{\\text{Window Size}}}\\rfloor = 0$ which, I believe is [easy](https://delvingbitcoin.org/t/stats-on-compact-block-reconstructions/1052/29) to do, we can use the exact same formula as above to decide whether or not prefilling is effective:\n\n$$\n\\frac{p * n}{\\text{Bandwidth}*\\text{RTT}} \\leq f_0 - f_p\n$$\n\n### Complication: TCP Retransmission\n\nSo far, I have assumed perfectly reliable networks and this isn't always the case, packets get lost, and in TCP that means waiting for a timeout, and then retransmitting. But, I believe the problem above I've described in relation to prefilling is very similar to the problem that the designers of TCP had in selecting a static window size, and later, dynamic window sizes through congestion control algorithms like those described in [RFC 5681](https://datatracker.ietf.org/doc/html/rfc5681) and [RFC 9438](https://datatracker.ietf.org/doc/html/rfc9438). Instead of the probability that a block reconstruction will fail, they deal with the probability that a packet will not arrive, in both cases, the consequence is an additional round-trip, and a core question is whether the marginal value of potentially saving a round-trip by packing in more data is worth the risk that retransmission will be necessary anyways. The analogy is imperfect, as there are many more concerns that TCP congestion control algorithms deal with, but I argue that the node can outsource the question: \"How large of a message can we send and reasonably expect everything to arrive?\" to its operating system's congestion control implementation.\n\n### Complication: Cost of Bandwidth\n\nIn all of the above, I have assumed the cost of using bandwidth is 0 outside of the latency cost. I've done this because I believe the cost of the redundant transactions sent in compact block prefills is negligible, the data I measured below suggests that prefills will be on the order of ~20KiB, so worst case monthly bandwidth usage of prefilling, assuming every byte is redundant and did not need to be sent, and that you always receive a prefilled CMPCTBLOCK from three HB peers, is ~300 MiB. (3 HB Peers * 20 KiB * 6 * 24 * 31)\n\n## Takeaways\nI don't think proving that the above inequality being satisfied is necessary for a prefilling solution, what I think it's useful for is building an intuition of the problem, and setting theoretical boundaries on how effective prefilling needs to be to be worth it.\n- Nodes are likelier to suffer rather than benefit from prefilling that have smaller $Bandwidth * RTT$ (See [Bandwidth-delay product (BDP)](https://en.wikipedia.org/wiki/Bandwidth-delay_product)) connections: e.g. nodes with low bandwidth and low ping. And nodes that have connections with large BDP's are likelier to benefit, e.g. high-bandwidth, high-latency connections(\"Long Fat Networks\" as described in [RFC 7323](https://datatracker.ietf.org/doc/html/rfc7323#section-1.1))\n- If the redundant broadcast probability $n$ is zero, prefilling is always worth it.\n\n# Data\nThe data was all taken from `debug.log`'s generated by the nodes and parsed with this python script: https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/logsparser.py\n\n- Statistics: https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/stats.py\n- Plots: https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/plots.py\n\nCSV's from the data collected can be found here: https://github.com/davidgumberg/logkicker/tree/main/compactblocks/2025-07-11-first-report\n\n- Statistics: https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/stats.py\n- Plots: https://github.com/davidgumberg/logkicker/blob/285034d6833e34dfcb058ce37b30affede0333be/compactblocks/plots.py\n\n## Summary\n\nThe node receiving not prefilled blocks had a reconstruction rate of 61.81%, the node receiving prefilled blocks had a reconstruction rate of 98.25%, but only 85.78% of those would have fit in the current TCP window of the CMPCTBLOCK being announced, so projecting from those two figures, 93.07% of blocks could have been reconstructed without an additional TCP round trip. The vast majority of TCP windows observed were around ~15KiB. For a lot of the data around prefills, the averages are massive because of a few extreme outliers, but the vast majority of the time, a very small amount of prefill data is needed to prevent a `GETBLOCKTXN->BLOCKTXN` round trip, 65% of blocks observed needed 1KiB or less of prefill.\n\n## Prefill-Receiving Node: stats on CMPCTBLOCK's received\nThis data was gathered from a node configured so that it would only receive CMPCTBLOCK announcements from our prefilling node, the main thing to see here is that reconstruction generally succeeds, the average reconstruction time metric is misleading, since we don't count extra RTT's that happen in the TCP layer in reconstruction time, just the time we receive the `CMPCTBLOCK` until the time we have reconstructed it.\n\n```\n49 out of 2793 blocks received failed reconstruction. (1.75%)\nReconstruction rate was 98.25%\nAvg size of received block: 55851.93 bytes\nAvg bytes missing from received blocks: 603.40 bytes\nAvg bytes missing from blocks that failed reconstruction: 34393.55 bytes\nAvg reconstruction time: 7.821697ms\n```\n\n![Figure 1a|690x344](upload://7Qg9ACyfr129UFUHmzHLe1D7Weo.png)\n\n![Figure 1b|690x346](upload://brMRGTdFTnYB8Rv5sqntWzi5FeP.png)\n\n## Prefilling Node: stats on CMPCTBLOCK's received\nThis data was gathered from the node that sends prefilled compact blocks to its peers. Because this node is otherwise unmodified, we can use its measurements on the receiving side as a baseline for block reconstruction on nodes today.\n\n```\n1101 out of 2883 blocks received failed reconstruction. (38.19%)\nReconstruction rate was 61.81%\nAvg size of received block: 15957.20 bytes\nAvg bytes missing from received blocks: 47849.36 bytes\nAvg bytes missing from blocks that failed reconstruction: 125294.91 bytes\nAvg reconstruction time: 25.741588ms\n```\n\n![Figure 2|640x480](upload://253eQl15AmXesNwzMf6qiehdygQ.png)\n\n\n![Figure 3a|690x343](upload://uKvfr1FkC8SU5dXCBdkDI5wD0yI.png)\n\n![Figure 3b|690x347](upload://i0RUvPGCCAC1cYh6Hqh5xPObOx2.png)\n\n\n\n### TCP Window data\nThere is a flaw in the window available bytes metric I have used, pointed out to me by @hodlinator, which is that I only did `window_size - cmpctblock_size`, and did not factor existing bytes queued to send to peers in `vSendMsg`. I anticipate this will have a small effect, but a branch which prefills up to the TCP window limit should take this into account.\n\n**Edit:**\n\n@andrewtoth has pointed out more complications in the available bytes metric: it will also have to take into account the current in-flight segments to the peer. On Linux, for example, this is [`tcpi_unacked`](https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/tcp.h#L244) (Multiplied by  [`tcpi_snd_mss`](https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/tcp.h#L241) to get size in bytes). It will also have to account for bytes that are in the operating system's send queue ([`tcpi_notsent_bytes`](https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/tcp.h#L278)). But I believe that because Bitcoin Core [uses](https://github.com/bitcoin/bitcoin/pull/6867) `TCP_NODELAY` the OS send buffer should generally be empty. On Linux, the sum of these two values can be obtained with `SIOCOUTQ`[^1]:\n\n```c\nint bytes_inflight_and_unsent, err;\nerr = ioctl(socket, SIOCOUTQ, &bytes_inflight_and_unsent)\n```\n\nI found this article helpful: https://tiebing.blogspot.com/2019/05/tcp-socket-send-buffer-deep-dive.html ([archive link](https://web.archive.org/web/20250716165959/https://tiebing.blogspot.com/2019/05/tcp-socket-send-buffer-deep-dive.html))\n\n[^1]: `man tcp` incorrectly documents `SIOCOUTQ` as only the unsent bytes, but it's [both unsent and unacked](https://github.com/torvalds/linux/blob/155a3c003e555a7300d156a5252c004c392ec6b0/include/uapi/linux/sockios.h#L27)\n\n```\nTCP Window Size: Avg: 16128.76 bytes, Median: 14480.0, Mode: 14480\nThe mode represented 13076/26392 windows. (49.55%)\nAvg. TCP window bytes used: 7449.62 bytes\nAvg. TCP window bytes available: 8679.14 bytes\n```\n\n![Figure 4|640x480](upload://7mLueCA5voJgqidteSvgsOYmRYn.png)\n\n\n## Prefilling node: stats on CMPCTBLOCK's sent\n```\nThe average CMPCTBLOCK we sent was 65732.80 bytes.\nThe average prefilled CMPCTBLOCK we sent was 91614.48 bytes.\nThe average not-prefilled CMPCTBLOCK we sent was 14483.78 bytes.\n17536/26392 blocks were sent with prefills. (66.44%)\nAvg available prefill bytes for all CMPCTBLOCK's we sent: 8679.14 bytes\nAvg available prefill bytes for prefilled CMPCTBLOCK's we sent: 8362.04 bytes\nAvg total prefill size for CMPCTBLOCK's we prefilled: 74593.04 bytes\n15042/17536 prefilled blocks sent fit in the available bytes. (85.78%)\n```\n\nThe average prefill size is notably large, but this is a consequence of some outlier blocks.\n\n![Figure 5a|690x273](upload://c6g6GtT1abGvQoJ2lIwvub20hyT.png)\n\n![Figure 5b|690x277](upload://ey0dTyUOAHoq9LQgvDcgLitDyhq.png)\n\n\n### `vExtraTxnForCompact`\nBut, we can probably do even better, since the above statistics are for prefilling *with* all of the transactions in `vExtraTxnForCompactBlock`, and as I understand, it is very likely for peers running the same branch of Bitcoin Core to have a similar `vExtraTxnForCompactBlock`'s to one another. So it is likely that reconstruction will often succeed even without these transactions, so they should be the first candidates for not being included in the prefill. Unfortunately, their size is not something that Bitcoin Core logs, although I tried to compute it with a heuristic: `prefill_size - missing_txns_we_requested_size`, but it turned out this was very incorrect.\n\n### Overflowing window before pre-fill.\nInterestingly, some compact blocks were already so large *before* prefilling that they required more than one TCP round-trip to be sent, while this circumstance is not ideal, prefilling performs better by taking advantage of this.\n\n```\n1432/26392 CMPCTBLOCK's sent were already over the window for a single RTT before prefilling. (5.43%)\nAvg. available bytes for prefill in blocks that were already over a single RTT: 8555.57 bytes\n1432/1432 excessively large blocks had prefills that fit. (100.00%)\n```",
  "actions_summary": [
    {
      "id": 2,
      "count": 8
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 315,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "An interactive/modifiable version of all the data and plots are in a jupyter notebook here: <a href=\"https://davidgumberg.github.io/logkicker/lab/index.html?path=2025-07-11-first-report%2FPrefilling.ipynb\" rel=\"noopener nofollow ugc\">https://davidgumberg.github.io/logkicker/lab/index.html?path=2025-07-11-first-report%2FPrefilling.ipynb</a> \n\n<a name=\"p-5488-summary-1\" class=\"anchor\" href=\"#p-5488-summary-1\"></a>Summary\nI connected two Bitcoin Core nodes running on mainnet, one prefilling transactions to a node &hellip;",
  "truncated": true,
  "post_url": "/t/stats-on-compact-block-reconstructions/1052/34",
  "reactions": [
    {
      "id": "rocket",
      "type": "emoji",
      "count": 5
    },
    {
      "id": "+1",
      "type": "emoji",
      "count": 2
    },
    {
      "id": "clap",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 8,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}