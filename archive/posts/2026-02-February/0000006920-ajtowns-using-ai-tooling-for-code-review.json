{
  "id": 6920,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2026-02-21T09:26:56.668Z",
  "cooked": "<p>After <a class=\"mention\" href=\"/u/instagibbs\">@instagibbs</a> reported success in using Claude for rebasing <a href=\"https://delvingbitcoin.org/t/ln-symmetry-project-recap/359/16\">ln-symmetry</a>, I had a go at messing with it too. While it seems very useful in general, I think one place that\u2019s worth talking about is using it as a review aid: PR review has long been recognised (<a href=\"https://adamjonas.com/bitcoin/coredev/retro/coredev-2020-retro/\">eg</a>) as a bottleneck in Bitcoin Core at least, and AI\u2019s certainly lowering the barrier to creating new PRs which won\u2019t make things easier.</p>\n<p>I think there\u2019s a few different goals when reviewing a PR that are worth being a bit explicit about:</p>\n<ul>\n<li>does this actually do what it\u2019s supposed to?</li>\n<li>is doing this a good thing? if it is a good thing, is it worth the cost? are there more important things that should take priority?</li>\n<li>could this be done better?</li>\n<li>are the changes properly tested?</li>\n<li>do I understand the change well enough to fix any bugs in it that get found later?</li>\n</ul>\n<p>With this in mind, I found two pretty strong biases that I didn\u2019t think were very helpful:</p>\n<ul>\n<li>Claude would largely take it for granted that the idea was good and worthwhile, and only review correctness.</li>\n<li>Claude would largely try to do everything itself \u2013 form an opinion and state a conclusion and even offer to post that as a PR review, sometimes even before I\u2019d had a chance to look at the commits myself.</li>\n</ul>\n<p>I think the \u201cis it worthwhile\u201d one is probably just hard; it\u2019s not that easy for humans either really. My test case for that was <a href=\"https://github.com/bitcoin/bitcoin/pull/34444/#issuecomment-3862608834\">PR#34444</a>, and as per the comment, even if its review contribution wasn\u2019t helpful, it was still helpful for me overall.</p>\n<p>But the \u201cI\u2019ll just do everything for you\u201d aspect doesn\u2019t seem so helpful \u2013 if you want to improve review, you want to add \u201cbrainpower\u201d to the review process, not subtract it. So the approaches I\u2019ve looked at for this is a few things:</p>\n<ul>\n<li>telling it to run a sub-agent and do a review, but keep the results of the review private until I\u2019ve done my own review, so that we can then compare them (it immediately summarised the results when the agent finished, of course)</li>\n<li>telling it that I\u2019m stepping through each commit, and to quiz me on anything that seems complicated in the commit (this worked pretty well, and found a couple of things I didn\u2019t understand fully) Helps to disable \u201cshow tips\u201d via /config, or else the quiz answers will appear as suggested responses, though\u2026</li>\n<li>asking it for help doing things when I\u2019m stepping through \u2013 in particular, I\u2019ve always found it hard to get code coverage reports and iwyu/clang-format results; telling the AI to do that for me has been great</li>\n</ul>\n<p>I\u2019m not sure how much it helped, but telling it various resources about the PR and getting it to do a sub-agent that summarises those as a resource to use before beginning the rule might be a good idea.</p>\n<p>Using it as a project manager (\u201coh, I should do X, remind me about that when I\u2019m done with Y\u201d) was also very helpful. I\u2019ve gone so far as to feed it my various blog posts on Bitcoin so it can help prioritise tasks at a higher level too, and so far it seems like that works okay too.</p>\n<p>Anyway, I used that approach very heavily in my review of <a href=\"https://github.com/bitcoin/bitcoin/pull/34257\">PR#34257</a> and <a href=\"https://github.com/bitcoin/bitcoin/pull/34023\">PR#34023</a> for cluster mempool related improvements, and found it pretty effective. The AI\u2019s initial self-review almost immediately spotted <a href=\"https://github.com/bitcoin/bitcoin/pull/34257#pullrequestreview-3770550800\">an inverted condition in a test</a>, and then having the AI assist with code-coverage reporting on the fuzz corpus helped validate that it really was behaving as it seemed. For the SFL optimisation stuff, I tried getting it to have a sub-agent review the code prior to the PR and suggest its own optimisations and then see if those matched the PR, or if anything was missing. It did claim to pick out the most valuable change, while missing most of the minor ones, but that didn\u2019t really add anything to the review.</p>\n<p>Probably the key bits of my overall prompting stuff are these bits (mostly copied from <a href=\"https://x.com/EXM7777/status/2018022297345654870\">a tweet I saw</a> or self-generated by claude):</p>\n<pre><code class=\"lang-auto\">## Core Principles\n\n### Simplicity First\n- Make every change as simple as possible. Impact minimal code.\n- Find root causes. No temporary fixes. Senior developer standards.\n- Changes should only touch what's necessary. Avoid introducing bugs.\n\n### Plan Before Executing\n- Enter plan mode for ANY non-trivial task (3+ files or architectural decisions)\n- If something seems off, STOP and re-plan immediately - don't keep pushing\n- Write detailed specs upfront to reduce ambiguity\n\n### Verification Before Done\n- Never mark a task complete without proving it works\n- Run tests, check logs, demonstrate correctness\n- Ask yourself: \"Would a staff engineer approve this?\"\n\n### Self-Improvement Loop\n- After ANY correction or finding: update `lessons.md` with the pattern\n- Write rules that prevent the same mistake\n- Review lessons at session start\n\n### Autonomous Investigation\n- When given a potential bug: just investigate it, don't ask for hand-holding\n- Point at logs, errors, failing tests - then resolve them\n- Zero context switching required from the user\n\n### Interactive Assistance\n- Claude assists; the user drives. Don't produce finished artifacts and\n  offer to post them. Present work incrementally and wait for direction.\n- When in doubt about the next step, ask rather than assume.\n\n### Demand Elegance (Balanced)\n- For non-trivial changes: pause and ask \"is there a more elegant way?\"\n- Skip this for simple, obvious fixes - don't over-engineer\n</code></pre>\n<p>Now that I actually look at that, I guess the \u201cAutonomous Investigation\u201d and \u201cInteractive Assistance\u201d sections are in some conflict there. Oh well!</p>\n<p>It\u2019s not currently clear to me what resources from a session would be interesting to publish \u2013 so far I haven\u2019t personally looked much at either the docs or the project files that it generates; I\u2019m more just using them as the AI\u2019s long-term memory so we can both pick back up where we left off. For conversations with ChatGPT and the like, just posting a log of the conversation can make sense, I think (<a href=\"https://gist.github.com/ajtowns/d61bea974a07190fa6c6c8eaef3638b9\">eg</a>), but it\u2019s not clear to me what would be similar for an agent-based project.</p>\n<p>(For those interested I\u2019m running it in a dedicated VM, with a read-only github token for looking up PRs, and no push access/etc. I haven\u2019t tried running with local models, or Codex or OpenClaw etc)</p>\n<p>Anyway, thought I\u2019d share. Anyone else trying something similar?</p>",
  "post_number": 1,
  "post_type": 1,
  "posts_count": 3,
  "updated_at": "2026-02-21T09:26:56.668Z",
  "reply_count": 1,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 2,
  "reads": 17,
  "readers_count": 16,
  "score": 33.4,
  "yours": false,
  "topic_id": 2277,
  "topic_slug": "using-ai-tooling-for-code-review",
  "topic_title": "Using AI tooling for code review",
  "topic_html_title": "Using AI tooling for code review",
  "category_id": 8,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "After @instagibbs reported success in using Claude for rebasing [ln-symmetry](https://delvingbitcoin.org/t/ln-symmetry-project-recap/359/16), I had a go at messing with it too. While it seems very useful in general, I think one place that's worth talking about is using it as a review aid: PR review has long been recognised ([eg](https://adamjonas.com/bitcoin/coredev/retro/coredev-2020-retro/)) as a bottleneck in Bitcoin Core at least, and AI's certainly lowering the barrier to creating new PRs which won't make things easier.\n\nI think there's a few different goals when reviewing a PR that are worth being a bit explicit about:\n\n * does this actually do what it's supposed to?\n * is doing this a good thing? if it is a good thing, is it worth the cost? are there more important things that should take priority?\n * could this be done better?\n * are the changes properly tested?\n * do I understand the change well enough to fix any bugs in it that get found later?\n \nWith this in mind, I found two pretty strong biases that I didn't think were very helpful:\n\n * Claude would largely take it for granted that the idea was good and worthwhile, and only review correctness.\n * Claude would largely try to do everything itself -- form an opinion and state a conclusion and even offer to post that as a PR review, sometimes even before I'd had a chance to look at the commits myself.\n\nI think the \"is it worthwhile\" one is probably just hard; it's not that easy for humans either really. My test case for that was [PR#34444](https://github.com/bitcoin/bitcoin/pull/34444/#issuecomment-3862608834), and as per the comment, even if its review contribution wasn't helpful, it was still helpful for me overall.\n\nBut the \"I'll just do everything for you\" aspect doesn't seem so helpful -- if you want to improve review, you want to add \"brainpower\" to the review process, not subtract it. So the approaches I've looked at for this is a few things:\n\n * telling it to run a sub-agent and do a review, but keep the results of the review private until I've done my own review, so that we can then compare them (it immediately summarised the results when the agent finished, of course)\n * telling it that I'm stepping through each commit, and to quiz me on anything that seems complicated in the commit (this worked pretty well, and found a couple of things I didn't understand fully) Helps to disable \"show tips\" via /config, or else the quiz answers will appear as suggested responses, though...\n * asking it for help doing things when I'm stepping through -- in particular, I've always found it hard to get code coverage reports and iwyu/clang-format results; telling the AI to do that for me has been great\n\nI'm not sure how much it helped, but telling it various resources about the PR and getting it to do a sub-agent that summarises those as a resource to use before beginning the rule might be a good idea.\n\nUsing it as a project manager (\"oh, I should do X, remind me about that when I'm done with Y\") was also very helpful. I've gone so far as to feed it my various blog posts on Bitcoin so it can help prioritise tasks at a higher level too, and so far it seems like that works okay too.\n\nAnyway, I used that approach very heavily in my review of [PR#34257](https://github.com/bitcoin/bitcoin/pull/34257) and [PR#34023](https://github.com/bitcoin/bitcoin/pull/34023) for cluster mempool related improvements, and found it pretty effective. The AI's initial self-review almost immediately spotted [an inverted condition in a test](https://github.com/bitcoin/bitcoin/pull/34257#pullrequestreview-3770550800), and then having the AI assist with code-coverage reporting on the fuzz corpus helped validate that it really was behaving as it seemed. For the SFL optimisation stuff, I tried getting it to have a sub-agent review the code prior to the PR and suggest its own optimisations and then see if those matched the PR, or if anything was missing. It did claim to pick out the most valuable change, while missing most of the minor ones, but that didn't really add anything to the review.\n\nProbably the key bits of my overall prompting stuff are these bits (mostly copied from [a tweet I saw](https://x.com/EXM7777/status/2018022297345654870) or self-generated by claude):\n\n```\n## Core Principles\n\n### Simplicity First\n- Make every change as simple as possible. Impact minimal code.\n- Find root causes. No temporary fixes. Senior developer standards.\n- Changes should only touch what's necessary. Avoid introducing bugs.\n\n### Plan Before Executing\n- Enter plan mode for ANY non-trivial task (3+ files or architectural decisions)\n- If something seems off, STOP and re-plan immediately - don't keep pushing\n- Write detailed specs upfront to reduce ambiguity\n\n### Verification Before Done\n- Never mark a task complete without proving it works\n- Run tests, check logs, demonstrate correctness\n- Ask yourself: \"Would a staff engineer approve this?\"\n\n### Self-Improvement Loop\n- After ANY correction or finding: update `lessons.md` with the pattern\n- Write rules that prevent the same mistake\n- Review lessons at session start\n\n### Autonomous Investigation\n- When given a potential bug: just investigate it, don't ask for hand-holding\n- Point at logs, errors, failing tests - then resolve them\n- Zero context switching required from the user\n\n### Interactive Assistance\n- Claude assists; the user drives. Don't produce finished artifacts and\n  offer to post them. Present work incrementally and wait for direction.\n- When in doubt about the next step, ask rather than assume.\n\n### Demand Elegance (Balanced)\n- For non-trivial changes: pause and ask \"is there a more elegant way?\"\n- Skip this for simple, obvious fixes - don't over-engineer\n```\n\nNow that I actually look at that, I guess the \"Autonomous Investigation\" and \"Interactive Assistance\" sections are in some conflict there. Oh well!\n\nIt's not currently clear to me what resources from a session would be interesting to publish -- so far I haven't personally looked much at either the docs or the project files that it generates; I'm more just using them as the AI's long-term memory so we can both pick back up where we left off. For conversations with ChatGPT and the like, just posting a log of the conversation can make sense, I think ([eg](https://gist.github.com/ajtowns/d61bea974a07190fa6c6c8eaef3638b9)), but it's not clear to me what would be similar for an agent-based project.\n\n(For those interested I'm running it in a dedicated VM, with a read-only github token for looking up PRs, and no push access/etc. I haven't tried running with local models, or Codex or OpenClaw etc)\n\nAnyway, thought I'd share. Anyone else trying something similar?",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "After <a class=\"mention\" href=\"/u/instagibbs\">@instagibbs</a> reported success in using Claude for rebasing <a href=\"https://delvingbitcoin.org/t/ln-symmetry-project-recap/359/16\">ln-symmetry</a>, I had a go at messing with it too. While it seems very useful in general, I think one place that\u2019s worth talking about is using it as a review aid: PR review has long been recognised (<a href=\"https://adamjonas.com/bitcoin/coredev/retro/coredev-2020-retro/\">eg</a>) as a bottleneck in Bitcoin Core at &hellip;",
  "truncated": true,
  "post_url": "/t/using-ai-tooling-for-code-review/2277/1",
  "reactions": [
    {
      "id": "heart",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null,
  "can_vote": false
}