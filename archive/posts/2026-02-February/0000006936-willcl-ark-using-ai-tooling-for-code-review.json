{
  "id": 6936,
  "name": "will",
  "username": "willcl-ark",
  "avatar_template": "/user_avatar/delvingbitcoin.org/willcl-ark/{size}/165_2.png",
  "created_at": "2026-02-23T09:12:06.600Z",
  "cooked": "<p>I have also been experimenting with almost exactly this using a <code>review-core</code> command in Claude code. It\u2019s certainly a long way from perfect, and if I\u2019m honest it does spot a few too many false-positives for my liking, but it is reasonably thorough, and often provides a decent starting spot go go from, or more regularly a sanity check against my own thoughts after I\u2019ve done my own review. I haven\u2019t decided yet if I prefer to run this before or after my own review, as both seem to have their merits (and downsides)\u2026</p>\n<p>The command I am currently using is:</p>\n<hr>\n<pre><code class=\"lang-auto\"># Bitcoin Core Code Review\n\nYou are assisting the user's review of Bitcoin Core code \u2014 security-critical software managing billions in value. Surface findings and concerns for the user to evaluate; don't produce a finished review or draw final conclusions on their behalf.\n\n## Review Process\n\n1. First, fetch upstream and identify what is being reviewed:\n   ```bash\n   git fetch upstream\n   ```\n   - If no argument provided, review the current branch's changes against `upstream/master`\n   - If a PR number is provided, fetch and review that PR\n\n2. Fetch PR context from GitHub (if reviewing a PR):\n   ```bash\n   gh pr view &lt;number&gt; --repo bitcoin/bitcoin\n   ```\n   The PR description often contains valuable context: motivation, design decisions, and related issues/PRs. Read it carefully before diving into code.\n\n3. Find the merge base, then gather context by examining the diff:\n   ```bash\n   git merge-base upstream/master HEAD\n   ```\n   ```bash\n   git diff &lt;merge-base&gt;..HEAD\n   ```\n   If the merge-base equals HEAD (PR already merged), diff against the parent of the first PR commit instead.\n\n4. Apply the checklist below systematically\n\n## Priority Checklist\n\n### Concept &amp; Justification\n- Is this change worth making? Don't take the premise for granted \u2014 question it\n- Does the implementation actually achieve its stated goal?\n- Is the benefit proportional to the complexity and review burden?\n\n### Security &amp; Consensus\n- Could this change affect consensus behavior? Flag for extensive review\n- Check for integer overflows, memory safety issues, undefined behavior\n- Verify all user/network input is validated before use\n- Look for DoS vectors (unbounded memory/CPU, slow paths attackers can trigger)\n- Ensure cryptographic code uses constant-time operations where needed\n\n### Threading &amp; Locking\n- Verify lock annotations (`EXCLUSIVE_LOCKS_REQUIRED`, `LOCKS_EXCLUDED`) are correct and complete\n- Check lock ordering\u2014would this introduce potential deadlocks?\n- Confirm `AssertLockHeld()` calls match annotations\n- Flag any use of `RecursiveMutex` where `Mutex` would suffice\n\n### Code Quality\n- Does the change do one thing well, or is it trying to do too much?\n- Does this fix the root cause, or just the symptom?\n- Are there unnecessary changes mixed in (refactors bundled with behavior changes)?\n- Is the commit history logical and bisectable?\n- Do commit messages explain *why*, not just *what*?\n- Could a reviewer who didn't write this code maintain and debug it later?\n\n### Testing\n- Are there unit tests for new/changed logic?\n- For RPC/P2P changes, are there functional tests?\n- Do existing tests still make sense, or do they need updating?\n- Consider edge cases: empty inputs, maximum values, malformed data\n\n### Style &amp; Conventions\n- Named arguments for booleans: `Foo(/*flag=*/true)` not `Foo(true)`\n- Prefer `std::optional` over sentinel values\n- No `std::map::operator[]` for reads (use `.find()` or `.at()`)\n- Initialize all members at declaration\n\n## Design Analysis\n\nAfter applying the checklist, step back and analyze the PR's approach at a higher level. Generate and answer these questions in your review under a \"### Design Analysis\" heading, after the line-by-line findings and before the summary.\n\n### Motivation &amp; Threat Model\n- What problem or attack does this change address? Explain the threat model or gap being closed.\n- Why does Bitcoin Core specifically benefit from this? Connect to concrete risks (DoS, privacy, censorship resistance, etc).\n- If this is a defense/hardening measure, what's the residual risk with and without it?\n\n### Approach Robustness\n- Could the chosen approach produce incorrect behavior under any scenario? Walk through failure modes explicitly.\n- What assumptions does the approach rely on? Are those assumptions guaranteed or merely conventional?\n- If there's a fallback/retry mechanism: can it loop infinitely, mask real errors, or leave inconsistent state?\n- What happens when upstream dependencies (Tor, OS, libs) change behavior? Is the approach brittle to version changes?\n\n### Alternative Approaches\n- Is there a simpler or more robust way to achieve the same goal? Consider what the PR chose *not* to do and why that tradeoff is or isn't justified.\n- Would a different approach avoid failure modes present in the current one?\n- If the current approach is the best one, say so and briefly explain why the alternatives are worse.\n\n### Strategic Assessment\n- What maintenance burden does this create? Will this need updating as dependencies (Tor, libraries, protocols) evolve?\n- Does this establish a pattern or precedent that future PRs will follow? Is that a pattern we want?\n- Is this the right layer to solve this problem? Should it be handled upstream, downstream, or by configuration instead of code?\n- For Bitcoin Core specifically: does this increase attack surface, trust assumptions, or dependency coupling in a way that's disproportionate to the gain?\n\nBe specific \u2014 name the scenarios and tradeoffs, don't just say \"this could go wrong\" or \"there might be a better way.\"\n\n## Output Format\n\nFor each concern found, report:\n\n```\n**[SEVERITY]** `file:line` - Brief description\n\nIssue: What's wrong\nSuggestion: How to fix it\n```\n\nSeverities:\n- **BLOCKING** - Must fix before merge (security, correctness, consensus)\n- **SHOULD-FIX** - Strong recommendation (bugs, significant issues)\n- **NIT** - Minor style or preference (optional to address)\n\n## Summary Section\n\nEnd with a summary:\n- What the PR accomplishes (1-2 sentences)\n- Overall assessment (ACK with suggestions / needs work / concept concerns)\n- Key concerns if any\n- What was done well\n\nBe direct but constructive.\n\n</code></pre>\n<hr>\n<p>It\u2019s kind of a mixture between things I specifically want it to consider, <code>developer-notes.md</code> and various other additions/removals.</p>\n<p>I have in a global <code>CLAUDE.md</code> things like:</p>\n<blockquote>\n<pre><code class=\"lang-auto\">### Self-Improvement Loop\n- After ANY correction or finding: update `lessons.md` with the pattern\n- Write rules that prevent the same mistake\n- Review lessons at session start\n</code></pre>\n</blockquote>\n<p>I uploaded a few of my settings to <a href=\"https://github.com/willcl-ark/.claude\" class=\"inline-onebox\">GitHub - willcl-ark/.claude</a> in case any of interest.</p>\n<p>One thing I definitely need to step up though it running it more containerised than I do currently. I\u2019ve seen firsthand it ignore disallowed commands, or run them in alternative ways to bypass things, and I don\u2019t believe for a moment that it will e.g. follow the intent of never reading a .env file; I\u2019ve seen it iterate <code>env</code> before in python for example.</p>",
  "post_number": 4,
  "post_type": 1,
  "posts_count": 4,
  "updated_at": "2026-02-23T09:12:06.600Z",
  "reply_count": 0,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 0,
  "reads": 13,
  "readers_count": 12,
  "score": 2.4,
  "yours": false,
  "topic_id": 2277,
  "topic_slug": "using-ai-tooling-for-code-review",
  "topic_title": "Using AI tooling for code review",
  "topic_html_title": "Using AI tooling for code review",
  "category_id": 8,
  "display_username": "will",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "I have also been experimenting with almost exactly this using a `review-core` command in Claude code. It's certainly a long way from perfect, and if I'm honest it does spot a few too many false-positives for my liking, but it is reasonably thorough, and often provides a decent starting spot go go from, or more regularly a sanity check against my own thoughts after I've done my own review. I haven't decided yet if I prefer to run this before or after my own review, as both seem to have their merits (and downsides)...\n\nThe command I am currently using is:\n\n----\n\n[code]\n# Bitcoin Core Code Review\n\nYou are assisting the user's review of Bitcoin Core code \u2014 security-critical software managing billions in value. Surface findings and concerns for the user to evaluate; don't produce a finished review or draw final conclusions on their behalf.\n\n## Review Process\n\n1. First, fetch upstream and identify what is being reviewed:\n   ```bash\n   git fetch upstream\n   ```\n   - If no argument provided, review the current branch's changes against `upstream/master`\n   - If a PR number is provided, fetch and review that PR\n\n2. Fetch PR context from GitHub (if reviewing a PR):\n   ```bash\n   gh pr view <number> --repo bitcoin/bitcoin\n   ```\n   The PR description often contains valuable context: motivation, design decisions, and related issues/PRs. Read it carefully before diving into code.\n\n3. Find the merge base, then gather context by examining the diff:\n   ```bash\n   git merge-base upstream/master HEAD\n   ```\n   ```bash\n   git diff <merge-base>..HEAD\n   ```\n   If the merge-base equals HEAD (PR already merged), diff against the parent of the first PR commit instead.\n\n4. Apply the checklist below systematically\n\n## Priority Checklist\n\n### Concept & Justification\n- Is this change worth making? Don't take the premise for granted \u2014 question it\n- Does the implementation actually achieve its stated goal?\n- Is the benefit proportional to the complexity and review burden?\n\n### Security & Consensus\n- Could this change affect consensus behavior? Flag for extensive review\n- Check for integer overflows, memory safety issues, undefined behavior\n- Verify all user/network input is validated before use\n- Look for DoS vectors (unbounded memory/CPU, slow paths attackers can trigger)\n- Ensure cryptographic code uses constant-time operations where needed\n\n### Threading & Locking\n- Verify lock annotations (`EXCLUSIVE_LOCKS_REQUIRED`, `LOCKS_EXCLUDED`) are correct and complete\n- Check lock ordering\u2014would this introduce potential deadlocks?\n- Confirm `AssertLockHeld()` calls match annotations\n- Flag any use of `RecursiveMutex` where `Mutex` would suffice\n\n### Code Quality\n- Does the change do one thing well, or is it trying to do too much?\n- Does this fix the root cause, or just the symptom?\n- Are there unnecessary changes mixed in (refactors bundled with behavior changes)?\n- Is the commit history logical and bisectable?\n- Do commit messages explain *why*, not just *what*?\n- Could a reviewer who didn't write this code maintain and debug it later?\n\n### Testing\n- Are there unit tests for new/changed logic?\n- For RPC/P2P changes, are there functional tests?\n- Do existing tests still make sense, or do they need updating?\n- Consider edge cases: empty inputs, maximum values, malformed data\n\n### Style & Conventions\n- Named arguments for booleans: `Foo(/*flag=*/true)` not `Foo(true)`\n- Prefer `std::optional` over sentinel values\n- No `std::map::operator[]` for reads (use `.find()` or `.at()`)\n- Initialize all members at declaration\n\n## Design Analysis\n\nAfter applying the checklist, step back and analyze the PR's approach at a higher level. Generate and answer these questions in your review under a \"### Design Analysis\" heading, after the line-by-line findings and before the summary.\n\n### Motivation & Threat Model\n- What problem or attack does this change address? Explain the threat model or gap being closed.\n- Why does Bitcoin Core specifically benefit from this? Connect to concrete risks (DoS, privacy, censorship resistance, etc).\n- If this is a defense/hardening measure, what's the residual risk with and without it?\n\n### Approach Robustness\n- Could the chosen approach produce incorrect behavior under any scenario? Walk through failure modes explicitly.\n- What assumptions does the approach rely on? Are those assumptions guaranteed or merely conventional?\n- If there's a fallback/retry mechanism: can it loop infinitely, mask real errors, or leave inconsistent state?\n- What happens when upstream dependencies (Tor, OS, libs) change behavior? Is the approach brittle to version changes?\n\n### Alternative Approaches\n- Is there a simpler or more robust way to achieve the same goal? Consider what the PR chose *not* to do and why that tradeoff is or isn't justified.\n- Would a different approach avoid failure modes present in the current one?\n- If the current approach is the best one, say so and briefly explain why the alternatives are worse.\n\n### Strategic Assessment\n- What maintenance burden does this create? Will this need updating as dependencies (Tor, libraries, protocols) evolve?\n- Does this establish a pattern or precedent that future PRs will follow? Is that a pattern we want?\n- Is this the right layer to solve this problem? Should it be handled upstream, downstream, or by configuration instead of code?\n- For Bitcoin Core specifically: does this increase attack surface, trust assumptions, or dependency coupling in a way that's disproportionate to the gain?\n\nBe specific \u2014 name the scenarios and tradeoffs, don't just say \"this could go wrong\" or \"there might be a better way.\"\n\n## Output Format\n\nFor each concern found, report:\n\n```\n**[SEVERITY]** `file:line` - Brief description\n\nIssue: What's wrong\nSuggestion: How to fix it\n```\n\nSeverities:\n- **BLOCKING** - Must fix before merge (security, correctness, consensus)\n- **SHOULD-FIX** - Strong recommendation (bugs, significant issues)\n- **NIT** - Minor style or preference (optional to address)\n\n## Summary Section\n\nEnd with a summary:\n- What the PR accomplishes (1-2 sentences)\n- Overall assessment (ACK with suggestions / needs work / concept concerns)\n- Key concerns if any\n- What was done well\n\nBe direct but constructive.\n\n\n[/code]\n\n----\n\nIt's kind of a mixture between things I specifically want it to consider, `developer-notes.md` and various other additions/removals.\n\nI have in a global `CLAUDE.md` things like:\n\n> ```\n> ### Self-Improvement Loop\n> - After ANY correction or finding: update `lessons.md` with the pattern\n> - Write rules that prevent the same mistake\n> - Review lessons at session start\n> ```\n\nI uploaded a few of my settings to https://github.com/willcl-ark/.claude in case any of interest.\n\nOne thing I definitely need to step up though it running it more containerised than I do currently. I've seen firsthand it ignore disallowed commands, or run them in alternative ways to bypass things, and I don't believe for a moment that it will e.g. follow the intent of never reading a .env file; I've seen it iterate `env` before in python for example.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 61,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "I have also been experimenting with almost exactly this using a review-core command in Claude code. It\u2019s certainly a long way from perfect, and if I\u2019m honest it does spot a few too many false-positives for my liking, but it is reasonably thorough, and often provides a decent starting spot go go from&hellip;",
  "truncated": true,
  "post_url": "/t/using-ai-tooling-for-code-review/2277/4",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}