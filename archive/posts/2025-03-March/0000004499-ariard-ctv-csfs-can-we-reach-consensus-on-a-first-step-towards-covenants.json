{
  "id": 4499,
  "name": "Antoine Riard",
  "username": "ariard",
  "avatar_template": "/letter_avatar_proxy/v4/letter/a/c67d28/{size}.png",
  "created_at": "2025-03-13T00:23:25.831Z",
  "cooked": "<h3><a name=\"p-4499-lightning-eltoo-1\" class=\"anchor\" href=\"#p-4499-lightning-eltoo-1\"></a>Lightning Eltoo</h3>\n<p>ajtowns:</p>\n<blockquote>\n<p>\"CTV+CSFS isn\u2019t equivalent to APO, it\u2019s somewhat more costly by requiring you to explicitly include the CTV hash in the witness data. The TXHASH approach is (in my opinion) a substantial improvement on that.\u201d</p>\n</blockquote>\n<p>stevenroose:</p>\n<blockquote>\n<p>\"I think it\u2019s fair to call something equivalent even if it\u2019s a little more costly but achieves the\nsame functionality. (Of course I wouldn\u2019t go as far to make the same argument for things like CAT where you have to dump the entire tx on stack including several dozen opcodes.) A better argument  would be that CTV+CSFS can only emulate APO|ALL and not the other APO flags. Though it seems that  the APO|ALL variant of APO has the most interest.\u201d</p>\n</blockquote>\n<p>I don\u2019t believe we can say things are equivalent when the marginal on-chain witness cost can fluctuates in the range of two-digits bytes. In Lightning, we already have to trim the outputs\nout of the commitment transaction, if the outputs scriptpubkeys + claiming input is superior to\nthe ongoing mempool feerates (very imperfect heuristic\u2026). This is a safety issue if you go to open LN chan with a miner, that you can never be sure of.</p>\n<p>Going for the more expensive Eltoo, i.e the one where the script stack has to provide <code>&lt;pubkey&gt;</code> <code>&lt;message&gt;</code> <code>&lt;signature&gt;</code>, where message size is equal to 32 bytes those 32 bytes compared to the <code>ANYPREVOUT</code> sighash approach that might make some chan unable to uncooperatively force-close, at a time of fee spikes.</p>\n<p>Note this concern on marginal channel or off-chain payment is something that very likely affects Ark too. It\u2019s even hard to compare the cost of a LN chan marginal payment vs the cost of a Ark marginal payment, as with ARK you have an ASP and you have to come with some probabilistic estimations for the interactivity of the ASP.</p>\n<p>If my memory is correct, the efficiency approach of logically equivalent primitive was already discussed in the <code>OP_CHECKMERKLEBRANCHVERIFY</code> vs check-if-this-is-a-PTR2 templated\napproach (i.e BIP341).</p>\n<h3><a name=\"p-4499-discreet-log-contracts-2\" class=\"anchor\" href=\"#p-4499-discreet-log-contracts-2\"></a>Discreet Log Contracts</h3>\n<p>ajtowns:</p>\n<blockquote>\n<p>\u201cDoesn\u2019t having CSFS available on its own give you equally efficient and much more flexible\nsimplifications of DLCs? I think having CAT available as well would probably also be fairly\npowerful here\u201d.</p>\n</blockquote>\n<p>See this <a href=\"https://github.com/bitcoinops/bitcoinops.github.io/pull/806\">thread</a> on Optech Github for the trade-offs on the usage of CTV of Discreet Log Contracts.</p>\n<p>tl;dr: With adding a hash for each CTV outcome, there is a logarithmic growth of the witness script size (i.e <code>&lt;hash1_event&gt;</code> <code>&lt;OP_CTV&gt;</code> <code>&lt;hash2_event&gt;</code> <code>&lt;OP_CTV&gt;</code>), if the bet is logarithmic in its structure. Evaluating what primitive is the best for a Discreet Log Contract is very function of (1) what is the marginally value \u201cbet on\u201d and (2) what is the probabilistic structure of the bet (i.e are you betting on a price where equal chance among all outcomes or a bet sport where ranges scores can be approximated).</p>\n<h3><a name=\"p-4499-push-based-approach-templating-3\" class=\"anchor\" href=\"#p-4499-push-based-approach-templating-3\"></a>Push-Based Approach Templating</h3>\n<p>stevenroose:</p>\n<blockquote>\n<p>The TXHASH BIP explicitly also specifies to enable CHECKTXHASHVERIFY in legacy and segwit\ncontext and outlines how hashes should be calculated for those contexts.</p>\n</blockquote>\n<p>See the old Johnson Lau <a href=\"https://github.com/jl2012/bips/blob/ce4a6980c89859b8f5c9074b6f219f973e4d9128/bip-0ZZZ.mediawiki\">idea</a> with <code>OP_PUSHDATADATA</code> for another variant of push-approach.</p>\n<p>My belief on the push-vs-implicit-access-with-sigs digest, it\u2019s all up to wish semantic you wish to check on the spending transaction of your constrained UTXO, and if it\u2019s not a templated approach, what is shortest path for stack operations among a N number of transactions fields.</p>\n<p>Of course, there can be numerous low-level details of primitive implementation to make that more efficient, like bitvector, special opcodes to push target input or assumptions on the \u201cmost-likely\u201d fetched transaction fields.</p>\n<p>I don\u2019t know if it\u2019s a programming model we wish to move towards wish\u2026This would start to be very likely to ASM where you have to program CPU registers at the bit-level. If you think Bitcoin Script programming is already low-level and error-prone, this is an order of magnitude worst. Complexity for the use-case programmer at the benefit of more on-chain efficiency.</p>\n<h3><a name=\"p-4499-on-the-taproot-rush-4\" class=\"anchor\" href=\"#p-4499-on-the-taproot-rush-4\"></a>On the Taproot Rush</h3>\n<p>ajtowns:</p>\n<blockquote>\n<p>So much for \u201cI won\u2019t be \u2026 pointing fingers\u201d, I guess? In any event, I would personally argue this was a serious flaw in how we deployed taproot, and one that we shouldn\u2019t repeat.</p>\n</blockquote>\n<p>I share the opinion, that we could have spent more time doing experimentations of the use-case enabled by Schnorr / Taproot. There was a <a href=\"https://github.com/BlockstreamResearch/scriptless-scripts/blob/fd2000d2c30cc8d9125ecd85b0dc14edf32266a3/md/multi-hop-locks.md\">research page</a> at the time listing all the ideas enabled by Schnorr. I did an <a href=\"https://github.com/lightningdevkit/rust-lightning/issues/605\">experiment</a> to implement PTLC+DLC in early ~2020 for Discreet Log Contract. The learning I\u2019ve come from it that we would have to seriously re-write the LN state machine. As far as I can tell, this has been confirmed by the more recent research of other LN folks.</p>\n<p>On the more conceptual limitations of the Taproot, the lack of commitment in the control block of the oddness of an internal pubkey is a limitation to leverage a Schnorr signature as mutable cryptographic accumulator for payments pools. This limitation was known before the activation of Taproot, and it has been discussed few times on the mailing list and <a href=\"https://bitcoinops.org/en/newsletters/2021/09/15/#covenant-opcode-proposal\">documented</a> by Optech.</p>\n<p>On the merge of the Taproot feature, let\u2019s remember that <a href=\"https://github.com/bitcoin/bitcoin/pull/19953\">the PR implementing it</a> was merged the latest day of the feature freeze for 0.21.0, which I don\u2019t believe I was the only one to find it was a bit of a rush\u2026</p>\n<p>One can see the names who have ACKed the merged commit at the time on the Github pull\nrequest, as I think seriously reviewing and testing code for a consensus change is always more expensive than talking about it:</p>\n<ul>\n<li>instagibbs</li>\n<li>benthecarman</li>\n<li>kallewoof</li>\n<li>jonasnick</li>\n<li>fjahr</li>\n<li>achow101</li>\n<li>jamesob (post-merge)</li>\n<li>ajtowns (post-merge)</li>\n<li>ariard (post-merge)</li>\n<li>marcofalke (post-merge)</li>\n</ul>\n<h3><a name=\"p-4499-on-the-usage-of-the-covenant-word-5\" class=\"anchor\" href=\"#p-4499-on-the-usage-of-the-covenant-word-5\"></a>On the usage of the \"Covenant\u201d word</h3>\n<p>ajtowns:</p>\n<blockquote>\n<p>Personally, I think the biggest blocker to progress here continues to be CTV\u2019s misguided\ndescription of \u201ccovenants\u201d, and its misguided and unjustified concern about \u201crecursive covenants\u201d.</p>\n</blockquote>\n<p>To be fair here the usage of the word covenant in Bitcoin is not Jeremy\u2019s initiative. I think it comes with Gmax \"<a href=\"https://bitcointalk.org/index.php?topic=278122.0\">CoinCovenants using SCIP signatures, an amuingly bad idea</a>\u201d bitcoin talk org article in 2013, and it was in the aftermath also used by folks like Roconnor, Johnson Lau, Roasbeef or even by myself as early as 2019 when OP_CTV was still called OP_SECURETHEBAG.</p>\n<p>I\u2019m not aware if Satoshi herself / himself has used the word covenant in its public writing. However the idea to use Script for many use-cases beyond payments, that\u2019s Satoshi, there is quote in the sense somewhere talking about escrow and having to think carefully the design of Script ahead.</p>\n<p>The problem of \u201crecursive covenants\u201d is also layout in Gmax\u2019s article of 2013, as a basic question, if malicious \u201ccovenants\u201d could be devised or thought at lot, and it was abundantly commented at the time on bitcoin talk org.</p>\n<h3><a name=\"p-4499-on-the-lack-of-enthusiasm-for-lightning-eltoo-6\" class=\"anchor\" href=\"#p-4499-on-the-lack-of-enthusiasm-for-lightning-eltoo-6\"></a>On the lack of enthusiasm for Lightning / Eltoo</h3>\n<p>1440000bytes:</p>\n<blockquote>\n<p>We see an arrogance and non sense being repeated here by developers who are misusing their reputation in the community. Some of these developers have no reasons to block CTV and been writing non sense for years that affects bitcoin.</p>\n</blockquote>\n<p>To bring more context on why there is a lack of enthusiasm for Eltoo Lightning, during the year of 2022, Greg Sanders have worked on a fork of core-lightning with eltoo support and this was reviewed multiple times by AJ Towns and myself.</p>\n<p>This is during the review of this Lightning-Eltoo and considering hypothetical novel attacks on eltoo Lightning (\u201cUpdates Overflow\u201d Attacks against Two-Party Eltoo ?\"), that I found was is (sadly) known today as Replacement Cycling Attacks.</p>\n<p>This is for a very experimental point, if you believe that reviewing complex Bitcoin second-layers is shamanism or gatekeeping. I still strongly believe that end-to-end PoC\u2019ing, testing and adversarial review is a good practice to get secure protocols, and no not all second-layers issues can be fixed \u201cin flight\u201d like \u201cthat\u201d, especially if the fixes commands themselves for serious engineering works at the base-layer (e.g better replacement / eviction policy algorithms).</p>\n<h3><a name=\"p-4499-ark-ctv-7\" class=\"anchor\" href=\"#p-4499-ark-ctv-7\"></a>Ark + CTV</h3>\n<p>stevenroose:</p>\n<blockquote>\n<p>But we have been working on this implementation for over 6 months, it is\nworking on bitcoin\u2019s vanilla signet, we have ample integration tests that\ntest various unilateral exit scenarios and all of these are passing for\nthe ctv-based trees.</p>\n</blockquote>\n<p>If I\u2019m understanding correctly, Ark is argued as an example of a near-production or production-ready use-case that would benefit from a hash-chain covenant like CTV. Given Ark is relying on a single \u201cblessed party\u201d the ASP, I\u2019m still curious how an ASP client can be sure that he can redeems its balance on-chain in a collaborative on-chain.</p>\n<p>Namely, how do you generalize the fair exchange of a secret to a N number of parties, where among the set of N there is blessed party M, how do you avoid collusion between the N-1 parties + the blessed party M against the N party. Fair exchange of secret is quite studied the 90\u2019s distributed litterature. There were papers also few years ago on Lightning, analyzing unsafe update mechanism for many parties.</p>\n<p>Of course, you can do a congestion control tree embedded in the on-chain swap UTXO coming the ASP, but now there is no efficiency gain remained for the usage of CTV (nVersion / nLocktime fields penalty for each depth of the tree).</p>\n<h3><a name=\"p-4499-vault-ctv-better-primitives-8\" class=\"anchor\" href=\"#p-4499-vault-ctv-better-primitives-8\"></a>Vault + CTV / better primitives</h3>\n<p>jamesob:</p>\n<blockquote>\n<p>Beyond that, as you should recall from your VAULT days, CTV (or an equivalent)\nis a necessary prerequisite to doing any kind of \u201cbetter\u201d vault. It\u2019s tablestakes.\nRob Hamilton recently substantiated the industry demand for good vaults, using\nVAULT or similar, and once again I can corroborate firsthand there.</p>\n</blockquote>\n<p>The issue, with vault, is of course dynamics fees for time-sensitive transactions, and if I remember correctly the emergency path, which is a time-sensitive path you have to be sure dynamic fees works well. Even if you pre-sign at some crazy rate, there is no guarantee that you won\u2019t have a nation-state sponsoring hacking group going to engage in a feerate race to delay the confirmation (e.g costless bribes to the miners), until the compromised withdrawal can confirm.</p>\n<p>This is not paranoia, if one follows smart contract exploits in the wider cryptocurrencies world (free to check rekt.news), you often see hacks in the $100M - $500M range. So an attacker going to burn 10% of the targeted value in miner bribing fees do not seem unrealistic or unreasonable to me. If you assume that attacker has already keys for the withdrawal or unvault target \"hot\u201d wallet.</p>\n<p>To be frank, fixing dynamics fess, it\u2019s very likely going to be someting in the line of \u201c<a href=\"https://bitcoinops.org/en/newsletters/2024/01/03/#fee-dependent-timelocks\">fee-dependent timelocks</a>\". And here everyone is free to believe or not (don\u2019t trust, verify), under all technical info and hypothesis I\u2019m aware off, eventually those are not going to be simple consensus changes\u2026</p>\n<p>Now, on the more precise question of CheckTemplateVerify and its usage for vaults, the best piece of information I\u2019m aware of for the key-sig-vs-hash-chain is based on this Phd Thesis, section 4 \"<a href=\"https://arxiv.org/pdf/2310.11911\">Evolving Bitcoin Custody</a>\u201d.</p>\n<p>Of course, while CheckTemplateVerify introduces <em>immutability</em> of a chain of transactions, where intermediary vault transactions do not have to be pre-signed and corresponding privates key deleted, there is still the issue of key ceremony to be dealt with. After reorg-delay, though this a novel property if one goes to design bitcoin second-layers.</p>\n<p>If you\u2019re software engineer with know-how on the difference between userspace and kernelspace or familiarity with core Internet protocols (\u2026yes all those talks on bitcoin consensus changes can be very technical in the raw sense), keys ceremonies and overall corresponding operational guidelines can be an incredibly hard thing to get right. All depends the threat model considered, though it\u2019s hard thing to do, and hard to do it repeatedly in production.</p>\n<p>So what is key ceremony for bitcoin vaults ? This is dealing with the transition of the cold wallet to the hotter wallets, though for bitcoin this is not a only a \u201cblind signature\u201d, it\u2019s verifying that the spent utxo exists, that the unvaulting outputs <code>scriptPubkeys</code> are valid or at byte-for-byte equal to the one that are going to be verified by the Script by bitcoin full-nodes at run-time.</p>\n<p>As people who are familiar with the <a href=\"https://vls.tech/\">Validating Lightning Signer</a>, series of custom checks and the situation there are to have re-write a LN state machine embeddable for the constraint of a secure enclave, being sure that your vault is the \u201ccorrect\u201d vault in production is a bit more complex safety-wise than is this a P2WSH yes or no.</p>\n<p>So I strongly believe the bottleneck we have to evaluate a CTV-enabled vault is a vault proof-of-concept specified enough that all the logic of the vault can be described with chain headers, UTXO proofs and outputs descriptors that they can be given through a carefully-designed interface to a HW or secure enclave and have the vault setup verification done there.</p>\n<p><strong>Do we have any bitcoin HW vendors or secure enclave vendors</strong>\n<strong>ready-to-extend their interfaces for a simple <a href=\"https://github.com/jamesob/simple-ctv-vault\">2-steps</a> CTV vault protocol ?</strong></p>\n<p>Not only with output script support though also with any efficient proving of the UTXO set, which can be challenging programming-wise as secure enclave RAM and cache memory is limited, by design. And as far as I researched so far, constrained templating like CTV do not comes with <a href=\"https://blog.bitmex.com/txwithhold-smart-contracts/\">tx-withhold risks</a> and do not alter the UTXO model, though my thanks if you prove me wrong here.</p>",
  "post_number": 27,
  "post_type": 1,
  "updated_at": "2025-03-13T00:28:28.752Z",
  "reply_count": 1,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 0,
  "reads": 11,
  "readers_count": 10,
  "score": 2.2,
  "yours": false,
  "topic_id": 1509,
  "topic_slug": "ctv-csfs-can-we-reach-consensus-on-a-first-step-towards-covenants",
  "topic_title": "CTV+CSFS: Can we reach consensus on a first step towards covenants?",
  "topic_html_title": "CTV+CSFS: Can we reach consensus on a first step towards covenants?",
  "category_id": 7,
  "display_username": "Antoine Riard",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "### Lightning Eltoo\n\najtowns:\n> \"CTV+CSFS isn\u2019t equivalent to APO, it\u2019s somewhat more costly by requiring you to explicitly include the CTV hash in the witness data. The TXHASH approach is (in my opinion) a substantial improvement on that.\u201d\n\nstevenroose:\n> \"I think it\u2019s fair to call something equivalent even if it\u2019s a little more costly but achieves the\n> same functionality. (Of course I wouldn\u2019t go as far to make the same argument for things like CAT where you have to dump the entire tx on stack including several dozen opcodes.) A better argument  would be that CTV+CSFS can only emulate APO|ALL and not the other APO flags. Though it seems that  the APO|ALL variant of APO has the most interest.\u201d\n\nI don't believe we can say things are equivalent when the marginal on-chain witness cost can fluctuates in the range of two-digits bytes. In Lightning, we already have to trim the outputs\nout of the commitment transaction, if the outputs scriptpubkeys + claiming input is superior to\nthe ongoing mempool feerates (very imperfect heuristic...). This is a safety issue if you go to open LN chan with a miner, that you can never be sure of.\n\nGoing for the more expensive Eltoo, i.e the one where the script stack has to provide `<pubkey>` `<message>` `<signature>`, where message size is equal to 32 bytes those 32 bytes compared to the `ANYPREVOUT` sighash approach that might make some chan unable to uncooperatively force-close, at a time of fee spikes.\n\nNote this concern on marginal channel or off-chain payment is something that very likely affects Ark too. It's even hard to compare the cost of a LN chan marginal payment vs the cost of a Ark marginal payment, as with ARK you have an ASP and you have to come with some probabilistic estimations for the interactivity of the ASP.\n\nIf my memory is correct, the efficiency approach of logically equivalent primitive was already discussed in the `OP_CHECKMERKLEBRANCHVERIFY` vs check-if-this-is-a-PTR2 templated\napproach (i.e BIP341).\n\n### Discreet Log Contracts\n\najtowns:\n\n>  \"Doesn\u2019t having CSFS available on its own give you equally efficient and much more flexible\n> simplifications of DLCs? I think having CAT available as well would probably also be fairly \n> powerful here\".\n\nSee this [thread](https://github.com/bitcoinops/bitcoinops.github.io/pull/806) on Optech Github for the trade-offs on the usage of CTV of Discreet Log Contracts.\n\ntl;dr: With adding a hash for each CTV outcome, there is a logarithmic growth of the witness script size (i.e `<hash1_event>` `<OP_CTV>` `<hash2_event>` `<OP_CTV>`), if the bet is logarithmic in its structure. Evaluating what primitive is the best for a Discreet Log Contract is very function of (1) what is the marginally value \"bet on\" and (2) what is the probabilistic structure of the bet (i.e are you betting on a price where equal chance among all outcomes or a bet sport where ranges scores can be approximated).\n\n### Push-Based Approach Templating\n\nstevenroose:\n> The TXHASH BIP explicitly also specifies to enable CHECKTXHASHVERIFY in legacy and segwit\n> context and outlines how hashes should be calculated for those contexts. \n\nSee the old Johnson Lau [idea](https://github.com/jl2012/bips/blob/ce4a6980c89859b8f5c9074b6f219f973e4d9128/bip-0ZZZ.mediawiki) with `OP_PUSHDATADATA` for another variant of push-approach.\n\nMy belief on the push-vs-implicit-access-with-sigs digest, it's all up to wish semantic you wish to check on the spending transaction of your constrained UTXO, and if it's not a templated approach, what is shortest path for stack operations among a N number of transactions fields.\n\nOf course, there can be numerous low-level details of primitive implementation to make that more efficient, like bitvector, special opcodes to push target input or assumptions on the \"most-likely\" fetched transaction fields.\n\nI don't know if it's a programming model we wish to move towards wish...This would start to be very likely to ASM where you have to program CPU registers at the bit-level. If you think Bitcoin Script programming is already low-level and error-prone, this is an order of magnitude worst. Complexity for the use-case programmer at the benefit of more on-chain efficiency.\n\n### On the Taproot Rush\n\najtowns:\n> So much for \u201cI won\u2019t be \u2026 pointing fingers\u201d, I guess? In any event, I would personally argue this was a serious flaw in how we deployed taproot, and one that we shouldn\u2019t repeat.\n\nI share the opinion, that we could have spent more time doing experimentations of the use-case enabled by Schnorr / Taproot. There was a [research page](https://github.com/BlockstreamResearch/scriptless-scripts/blob/fd2000d2c30cc8d9125ecd85b0dc14edf32266a3/md/multi-hop-locks.md) at the time listing all the ideas enabled by Schnorr. I did an [experiment](https://github.com/lightningdevkit/rust-lightning/issues/605) to implement PTLC+DLC in early ~2020 for Discreet Log Contract. The learning I\u2019ve come from it that we would have to seriously re-write the LN state machine. As far as I can tell, this has been confirmed by the more recent research of other LN folks.\n\nOn the more conceptual limitations of the Taproot, the lack of commitment in the control block of the oddness of an internal pubkey is a limitation to leverage a Schnorr signature as mutable cryptographic accumulator for payments pools. This limitation was known before the activation of Taproot, and it has been discussed few times on the mailing list and [documented](https://bitcoinops.org/en/newsletters/2021/09/15/#covenant-opcode-proposal) by Optech.\n\nOn the merge of the Taproot feature, let's remember that [the PR implementing it](https://github.com/bitcoin/bitcoin/pull/19953) was merged the latest day of the feature freeze for 0.21.0, which I don\u2019t believe I was the only one to find it was a bit of a rush\u2026\n\nOne can see the names who have ACKed the merged commit at the time on the Github pull\nrequest, as I think seriously reviewing and testing code for a consensus change is always more expensive than talking about it:\n- instagibbs\n- benthecarman\n- kallewoof\n- jonasnick\n- fjahr\n- achow101\n- jamesob (post-merge)\n- ajtowns (post-merge)\n- ariard (post-merge)\n- marcofalke (post-merge)\n\n### On the usage of the \"Covenant\u201d word\n\najtowns:\n> Personally, I think the biggest blocker to progress here continues to be CTV\u2019s misguided\n> description of \u201ccovenants\u201d, and its misguided and unjustified concern about \u201crecursive covenants\u201d.\n\nTo be fair here the usage of the word covenant in Bitcoin is not Jeremy's initiative. I think it comes with Gmax \"[CoinCovenants using SCIP signatures, an amuingly bad idea](https://bitcointalk.org/index.php?topic=278122.0)\u201d bitcoin talk org article in 2013, and it was in the aftermath also used by folks like Roconnor, Johnson Lau, Roasbeef or even by myself as early as 2019 when OP_CTV was still called OP_SECURETHEBAG.\n\nI'm not aware if Satoshi herself / himself has used the word covenant in its public writing. However the idea to use Script for many use-cases beyond payments, that\u2019s Satoshi, there is quote in the sense somewhere talking about escrow and having to think carefully the design of Script ahead.\n\nThe problem of \"recursive covenants\" is also layout in Gmax's article of 2013, as a basic question, if malicious \"covenants\" could be devised or thought at lot, and it was abundantly commented at the time on bitcoin talk org.\n\n### On the lack of enthusiasm for Lightning / Eltoo\n\n1440000bytes:\n> We see an arrogance and non sense being repeated here by developers who are misusing their reputation in the community. Some of these developers have no reasons to block CTV and been writing non sense for years that affects bitcoin.\n\nTo bring more context on why there is a lack of enthusiasm for Eltoo Lightning, during the year of 2022, Greg Sanders have worked on a fork of core-lightning with eltoo support and this was reviewed multiple times by AJ Towns and myself.\n\nThis is during the review of this Lightning-Eltoo and considering hypothetical novel attacks on eltoo Lightning (\"Updates Overflow\" Attacks against Two-Party Eltoo ?\"), that I found was is (sadly) known today as Replacement Cycling Attacks.\n\nThis is for a very experimental point, if you believe that reviewing complex Bitcoin second-layers is shamanism or gatekeeping. I still strongly believe that end-to-end PoC'ing, testing and adversarial review is a good practice to get secure protocols, and no not all second-layers issues can be fixed \"in flight\" like \"that\", especially if the fixes commands themselves for serious engineering works at the base-layer (e.g better replacement / eviction policy algorithms).\n\n### Ark + CTV\n\nstevenroose:\n> But we have been working on this implementation for over 6 months, it is\n> working on bitcoin\u2019s vanilla signet, we have ample integration tests that\n> test various unilateral exit scenarios and all of these are passing for\n> the ctv-based trees.\n\nIf I'm understanding correctly, Ark is argued as an example of a near-production or production-ready use-case that would benefit from a hash-chain covenant like CTV. Given Ark is relying on a single \"blessed party\" the ASP, I'm still curious how an ASP client can be sure that he can redeems its balance on-chain in a collaborative on-chain.\n\nNamely, how do you generalize the fair exchange of a secret to a N number of parties, where among the set of N there is blessed party M, how do you avoid collusion between the N-1 parties + the blessed party M against the N party. Fair exchange of secret is quite studied the 90's distributed litterature. There were papers also few years ago on Lightning, analyzing unsafe update mechanism for many parties.\n\nOf course, you can do a congestion control tree embedded in the on-chain swap UTXO coming the ASP, but now there is no efficiency gain remained for the usage of CTV (nVersion / nLocktime fields penalty for each depth of the tree).\n\n### Vault + CTV / better primitives\n\njamesob:\n> Beyond that, as you should recall from your VAULT days, CTV (or an equivalent)\n> is a necessary prerequisite to doing any kind of \u201cbetter\u201d vault. It\u2019s tablestakes.\n> Rob Hamilton recently substantiated the industry demand for good vaults, using\n> VAULT or similar, and once again I can corroborate firsthand there.\n\nThe issue, with vault, is of course dynamics fees for time-sensitive transactions, and if I remember correctly the emergency path, which is a time-sensitive path you have to be sure dynamic fees works well. Even if you pre-sign at some crazy rate, there is no guarantee that you won't have a nation-state sponsoring hacking group going to engage in a feerate race to delay the confirmation (e.g costless bribes to the miners), until the compromised withdrawal can confirm.\n\nThis is not paranoia, if one follows smart contract exploits in the wider cryptocurrencies world (free to check rekt.news), you often see hacks in the $100M - $500M range. So an attacker going to burn 10% of the targeted value in miner bribing fees do not seem unrealistic or unreasonable to me. If you assume that attacker has already keys for the withdrawal or unvault target \"hot\u201d wallet.\n\nTo be frank, fixing dynamics fess, it's very likely going to be someting in the line of \u201c[fee-dependent timelocks](https://bitcoinops.org/en/newsletters/2024/01/03/#fee-dependent-timelocks)\". And here everyone is free to believe or not (don't trust, verify), under all technical info and hypothesis I'm aware off, eventually those are not going to be simple consensus changes\u2026\n\nNow, on the more precise question of CheckTemplateVerify and its usage for vaults, the best piece of information I'm aware of for the key-sig-vs-hash-chain is based on this Phd Thesis, section 4 \"[Evolving Bitcoin Custody](https://arxiv.org/pdf/2310.11911)\u201d.\n\nOf course, while CheckTemplateVerify introduces _immutability_ of a chain of transactions, where intermediary vault transactions do not have to be pre-signed and corresponding privates key deleted, there is still the issue of key ceremony to be dealt with. After reorg-delay, though this a novel property if one goes to design bitcoin second-layers.\n\nIf you're software engineer with know-how on the difference between userspace and kernelspace or familiarity with core Internet protocols (...yes all those talks on bitcoin consensus changes can be very technical in the raw sense), keys ceremonies and overall corresponding operational guidelines can be an incredibly hard thing to get right. All depends the threat model considered, though it\u2019s hard thing to do, and hard to do it repeatedly in production.\n\nSo what is key ceremony for bitcoin vaults ? This is dealing with the transition of the cold wallet to the hotter wallets, though for bitcoin this is not a only a \"blind signature\", it's verifying that the spent utxo exists, that the unvaulting outputs `scriptPubkeys` are valid or at byte-for-byte equal to the one that are going to be verified by the Script by bitcoin full-nodes at run-time.\n\nAs people who are familiar with the [Validating Lightning Signer](https://vls.tech/), series of custom checks and the situation there are to have re-write a LN state machine embeddable for the constraint of a secure enclave, being sure that your vault is the \"correct\" vault in production is a bit more complex safety-wise than is this a P2WSH yes or no.\n\nSo I strongly believe the bottleneck we have to evaluate a CTV-enabled vault is a vault proof-of-concept specified enough that all the logic of the vault can be described with chain headers, UTXO proofs and outputs descriptors that they can be given through a carefully-designed interface to a HW or secure enclave and have the vault setup verification done there.\n\n**Do we have any bitcoin HW vendors or secure enclave vendors**\n**ready-to-extend their interfaces for a simple [2-steps](https://github.com/jamesob/simple-ctv-vault) CTV vault protocol ?**\n\nNot only with output script support though also with any efficient proving of the UTXO set, which can be challenging programming-wise as secure enclave RAM and cache memory is limited, by design. And as far as I researched so far, constrained templating like CTV do not comes with [tx-withhold risks](https://blog.bitmex.com/txwithhold-smart-contracts/) and do not alter the UTXO model, though my thanks if you prove me wrong here.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 5,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": "Github link was replaced with a permanent link",
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}