{
  "id": 4481,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2025-03-12T03:11:53.178Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"stevenroose\" data-post=\"1\" data-topic=\"1509\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/stevenroose/48/1087_2.png\" class=\"avatar\"> stevenroose:</div>\n<blockquote>\n<p>has been deployed on various <a href=\"https://github.com/bitcoin-inquisition/bitcoin\">test networks</a> and has been used to develop <a href=\"https://utxos.org/uses/\">several use cases</a>.</p>\n</blockquote>\n</aside>\n<p>I like the aphorism \u201ctrust, but verify\u201d (of course, some Bitcoiners take it further with \u201cdon\u2019t trust, verify\u201d \u2013 but either way, the verification part is important). When I try to verify statements like these about CTV, they usually come up pretty lacking.</p>\n<p>Taking the specific examples you list for CTV+CSFS, rather than the ones on the utxos page:</p>\n<ul>\n<li>\u201cCTV+CSFS functions as an equivalent for SIGHASH_ANYPREVOUT (APO), which enables Lightning Symmetry (formerly Eltoo)\u201d</li>\n</ul>\n<p>CTV+CSFS isn\u2019t equivalent to APO, it\u2019s somewhat more costly by requiring you to explicitly include the CTV hash in the witness data. The <a href=\"https://gnusha.org/pi/bitcoindev/CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com/\">TXHASH</a> approach is (in my opinion) a substantial improvement on that.</p>\n<p>The TXHASH approach would be a taproot-only solution (as is CSFS), which would have the benefit of both simplifying the change (removing policy considerations for relay of bare-CTV txs, not having to consider the CTV in P2SH being unsatisfiable), and removing the need for segwit-related hashes to be precalculated for non-segwit transactions, preventing <a href=\"https://github.com/bitcoin/bitcoin/pull/21702#pullrequestreview-859718084\">the potential for IBD slowdown</a>, and not requiring complicated workarounds. I believe the only cost would be adding 70 witness bytes to txs in the \u201ccongestion control\u201d use case, however that use case doesn\u2019t seem viable in the first place to me.</p>\n<p>(Strictly, \u201cTXHASH EQUAL\u201d is perhaps an extra witness byte compared to \u201cCTV\u201d, though \u201cTXHASH EQUALVERIFY\u201d is the same as \u201cCTV DROP\u201d. \u201c[sig] TXHASH [p] CSFS\u201d is probably a byte cheaper than APO, since you add \u201cTXHASH\u201d but save both a SIGHASH byte and a public key version byte. TXHASH also has the benefit that you can just run the script \u201cTXHASH\u201d through a script interpreter to get the TXHASH you want to commit to, rather than having to construct it out of band)</p>\n<p>Beyond that, the exploration into ln-symmetry has been both fairly preliminary (to the best of my knowledge, nobody has been able to reproduce Greg\u2019s results; I\u2019ve tried, and I believe cguida has as well \u2013 ie, the \u201cverify\u201d part hasn\u2019t succeeded in general). It also used APO, the annex, and some custom relay rules, not CTV or CSFS or the current TRUC/ephemeral anchor model, so even if it did provide good evidence that eltoo was possible with APO, someone would still need to do the work to redesign it for CTV/TXHASH/CSFS before it was good evidence for that approach. I suspect TXHASH, CAT and CSFS would actually be a good combination here, as that would allow for a single signature to easily commit to both the tx and publication of some data while minimising wasted bytes and without needing to allow relay of random data in the annex. (Doing an adaptor signature rather than forcing publication of data would be more efficient on-chain, but seems to still be hard to convert from a whiteboard spec to an actual implementation)</p>\n<p>Unfortunately, eltoo/ln-symmetry doesn\u2019t seem to be a very high priority in the lightning space from what I can see \u2013 eg, see the <a href=\"https://x.com/TheBlueMatt/status/1859070516956389704\">priorities from LDK</a>.</p>\n<p>I think having both CAT and CSFS would make implementing PTLCs a bit easier \u2013 you could replace \u201c SIZE 32 EQUALVERIFY SHA256  EQUALVERIFY\u201d with \u201c SIZE 32 EQUALVERIFY  TUCK CAT SWAP DUP CSFS\u201d where \u201cy\u201d is the the s-part of the signature, calculated as preimage/(1+H(x,x,x)). Not simple per se, but separates out the PTLC calculation for the signing of the tx as a whole (avoiding the need for adaptor signatures), and only needs to be calculated once, not once per channel update. I can\u2019t see a way to get the same result from just CSFS alone.</p>\n<ul>\n<li>\u201cI am obviously biased here, but CTV is a game-changer for Ark\u201d</li>\n</ul>\n<p>When I looked into this, <a href=\"https://x.com/ajtowns/status/1856635064941166753\">as far as I could tell</a> Ark has been built based on the elements introspection opcodes and on pre-signed transactions, but there has been no practical exploration into actually using it with CTV. For something that was announced as being implementable either with BIP 118 (APO) or BIP 119 (CTV), never having actually done that comes across as a huge red flag for me, particularly when people are willing to implement crazy things like the \u201cpurrfect\u201d vaults.</p>\n<ul>\n<li>\u201cProtocols involving DLCs, which have been growing in popularity, can be significantly simplified using CTV.\u201d</li>\n</ul>\n<p>Doesn\u2019t having CSFS available on its own give you equally efficient and much more flexible simplifications of DLCs? I think having CAT available as well would probably also be fairly powerful here.</p>\n<ul>\n<li>\u201cBitVM would be able to drastically reduce its script sizes by replacing their current use of Lamport signatures implemented in Script by simple CSFS operations\u201d</li>\n</ul>\n<p>I think CAT would also be a significant win here.</p>\n<ul>\n<li>\u201cVery limited vaults have been built with CTV.\u201d</li>\n</ul>\n<p>I don\u2019t believe the CTV-only \u201cvaults\u201d are at all interesting or useful in practice; I\u2019m not sure if adding CSFS into the mix changes that in any way. Fundamentally, I think you want some ability to calculate an output scriptPubKey as \u201cback to cold storage, or spend here after some delay\u201d, and CTV and the like only give the \u201cspend here\u201d part of that. Features like that are very complicated, and are very poorly explored. I think <a href=\"https://delvingbitcoin.org/t/flexible-coin-earmarks/1275\">they\u2019re worth exploring</a>, but probably not worth rushing.</p>\n<aside class=\"quote no-group\" data-username=\"stevenroose\" data-post=\"1\" data-topic=\"1509\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/stevenroose/48/1087_2.png\" class=\"avatar\"> stevenroose:</div>\n<blockquote>\n<p>While no one will deny that covenants are a useful tool to build a wide variety of second-layer protocols, I feel that there is still hesitancy in the wider bitcoin user community on how the merits of the functionality covenants and second-layer protocols enable outweigh the risks of introducing them.</p>\n</blockquote>\n</aside>\n<p>I mean, personally <a href=\"https://gnusha.org/pi/bitcoindev/20220719044458.GA26986@erisian.com.au/\">I have denied that covenants are a useful tool</a> and continue to do so. Covenants are a bad idea, and misusing that term to also cover things that are useful was also a bad idea. Jeremy may have had a good excuse for making that mistake in 2019 or so, but there\u2019s no reason to continue it.</p>\n<p>If you\u2019re seriously trying to establish consensus about activating CTV and CSFS simultaneously, I would expect the first step would be to revise the CTV BIP so that its motivation/rationale are actually consistent with such an action.</p>\n<aside class=\"quote no-group\" data-username=\"stevenroose\" data-post=\"1\" data-topic=\"1509\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/stevenroose/48/1087_2.png\" class=\"avatar\"> stevenroose:</div>\n<blockquote>\n<p>This is why I took on the work to spec out and implement the <a href=\"https://covenants.info/proposals/txhash/\">OP_TXHASH opcode</a> according to Russel O\u2019Connor\u2019s ideas. While TXHASH as it stands is far from being mature enough to be deployed, it can function as an upgrade path for the similar but more restricted opcode <a href=\"https://covenants.info/proposals/ctv/\">OP_CTV</a>.</p>\n</blockquote>\n</aside>\n<p>There\u2019s no fundamental reason for TXHASH to be particuarly more flexible than CTV; it could be implemented precisely as \u201cpush the BIP-119 hash for this tx onto the stack\u201d. If you wanted slightly more flexibility, you could use a SIGHASH-like approach where there\u2019s a handful of values that will hash different parts of the tx, which could also precisely cover all the BIP-118 sighash values. It\u2019s not immediately clear to me what variants would actually be useful though; I think having CAT available would cover most of the cases where committing to the OP_CODESEPARATOR position or the script being executed as a whole would be very useful though, which are the main differences between the two APO variants. I don\u2019t think upgradability considerations here are even particularly necessary; just introducing OP_TXHASH2 in future seems roughly fine. (For general tx introspection, an OP_TX that doesn\u2019t automatically hash everything is perhaps more useful, but general tx introspection is a much wider design space)</p>\n<aside class=\"quote no-group\" data-username=\"stevenroose\" data-post=\"8\" data-topic=\"1509\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/stevenroose/48/1087_2.png\" class=\"avatar\"> stevenroose:</div>\n<blockquote>\n<p>I find is quite disingenuous when people point to the lack of implementations as an argument against a protocol upgrade. First of all, there were 0 implementations of taproot when it was deployed, but more generally, we cannot expect our developer ecosystem to be building on features we are still pondering to even add or not. Most of us can\u2019t afford to spend months building something that in the best case will have to be shelved for another two years and worst case will be thrown out entirely.</p>\n</blockquote>\n</aside>\n<p>So much for \u201cI won\u2019t be \u2026 pointing fingers\u201d, I guess? In any event, I would personally argue this was a serious flaw in how we deployed taproot, and one that we shouldn\u2019t repeat. While we did have some practical experimentation (the <a href=\"https://bitcoinops.org/en/schnorr-taproot-workshop/\">optech taproot workshops</a> explored schnorr, alternative tapscripts, and degrading multisig eg), and certainly had plenty of internal tests, that was still pretty limited. In particular, there were a variety of problems we didn\u2019t catch particularly early, but likely could have with more focus on \u201cdoes this work in practice, or just in theory?\u201d:</p>\n<ul>\n<li>going from an abstract design for musig to an actual implementation was quite complicated, and perhaps would have been simplified if the x-only/32-byte point changes could have been reconsidered. The optech workshops predated this change, so didn\u2019t have a chance to catch the problem; and the taproot review sessions afterwards were mostly focussed on the theory, with any failures at not being able to actually use the features in practice not raising huge alarms.</li>\n<li>Neutrino had a <a href=\"https://gnusha.org/pi/bitcoindev/CAO3Pvs-Jazo27Vmi3Rforke++T5rkboS=2PK9CSSTtCk4enF2w@mail.gmail.com/\">bug</a> regarding compact block filters impacting blocks with taproot spends, that was only discovered a little over a week before taproot activated on mainnet.</li>\n<li>Likewise, there were <a href=\"https://bitcoinops.org/en/newsletters/2022/10/19/#block-parsing-bug-affecting-btcd-and-lnd\">multiple</a> <a href=\"https://bitcoinops.org/en/newsletters/2022/11/09/#block-parsing-bug-affecting-multiple-software\">bugs</a> in btcd related to parsing of transactions that were only caught long after taproot was in active use. Really, these were holdover bugs since segwit, however taproot at least made transactions that trigger the first bug relayable. Either way, more practical experimentation on public test networks, rather than just in our internal test framework, would likely have allowed these bugs to have been discovered earlier, and potentially fixed prior to it causing downtime for users on mainnet, with risk of loss of funds.</li>\n</ul>\n<p>From a social point of view this outcome probably shouldn\u2019t be surprising \u2013 there were plenty of people pushing for taproot to be activated ASAP, and nobody saying that we should slow down and spend more time testing things and demonstrating that they\u2019re useful.</p>\n<p>As far as \u201cmost of us can\u2019t afford to spend months building\u201d goes, there\u2019s two things you should consider. One is that with open source, you only need one person to build something, after which point everyone can reap the benefits. If you can\u2019t find even one person willing to spend time on a moonshot project, it\u2019s probably not actually much of a moonshot. Second, is that, <a href=\"https://x.com/tierotiero/status/1899406106851463530\">reportedly</a> these things only take a few hours, not months.</p>\n<p>Personally, I think the biggest blocker to progress here continues to be CTV\u2019s misguided description of \u201ccovenants\u201d, and its misguided and unjustified concern about \u201crecursive covenants\u201d. Particularly given those concerns are incompatible with co-activation of CSFS, I would have thought a simple first step would be updating BIP 119 to remove/correct them, which might then also allow some rational discussion of CAT and similar features. I and others have already tried talking to Jeremy both publicly and privately about those issues with no success, but maybe you\u2019ll have some. Otherwise, discarding BIP 119 entirely and starting from scratch with an equally expressive and more efficient simplified TXHASH BIP could be a good option.</p>",
  "post_number": 14,
  "post_type": 1,
  "updated_at": "2025-03-12T03:11:53.178Z",
  "reply_count": 1,
  "reply_to_post_number": null,
  "quote_count": 2,
  "incoming_link_count": 1,
  "reads": 12,
  "readers_count": 11,
  "score": 12.2,
  "yours": false,
  "topic_id": 1509,
  "topic_slug": "ctv-csfs-can-we-reach-consensus-on-a-first-step-towards-covenants",
  "topic_title": "CTV+CSFS: Can we reach consensus on a first step towards covenants?",
  "topic_html_title": "CTV+CSFS: Can we reach consensus on a first step towards covenants?",
  "category_id": 7,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"stevenroose, post:1, topic:1509\"]\nhas been deployed on various [test networks](https://github.com/bitcoin-inquisition/bitcoin) and has been used to develop [several use cases](https://utxos.org/uses/).\n[/quote]\n\nI like the aphorism \"trust, but verify\" (of course, some Bitcoiners take it further with \"don't trust, verify\" -- but either way, the verification part is important). When I try to verify statements like these about CTV, they usually come up pretty lacking.\n\nTaking the specific examples you list for CTV+CSFS, rather than the ones on the utxos page:\n\n * \"CTV+CSFS functions as an equivalent for SIGHASH_ANYPREVOUT (APO), which enables Lightning Symmetry (formerly Eltoo)\"\n\nCTV+CSFS isn't equivalent to APO, it's somewhat more costly by requiring you to explicitly include the CTV hash in the witness data. The [TXHASH](https://gnusha.org/pi/bitcoindev/CAMZUoK=pkZuovtifBzdqhoyegzG+9hRTFEc7fG9nZPDK4KbU3w@mail.gmail.com/) approach is (in my opinion) a substantial improvement on that.\n\nThe TXHASH approach would be a taproot-only solution (as is CSFS), which would have the benefit of both simplifying the change (removing policy considerations for relay of bare-CTV txs, not having to consider the CTV in P2SH being unsatisfiable), and removing the need for segwit-related hashes to be precalculated for non-segwit transactions, preventing [the potential for IBD slowdown](https://github.com/bitcoin/bitcoin/pull/21702#pullrequestreview-859718084), and not requiring complicated workarounds. I believe the only cost would be adding 70 witness bytes to txs in the \"congestion control\" use case, however that use case doesn't seem viable in the first place to me.\n\n(Strictly, \"TXHASH EQUAL\" is perhaps an extra witness byte compared to \"CTV\", though \"TXHASH EQUALVERIFY\" is the same as \"CTV DROP\". \"[sig] TXHASH [p] CSFS\" is probably a byte cheaper than APO, since you add \"TXHASH\" but save both a SIGHASH byte and a public key version byte. TXHASH also has the benefit that you can just run the script \"TXHASH\" through a script interpreter to get the TXHASH you want to commit to, rather than having to construct it out of band)\n\nBeyond that, the exploration into ln-symmetry has been both fairly preliminary (to the best of my knowledge, nobody has been able to reproduce Greg's results; I've tried, and I believe cguida has as well -- ie, the \"verify\" part hasn't succeeded in general). It also used APO, the annex, and some custom relay rules, not CTV or CSFS or the current TRUC/ephemeral anchor model, so even if it did provide good evidence that eltoo was possible with APO, someone would still need to do the work to redesign it for CTV/TXHASH/CSFS before it was good evidence for that approach. I suspect TXHASH, CAT and CSFS would actually be a good combination here, as that would allow for a single signature to easily commit to both the tx and publication of some data while minimising wasted bytes and without needing to allow relay of random data in the annex. (Doing an adaptor signature rather than forcing publication of data would be more efficient on-chain, but seems to still be hard to convert from a whiteboard spec to an actual implementation)\n\nUnfortunately, eltoo/ln-symmetry doesn't seem to be a very high priority in the lightning space from what I can see -- eg, see the [priorities from LDK](https://x.com/TheBlueMatt/status/1859070516956389704).\n\nI think having both CAT and CSFS would make implementing PTLCs a bit easier -- you could replace \"<preimage> SIZE 32 EQUALVERIFY SHA256 <x> EQUALVERIFY\" with \"<y> SIZE 32 EQUALVERIFY <x> TUCK CAT SWAP DUP CSFS\" where \"y\" is the the s-part of the signature, calculated as preimage/(1+H(x,x,x)). Not simple per se, but separates out the PTLC calculation for the signing of the tx as a whole (avoiding the need for adaptor signatures), and only needs to be calculated once, not once per channel update. I can't see a way to get the same result from just CSFS alone.\n\n * \"I am obviously biased here, but CTV is a game-changer for Ark\"\n\nWhen I looked into this, [as far as I could tell](https://x.com/ajtowns/status/1856635064941166753) Ark has been built based on the elements introspection opcodes and on pre-signed transactions, but there has been no practical exploration into actually using it with CTV. For something that was announced as being implementable either with BIP 118 (APO) or BIP 119 (CTV), never having actually done that comes across as a huge red flag for me, particularly when people are willing to implement crazy things like the \"purrfect\" vaults.\n\n * \"Protocols involving DLCs, which have been growing in popularity, can be significantly simplified using CTV.\"\n\nDoesn't having CSFS available on its own give you equally efficient and much more flexible simplifications of DLCs? I think having CAT available as well would probably also be fairly powerful here.\n\n * \"BitVM would be able to drastically reduce its script sizes by replacing their current use of Lamport signatures implemented in Script by simple CSFS operations\"\n\nI think CAT would also be a significant win here.\n\n * \"Very limited vaults have been built with CTV.\"\n\nI don't believe the CTV-only \"vaults\" are at all interesting or useful in practice; I'm not sure if adding CSFS into the mix changes that in any way. Fundamentally, I think you want some ability to calculate an output scriptPubKey as \"back to cold storage, or spend here after some delay\", and CTV and the like only give the \"spend here\" part of that. Features like that are very complicated, and are very poorly explored. I think [they're worth exploring](https://delvingbitcoin.org/t/flexible-coin-earmarks/1275), but probably not worth rushing.\n\n[quote=\"stevenroose, post:1, topic:1509\"]\nWhile no one will deny that covenants are a useful tool to build a wide variety of second-layer protocols, I feel that there is still hesitancy in the wider bitcoin user community on how the merits of the functionality covenants and second-layer protocols enable outweigh the risks of introducing them.\n[/quote]\n\nI mean, personally [I have denied that covenants are a useful tool](https://gnusha.org/pi/bitcoindev/20220719044458.GA26986@erisian.com.au/) and continue to do so. Covenants are a bad idea, and misusing that term to also cover things that are useful was also a bad idea. Jeremy may have had a good excuse for making that mistake in 2019 or so, but there's no reason to continue it.\n\nIf you're seriously trying to establish consensus about activating CTV and CSFS simultaneously, I would expect the first step would be to revise the CTV BIP so that its motivation/rationale are actually consistent with such an action.\n\n[quote=\"stevenroose, post:1, topic:1509\"]\nThis is why I took on the work to spec out and implement the [OP_TXHASH opcode](https://covenants.info/proposals/txhash/) according to Russel O\u2019Connor\u2019s ideas. While TXHASH as it stands is far from being mature enough to be deployed, it can function as an upgrade path for the similar but more restricted opcode [OP_CTV](https://covenants.info/proposals/ctv/).\n[/quote]\n\nThere's no fundamental reason for TXHASH to be particuarly more flexible than CTV; it could be implemented precisely as \"push the BIP-119 hash for this tx onto the stack\". If you wanted slightly more flexibility, you could use a SIGHASH-like approach where there's a handful of values that will hash different parts of the tx, which could also precisely cover all the BIP-118 sighash values. It's not immediately clear to me what variants would actually be useful though; I think having CAT available would cover most of the cases where committing to the OP_CODESEPARATOR position or the script being executed as a whole would be very useful though, which are the main differences between the two APO variants. I don't think upgradability considerations here are even particularly necessary; just introducing OP_TXHASH2 in future seems roughly fine. (For general tx introspection, an OP_TX that doesn't automatically hash everything is perhaps more useful, but general tx introspection is a much wider design space)\n\n[quote=\"stevenroose, post:8, topic:1509\"]\nI find is quite disingenuous when people point to the lack of implementations as an argument against a protocol upgrade. First of all, there were 0 implementations of taproot when it was deployed, but more generally, we cannot expect our developer ecosystem to be building on features we are still pondering to even add or not. Most of us can\u2019t afford to spend months building something that in the best case will have to be shelved for another two years and worst case will be thrown out entirely.\n[/quote]\n\nSo much for \"I won't be .. pointing fingers\", I guess? In any event, I would personally argue this was a serious flaw in how we deployed taproot, and one that we shouldn't repeat. While we did have some practical experimentation (the [optech taproot workshops](https://bitcoinops.org/en/schnorr-taproot-workshop/) explored schnorr, alternative tapscripts, and degrading multisig eg), and certainly had plenty of internal tests, that was still pretty limited. In particular, there were a variety of problems we didn't catch particularly early, but likely could have with more focus on \"does this work in practice, or just in theory?\":\n\n * going from an abstract design for musig to an actual implementation was quite complicated, and perhaps would have been simplified if the x-only/32-byte point changes could have been reconsidered. The optech workshops predated this change, so didn't have a chance to catch the problem; and the taproot review sessions afterwards were mostly focussed on the theory, with any failures at not being able to actually use the features in practice not raising huge alarms.\n * Neutrino had a [bug](https://gnusha.org/pi/bitcoindev/CAO3Pvs-Jazo27Vmi3Rforke++T5rkboS=2PK9CSSTtCk4enF2w@mail.gmail.com/) regarding compact block filters impacting blocks with taproot spends, that was only discovered a little over a week before taproot activated on mainnet.\n * Likewise, there were [multiple](https://bitcoinops.org/en/newsletters/2022/10/19/#block-parsing-bug-affecting-btcd-and-lnd) [bugs](https://bitcoinops.org/en/newsletters/2022/11/09/#block-parsing-bug-affecting-multiple-software) in btcd related to parsing of transactions that were only caught long after taproot was in active use. Really, these were holdover bugs since segwit, however taproot at least made transactions that trigger the first bug relayable. Either way, more practical experimentation on public test networks, rather than just in our internal test framework, would likely have allowed these bugs to have been discovered earlier, and potentially fixed prior to it causing downtime for users on mainnet, with risk of loss of funds.\n\nFrom a social point of view this outcome probably shouldn't be surprising -- there were plenty of people pushing for taproot to be activated ASAP, and nobody saying that we should slow down and spend more time testing things and demonstrating that they're useful.\n\nAs far as \"most of us can't afford to spend months building\" goes, there's two things you should consider. One is that with open source, you only need one person to build something, after which point everyone can reap the benefits. If you can't find even one person willing to spend time on a moonshot project, it's probably not actually much of a moonshot. Second, is that, [reportedly](https://x.com/tierotiero/status/1899406106851463530) these things only take a few hours, not months.\n\n\nPersonally, I think the biggest blocker to progress here continues to be CTV's misguided description of \"covenants\", and its misguided and unjustified concern about \"recursive covenants\". Particularly given those concerns are incompatible with co-activation of CSFS, I would have thought a simple first step would be updating BIP 119 to remove/correct them, which might then also allow some rational discussion of CAT and similar features. I and others have already tried talking to Jeremy both publicly and privately about those issues with no success, but maybe you'll have some. Otherwise, discarding BIP 119 entirely and starting from scratch with an equally expressive and more efficient simplified TXHASH BIP could be a good option.",
  "actions_summary": [],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [
    {
      "id": "-1",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false
}