{
  "id": 6564,
  "name": "Gregory Sanders",
  "username": "instagibbs",
  "avatar_template": "/user_avatar/delvingbitcoin.org/instagibbs/{size}/28_2.png",
  "created_at": "2026-01-05T12:52:40.030Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"renepickhardt\" data-post=\"5\" data-topic=\"2179\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/renepickhardt/48/7_2.png\" class=\"avatar\"> renepickhardt:</div>\n<blockquote>\n<p>If that\u2019s correct, then the benefit is not \u201cless liquidity in general\u201d, but specifically reduced <em>worst-case overlap exposure</em> (not provisioning as if both old and new claims could be exercised). Is that the intended interpretation, or am I misunderstanding your approach?</p>\n</blockquote>\n</aside>\n<p>There are two components to the liquiditiy requirements:</p>\n<ol>\n<li>ASP: worst-case overlap exposure, where refreshed vtxos are in a forefeited yet not viable to sweep in a vbytes-cheap state(tree timeout). With LN on top, the velocity of these Ark refreshes can go down.</li>\n<li>LSP: Inbound liquidity: Either during construction or over time, LSPs choose to have money parked into channels, and in many contexts, are never used. If the mobile user is online they could splice it out (for vbytes cost), but the user may almost never come back online. Layering LN on Ark allows this \u201ctargeting\u201d to more tightly track practical usage. If too much is allocated, it can be reclaimed as the tree times out. If  too little, a new channel can simply be instantiated in a new tree (concurrent channels, or consolidating via revocation of old vtxo, at additional liquidity cost of refresh!)</li>\n</ol>\n<p>The challenge here is that while marginal vbytes have dropped to ~0, there is the ASP/LSP liquidity optimization challenge left and that is what (someone) should explore.</p>\n<p>I also have to note that the ASP/LSP have to be the same identity or trust each other otherwise the LSP is on the hook for unrolling channels when the mobile client turns off their phone, otherwise they hand all their money to the ASP at tree timeout.</p>",
  "post_number": 6,
  "post_type": 1,
  "posts_count": 8,
  "updated_at": "2026-01-05T12:53:27.321Z",
  "reply_count": 1,
  "reply_to_post_number": 5,
  "quote_count": 1,
  "incoming_link_count": 2,
  "reads": 18,
  "readers_count": 17,
  "score": 63.6,
  "yours": false,
  "topic_id": 2179,
  "topic_slug": "ark-as-a-channel-factory-compressed-liquidity-management-for-improved-payment-feasibility",
  "topic_title": "Ark as a Channel Factory: Compressed Liquidity Management for Improved Payment Feasibility",
  "topic_html_title": "Ark as a Channel Factory: Compressed Liquidity Management for Improved Payment Feasibility",
  "category_id": 7,
  "display_username": "Gregory Sanders",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"renepickhardt, post:5, topic:2179\"]\nIf that\u2019s correct, then the benefit is not \u201cless liquidity in general\u201d, but specifically reduced *worst-case overlap exposure* (not provisioning as if both old and new claims could be exercised). Is that the intended interpretation, or am I misunderstanding your approach?\n\n[/quote]\n\nThere are two components to the liquiditiy requirements:\n\n1. ASP: worst-case overlap exposure, where refreshed vtxos are in a forefeited yet not viable to sweep in a vbytes-cheap state(tree timeout). With LN on top, the velocity of these Ark refreshes can go down.\n2. LSP: Inbound liquidity: Either during construction or over time, LSPs choose to have money parked into channels, and in many contexts, are never used. If the mobile user is online they could splice it out (for vbytes cost), but the user may almost never come back online. Layering LN on Ark allows this \u201ctargeting\u201d to more tightly track practical usage. If too much is allocated, it can be reclaimed as the tree times out. If  too little, a new channel can simply be instantiated in a new tree (concurrent channels, or consolidating via revocation of old vtxo, at additional liquidity cost of refresh!)\n\nThe challenge here is that while marginal vbytes have dropped to \\~0, there is the ASP/LSP liquidity optimization challenge left and that is what (someone) should explore.\n\nI also have to note that the ASP/LSP have to be the same identity or trust each other otherwise the LSP is on the hook for unrolling channels when the mobile client turns off their phone, otherwise they hand all their money to the ASP at tree timeout.",
  "actions_summary": [
    {
      "id": 2,
      "count": 3
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 31,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "There are two components to the liquiditiy requirements: \n\nASP: worst-case overlap exposure, where refreshed vtxos are in a forefeited yet not viable to sweep in a vbytes-cheap state(tree timeout). With LN on top, the velocity of these Ark refreshes can go down.\nLSP: Inbound liquidity: Either durin&hellip;",
  "truncated": true,
  "post_url": "/t/ark-as-a-channel-factory-compressed-liquidity-management-for-improved-payment-feasibility/2179/6",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 2
    },
    {
      "id": "heart",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 3,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}