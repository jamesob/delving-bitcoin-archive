{
  "id": 4722,
  "name": "Ethan Heilman",
  "username": "EthanHeilman",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ethanheilman/{size}/328_2.png",
  "created_at": "2025-04-07T16:30:38.331Z",
  "cooked": "<p>PQ (Post Quantum) signatures present a problem for Bitcoin:</p>\n<ol>\n<li>\n<p>We can not ignore them. I strongly believe Bitcoin will need to move to PQ signatures in the near future. The rest of this email is premised on this belief.</p>\n</li>\n<li>\n<p>They are large. Of the three proposed in BIP-360 <sup class=\"footnote-ref\"><a href=\"#footnote-4722-1\" id=\"footnote-ref-4722-1\">[1]</a></sup>, the smallest is 1.5kb for the public key + signature <sup class=\"footnote-ref\"><a href=\"#footnote-4722-2\" id=\"footnote-ref-4722-2\">[2]</a></sup>. Without a discount this represents a massive reduction in Bitcoin\u2019s transaction volume due to the increase in transaction size of Bitcoin payment using such signatures.</p>\n</li>\n<li>\n<p>Even if we discount PQ signatures and public keys so that the maximum number of transactions that can fit in a block is unchanged we still have the problem that these blocks and transactions will be an order of magnitude bigger. If it is the case that we can handle these extra bytes without degrading performance or decentralization, then consider the head room we are giving up that could be used for scalability.</p>\n</li>\n</ol>\n<p>Beyond this there is also the risk that techniques could be developed to encode JPEGs and other data in these discounted PQ signatures or public keys. BIP-360 takes steps to make an abuse of this discount more difficult by requiring that a PQ signature and public key can only be written to the blockchain if they verify. We do not need PQ Signatures to be completely \u201cJPEG resistant\u201d, they just need PQ signatures to not enable significantly cheaper storage than payments. The degree to which the proposed PQ signature algorithms resist being repurposed as a storage mechanism is an open question and worth investigating.</p>\n<p>If it turned out PQ signatures could be used to encode data very cheaply, then Bitcoin faces the dilemma that if you discount PQ signatures, you make the JPEG problem worse and may price out the payment use case. If you don\u2019t discount PQ, you price out most people from sending payments in Bitcoin since non-PQ witness data can be used for storage.</p>\n<h2><a name=\"p-4722-non-interactive-transaction-compression-ntc-1\" class=\"anchor\" href=\"#p-4722-non-interactive-transaction-compression-ntc-1\"></a>Non-interactive Transaction Compression (NTC)</h2>\n<p>I want to draw the community\u2019s attention to a solution that could not only address these problems but also increase Bitcoin\u2019s scalability (and privacy):</p>\n<p>Non-interactive Transaction Compression (NTC) for Transactions supporting PQ signatures. This is sometimes called Non-Interactive Witness Aggregation (NIWA) <sup class=\"footnote-ref\"><a href=\"#footnote-4722-3\" id=\"footnote-ref-4722-3\">[3]</a></sup>.</p>\n<p>This would require a new transaction type supporting PQ signatures. The miner of a block would then pull out the signatures and hash pointers from transactions to compress transaction data and non-interactively aggregate all the PQ signatures in all the transactions in a block, replacing them with one big STARK (STARKS are a form of SNARK which is PQ). This would make PQ signatures significantly smaller and cheaper than ECDSA and Schnorr signatures.</p>\n<p>Consider the following back of the envelope math:</p>\n<p><span class=\"math\">2</span> bytes per Input <span class=\"math\">= 2</span> bytes per TXID, <span class=\"math\">0</span> bytes per signature</p>\n<p><span class=\"math\">37</span> bytes per output <span class=\"math\">= 32</span> bytes pubkey hash + <span class=\"math\">5</span> bytes value (max 2.8m BTC per output)</p>\n<p>1-input-2-output transaction would be: <span class=\"math\">2 + 2\\times37 = 76</span> bytes</p>\n<p><span class=\"math\">(4,000,000/76)/(60\\times10) = ~87</span> txns/sec</p>\n<p>You could shave some bytes off the value, or add some bytes to the TXID. <sup class=\"footnote-ref\"><a href=\"#footnote-4722-4\" id=\"footnote-ref-4722-4\">[4]</a></sup> provides a more detailed estimate, proposing 113.5 weight units (WU) for a 1-input-2-output transaction with no address reuse. However it does not consider TXID compression. An account-based model would take this even further to 12 bytes per transaction per block <sup class=\"footnote-ref\"><a href=\"#footnote-4722-5\" id=\"footnote-ref-4722-5\">[5]</a></sup>. This would enable approximately <span class=\"math\">4,000,000/(12\\times60\\times10) = 555</span> txns/second.</p>\n<p>A secondary benefit of having on-chain PQ payments only be ~76 bytes in size is that it fundamentally changes the pricing relationship between payments and on-chain JPEG/complex contracts. The problem with on-chain JPEGs is not that they are possible, but that they are price competitive with payments. At ~76 bytes per payment or better yet ~76 bytes per LN channel open/close, JPEGs no longer present the same fee competition to payments as payments become much cheaper.</p>\n<p>Such a system would present scaling issues for the mempool because prior to aggregation and compression, these transactions would be 2kb to 100kb in size and there would be a lot more of them. It is likely parties producing large numbers of transactions would want to pre-aggregate and compress them in one big many input, many output transactions. Aggregating prior to the miner may have privacy benefits but also scalability benefits as it would enable cut-throughs and very cheap consolidation transactions. ~87/txns a second does not include these additional scalability benefits.</p>\n<h3><a name=\"p-4722-consolidation-and-cut-throughs-2\" class=\"anchor\" href=\"#p-4722-consolidation-and-cut-throughs-2\"></a>Consolidation and Cut-throughs</h3>\n<p>Consider an exchange that receives and sends a large number of transactions. For instance between block confirmations customers send the exchange 10 1-input-2-output transactions in deposits and the exchange sends out 10 1-input-2-output transactions in withdrawals. The exchange could consolidate all of the outputs paying the exchange, including chain outputs, into one output and do the same for inputs. This would reduce not just size, but also validation costs.</p>\n<div class=\"math\">\n\n(10 \\times 2 + 20 \\times 2 \\times 37) + (10 \\times 2 + 20 \\times 2 \\times 37) = 3000 \\text{ bytes}\n\n</div>\n<p>becomes</p>\n<div class=\"math\">\n\n(10 \\times 2 + 11 \\times 2 \\times 37) + (2 + 11 \\times 2 \\times 37) = 1650 \\text{ bytes}\n\n</div>\n<h3><a name=\"p-4722-parallelizing-and-distributing-proof-construction-3\" class=\"anchor\" href=\"#p-4722-parallelizing-and-distributing-proof-construction-3\"></a>Parallelizing and Distributing Proof Construction</h3>\n<p>If constructing these proofs turned out to be as expensive as performing POW, it would make block generation not progress free. Essentially you\u2019d have a two step POW: proof generation and then the actual POW. Such a scenario would be very bad and cause the biggest miner to always be the one that generates blocks. A critical assumption I am making is that such proof generation is not particularly expensive in the scheme of POW. I am optimistic that proof generation will not be this expensive for two reasons</p>\n<p>There are PQ signature schemes which support non-interactive aggregation such as LaBRADOR [5]. Thus, the STARK wouldn\u2019t need to perform the block-wide signature aggregation and would only need to perform transaction compression, cut throughs and consolidation.</p>\n<p>We could make use of recursive STARKs <sup class=\"footnote-ref\"><a href=\"#footnote-4722-6\" id=\"footnote-ref-4722-6\">[6]</a></sup> to allow miners to parallelize proof generation to reduce latency or to decentralize proof generation. Users creating transactions could perform non-interactive coinjoins with other users or settlement/batching. This would not only take proof generation pressure off of the miners and reduce the strain on the mempool but in some circumstances it would provide privacy if used with payjoin techniques like receiver side payment batching <sup class=\"footnote-ref\"><a href=\"#footnote-4722-7\" id=\"footnote-ref-4722-7\">[7]</a></sup>.</p>\n<p>The approach we are proposing treats the STARK the miner produces as free from a blocksize perspective. This is important for bootstrapping because it means that fees are significantly cheaper for a transaction, even if it is the only compressed transaction in the block. This encourages adoption. Adoption helps address the chicken and egg problem of wallets and exchanges not investing engineering resources to support a new transaction type if no one is using it and no one wants to use it because it isn\u2019t well supported. By having a single format, built into the block we both accelerate the switch over and prevent a fragmented ecosystem that might arise from doing this in Bitcoin script. Fragmentation reduces the scalability benefits because validators have to validate multiple STARKs and reduces the privacy benefits because there are many coinjoins, rather than each being a coinjoin.</p>\n<p>Even if our approach here turns out to be infeasible, we need a way to reduce the size of PQ signatures in Bitcoin. The ability to move coins, including the ability to move coins that represent JPEGs, is the main functionality of Bitcoin. If we make storage/JPEG too price competitive with the ability to transfer coins, we destroy that essential functionality and decrease the utility of Bitcoin for everyone. Currently moving coins securely requires at least one 64 byte signature, which is an unfortunate tax on this most vital of all use cases. I believe removing that tax with signature aggregation will be beneficial for all parties.</p>\n<h2><a name=\"p-4722-closing-thoughts-4\" class=\"anchor\" href=\"#p-4722-closing-thoughts-4\"></a>Closing Thoughts</h2>\n<p>Consider the world of PQ signatures in Bitcoin without STARKs:</p>\n<ul>\n<li>\n<p>The large size of PQ signatures will make it more expensive for users to use them prior to the invention of a CRQC (Cryptographically Relevant Quantum Computer). This means that most outputs will not be protected by PQ signatures. Once a CRQC arises there will be a rush to move funds under the protection of PQ signatures but due to the large size of PQ signatures the fees will be too expensive for most outputs. Users will instead need to move their funds to centralized custodial wallets that can use a small number of outputs. In such a world it will be much harder and expensive to self-custody.</p>\n</li>\n<li>\n<p>Without a solution here the large sizes of PQ signatures will limit Bitcoin\u2019s functionality to move coins using on-chain payments. This will also favor centralized custodians and erode the decentralized nature of Bitcoin.</p>\n</li>\n</ul>\n<p>None of this is an argument against adopting BIP-360 or other PQ signatures schemes into Bitcoin. On the contrary, having PQ signatures in Bitcoin would be a useful stepping stone to PQ transaction compression since it would allow us to gain agreement on which PQ signature schemes to build on. Most importantly, in the event of a CRQC being developed it will be far better to have uncompressed PQ signatures in Bitcoin than none at all.</p>\n<p>Acknowledgements:</p>\n<p>These ideas arose out of correspondence with Hunter Beast. I want to thank Neha Narula, John Light, Eli Ben-Sasson for their feedback, Jonas Nick for his feedback and his idea to use LaBRADOR for signature aggregation, Tadge Dryja for suggesting the term \u201cJPEG resistance\u201d and his ideas around its feasibility. I had a number of fruitful discussions over lunch with members of the MIT DCI and on the Bitcoin PQ working group. These acknowledgements should not be taken as an agreement with or endorsement of the ideas in this email.</p>\n<p>This originally appeared on the bitcoin-dev mailinglist as <a href=\"https://groups.google.com/g/bitcoindev/c/wKizvPUfO7w\" rel=\"noopener nofollow ugc\">Post Quantum Signatures and Scaling Bitcoin (Apr 4, 2025)</a> and is also on my homepage as <a href=\"https://www.ethanheilman.com/x/32/index.html\" rel=\"noopener nofollow ugc\">Some Thoughts on Post Quantum Signatures and Scaling Bitcoin</a>.</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://vitalik.eth.limo/general/2021/01/05/rollup.html\">\n  <header class=\"source\">\n\n      <a href=\"https://vitalik.eth.limo/general/2021/01/05/rollup.html\" target=\"_blank\" rel=\"noopener nofollow ugc\">vitalik.eth.limo</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"https://vitalik.eth.limo/general/2021/01/05/rollup.html\" target=\"_blank\" rel=\"noopener nofollow ugc\">An Incomplete Guide to Rollups</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>[^8] John Tromp, Fee burning and Dynamic Block Size (2018) <a href=\"https://lists.launchpad.net/mimblewimble/msg00450.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Fee burning and Dynamic Block Size : Mailing list archive : mimblewimble team in Launchpad</a></p>\n<hr class=\"footnotes-sep\">\n\n<ol class=\"footnotes-list\">\n<li id=\"footnote-4722-1\" class=\"footnote-item\"><p>Hunter Beast, BIP-360: QuBit - Pay to Quantum Resistant Hash (2025) <a href=\"https://github.com/bitcoin/bips/pull/1670/files#\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">BIP-360: QuBit - Pay to Quantum Resistant Hash by cryptoquick \u00b7 Pull Request #1670 \u00b7 bitcoin/bips \u00b7 GitHub</a> <a href=\"#footnote-ref-4722-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"footnote-4722-2\" class=\"footnote-item\"><p>Benchmark Report: Post-Quantum Cryptography vs secp256k1 <a href=\"https://github.com/cryptoquick/libbitcoinpqc/blob/0dc6f7e7f09b2c8cbedea3ad2705e423d6716425/benches/REPORT.md\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">libbitcoinpqc/benches/REPORT.md at 0dc6f7e7f09b2c8cbedea3ad2705e423d6716425 \u00b7 cryptoquick/libbitcoinpqc \u00b7 GitHub</a> <a href=\"#footnote-ref-4722-2\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"footnote-4722-3\" class=\"footnote-item\"><p>Ruben Somsen, SNARKs and the future of blockchains (2020) <a href=\"https://medium.com/@RubenSomsen/snarks-and-the-future-of-blockchains-55b82012452b\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">SNARKs and the future of blockchains | by Ruben Somsen | Medium</a> <a href=\"#footnote-ref-4722-3\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"footnote-4722-4\" class=\"footnote-item\"><p>John Light, Validity Rollups on Bitcoin (2022) <a href=\"https://github.com/john-light/validity-rollups/blob/fecc3433d8e95ab40263db8c2941794e0115d2d5/validity_rollups_on_bitcoin.md\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">validity-rollups/validity_rollups_on_bitcoin.md at fecc3433d8e95ab40263db8c2941794e0115d2d5 \u00b7 john-light/validity-rollups \u00b7 GitHub</a> <a href=\"#footnote-ref-4722-4\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"footnote-4722-5\" class=\"footnote-item\"><p>Vitalik Buterin, An Incomplete Guide to Rollups (2021) <a href=\"#footnote-ref-4722-5\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"footnote-4722-6\" class=\"footnote-item\"><p>Gidi Kaempfer, Recursive STARKs (2022) <a href=\"https://www.starknet.io/blog/recursive-starks/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Recursive STARKs | Starknet</a> <a href=\"#footnote-ref-4722-6\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"footnote-4722-7\" class=\"footnote-item\"><p>Dan Gould, Interactive Payment Batching is Better (2023) <a href=\"https://payjoin.substack.com/p/interactive-payment-batching-is-better\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Interactive Payment Batching is Better - by Dan Gould</a> <a href=\"#footnote-ref-4722-7\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>",
  "post_number": 1,
  "post_type": 1,
  "posts_count": 1,
  "updated_at": "2025-04-07T16:35:48.201Z",
  "reply_count": 0,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 0,
  "reads": 9,
  "readers_count": 8,
  "score": 1.8,
  "yours": false,
  "topic_id": 1584,
  "topic_slug": "post-quantum-signatures-and-scaling-bitcoin-with-starks",
  "topic_title": "Post Quantum Signatures and Scaling Bitcoin with STARKs",
  "topic_html_title": "Post Quantum Signatures and Scaling Bitcoin with STARKs",
  "category_id": 7,
  "display_username": "Ethan Heilman",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "PQ (Post Quantum) signatures present a problem for Bitcoin:\n\n1. We can not ignore them. I strongly believe Bitcoin will need to move to PQ signatures in the near future. The rest of this email is premised on this belief.\n\n2. They are large. Of the three proposed in BIP-360 [^0], the smallest is 1.5kb for the public key + signature [^1]. Without a discount this represents a massive reduction in Bitcoin's transaction volume due to the increase in transaction size of Bitcoin payment using such signatures.\n\n3. Even if we discount PQ signatures and public keys so that the maximum number of transactions that can fit in a block is unchanged we still have the problem that these blocks and transactions will be an order of magnitude bigger. If it is the case that we can handle these extra bytes without degrading performance or decentralization, then consider the head room we are giving up that could be used for scalability.\n\nBeyond this there is also the risk that techniques could be developed to encode JPEGs and other data in these discounted PQ signatures or public keys. BIP-360 takes steps to make an abuse of this discount more difficult by requiring that a PQ signature and public key can only be written to the blockchain if they verify. We do not need PQ Signatures to be completely \u201cJPEG resistant\u201d, they just need PQ signatures to not enable significantly cheaper storage than payments. The degree to which the proposed PQ signature algorithms resist being repurposed as a storage mechanism is an open question and worth investigating.\n\nIf it turned out PQ signatures could be used to encode data very cheaply, then Bitcoin faces the dilemma that if you discount PQ signatures, you make the JPEG problem worse and may price out the payment use case. If you don't discount PQ, you price out most people from sending payments in Bitcoin since non-PQ witness data can be used for storage.\n\n## Non-interactive Transaction Compression (NTC)\n\nI want to draw the community's attention to a solution that could not only address these problems but also increase Bitcoin\u2019s scalability (and privacy):\n\nNon-interactive Transaction Compression (NTC) for Transactions supporting PQ signatures. This is sometimes called Non-Interactive Witness Aggregation (NIWA) [^2].\n\nThis would require a new transaction type supporting PQ signatures. The miner of a block would then pull out the signatures and hash pointers from transactions to compress transaction data and non-interactively aggregate all the PQ signatures in all the transactions in a block, replacing them with one big STARK (STARKS are a form of SNARK which is PQ). This would make PQ signatures significantly smaller and cheaper than ECDSA and Schnorr signatures.\n\nConsider the following back of the envelope math:\n\n$2$ bytes per Input $= 2$ bytes per TXID, $0$ bytes per signature\n\n$37$ bytes per output $= 32$ bytes pubkey hash + $5$ bytes value (max 2.8m BTC per output)\n\n1-input-2-output transaction would be: $2 + 2\\times37 = 76$ bytes\n\n$(4,000,000/76)/(60\\times10) = ~87$ txns/sec\n\nYou could shave some bytes off the value, or add some bytes to the TXID. [^3] provides a more detailed estimate, proposing 113.5 weight units (WU) for a 1-input-2-output transaction with no address reuse. However it does not consider TXID compression. An account-based model would take this even further to 12 bytes per transaction per block [^4]. This would enable approximately $4,000,000/(12\\times60\\times10) = 555$ txns/second.\n\nA secondary benefit of having on-chain PQ payments only be ~76 bytes in size is that it fundamentally changes the pricing relationship between payments and on-chain JPEG/complex contracts. The problem with on-chain JPEGs is not that they are possible, but that they are price competitive with payments. At ~76 bytes per payment or better yet ~76 bytes per LN channel open/close, JPEGs no longer present the same fee competition to payments as payments become much cheaper.\n\nSuch a system would present scaling issues for the mempool because prior to aggregation and compression, these transactions would be 2kb to 100kb in size and there would be a lot more of them. It is likely parties producing large numbers of transactions would want to pre-aggregate and compress them in one big many input, many output transactions. Aggregating prior to the miner may have privacy benefits but also scalability benefits as it would enable cut-throughs and very cheap consolidation transactions. ~87/txns a second does not include these additional scalability benefits.\n\n### Consolidation and Cut-throughs\n\nConsider an exchange that receives and sends a large number of transactions. For instance between block confirmations customers send the exchange 10 1-input-2-output transactions in deposits and the exchange sends out 10 1-input-2-output transactions in withdrawals. The exchange could consolidate all of the outputs paying the exchange, including chain outputs, into one output and do the same for inputs. This would reduce not just size, but also validation costs.\n\n$$\n\n(10 \\times 2 + 20 \\times 2 \\times 37) + (10 \\times 2 + 20 \\times 2 \\times 37) = 3000 \\text{ bytes}\n\n$$\n\nbecomes\n\n$$\n\n(10 \\times 2 + 11 \\times 2 \\times 37) + (2 + 11 \\times 2 \\times 37) = 1650 \\text{ bytes}\n\n$$\n\n### Parallelizing and Distributing Proof Construction\n\nIf constructing these proofs turned out to be as expensive as performing POW, it would make block generation not progress free. Essentially you'd have a two step POW: proof generation and then the actual POW. Such a scenario would be very bad and cause the biggest miner to always be the one that generates blocks. A critical assumption I am making is that such proof generation is not particularly expensive in the scheme of POW. I am optimistic that proof generation will not be this expensive for two reasons\n\nThere are PQ signature schemes which support non-interactive aggregation such as LaBRADOR [5]. Thus, the STARK wouldn\u2019t need to perform the block-wide signature aggregation and would only need to perform transaction compression, cut throughs and consolidation.\n\nWe could make use of recursive STARKs [^6] to allow miners to parallelize proof generation to reduce latency or to decentralize proof generation. Users creating transactions could perform non-interactive coinjoins with other users or settlement/batching. This would not only take proof generation pressure off of the miners and reduce the strain on the mempool but in some circumstances it would provide privacy if used with payjoin techniques like receiver side payment batching [^7].\n\nThe approach we are proposing treats the STARK the miner produces as free from a blocksize perspective. This is important for bootstrapping because it means that fees are significantly cheaper for a transaction, even if it is the only compressed transaction in the block. This encourages adoption. Adoption helps address the chicken and egg problem of wallets and exchanges not investing engineering resources to support a new transaction type if no one is using it and no one wants to use it because it isn't well supported. By having a single format, built into the block we both accelerate the switch over and prevent a fragmented ecosystem that might arise from doing this in Bitcoin script. Fragmentation reduces the scalability benefits because validators have to validate multiple STARKs and reduces the privacy benefits because there are many coinjoins, rather than each being a coinjoin.\n\nEven if our approach here turns out to be infeasible, we need a way to reduce the size of PQ signatures in Bitcoin. The ability to move coins, including the ability to move coins that represent JPEGs, is the main functionality of Bitcoin. If we make storage/JPEG too price competitive with the ability to transfer coins, we destroy that essential functionality and decrease the utility of Bitcoin for everyone. Currently moving coins securely requires at least one 64 byte signature, which is an unfortunate tax on this most vital of all use cases. I believe removing that tax with signature aggregation will be beneficial for all parties.\n\n## Closing Thoughts\n\nConsider the world of PQ signatures in Bitcoin without STARKs:\n\n- The large size of PQ signatures will make it more expensive for users to use them prior to the invention of a CRQC (Cryptographically Relevant Quantum Computer). This means that most outputs will not be protected by PQ signatures. Once a CRQC arises there will be a rush to move funds under the protection of PQ signatures but due to the large size of PQ signatures the fees will be too expensive for most outputs. Users will instead need to move their funds to centralized custodial wallets that can use a small number of outputs. In such a world it will be much harder and expensive to self-custody.\n\n- Without a solution here the large sizes of PQ signatures will limit Bitcoin's functionality to move coins using on-chain payments. This will also favor centralized custodians and erode the decentralized nature of Bitcoin.\n\nNone of this is an argument against adopting BIP-360 or other PQ signatures schemes into Bitcoin. On the contrary, having PQ signatures in Bitcoin would be a useful stepping stone to PQ transaction compression since it would allow us to gain agreement on which PQ signature schemes to build on. Most importantly, in the event of a CRQC being developed it will be far better to have uncompressed PQ signatures in Bitcoin than none at all.\n\nAcknowledgements:\n\nThese ideas arose out of correspondence with Hunter Beast. I want to thank Neha Narula, John Light, Eli Ben-Sasson for their feedback, Jonas Nick for his feedback and his idea to use LaBRADOR for signature aggregation, Tadge Dryja for suggesting the term \u201cJPEG resistance\u201d and his ideas around its feasibility. I had a number of fruitful discussions over lunch with members of the MIT DCI and on the Bitcoin PQ working group. These acknowledgements should not be taken as an agreement with or endorsement of the ideas in this email.\n\nThis originally appeared on the bitcoin-dev mailinglist as [Post Quantum Signatures and Scaling Bitcoin (Apr 4, 2025)](https://groups.google.com/g/bitcoindev/c/wKizvPUfO7w) and is also on my homepage as [Some Thoughts on Post Quantum Signatures and Scaling Bitcoin](https://www.ethanheilman.com/x/32/index.html). \n\n[^0]: Hunter Beast, BIP-360: QuBit - Pay to Quantum Resistant Hash (2025) https://github.com/bitcoin/bips/pull/1670/files#\n\n[^1]: Benchmark Report: Post-Quantum Cryptography vs secp256k1 https://github.com/cryptoquick/libbitcoinpqc/blob/0dc6f7e7f09b2c8cbedea3ad2705e423d6716425/benches/REPORT.md\n\n[^2]: Ruben Somsen, SNARKs and the future of blockchains (2020) https://medium.com/@RubenSomsen/snarks-and-the-future-of-blockchains-55b82012452b\n\n[^3]: John Light, Validity Rollups on Bitcoin (2022) https://github.com/john-light/validity-rollups/blob/fecc3433d8e95ab40263db8c2941794e0115d2d5/validity_rollups_on_bitcoin.md\n\n[^4]: Vitalik Buterin, An Incomplete Guide to Rollups (2021)\n\nhttps://vitalik.eth.limo/general/2021/01/05/rollup.html\n\n[^5]: Aardal, Aranha, Boudgoust, Kolby, Takahashi, Aggregating Falcon Signatures with LaBRADOR (2024) https://eprint.iacr.org/2024/311\n\n[^6]: Gidi Kaempfer, Recursive STARKs (2022) https://www.starknet.io/blog/recursive-starks/\n\n[^7]: Dan Gould, Interactive Payment Batching is Better (2023) https://payjoin.substack.com/p/interactive-payment-batching-is-better\n\n[^8] John Tromp, Fee burning and Dynamic Block Size (2018) https://lists.launchpad.net/mimblewimble/msg00450.html",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 267,
  "hidden": false,
  "trust_level": 2,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": "Github link was replaced with a permanent link",
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "PQ (Post Quantum) signatures present a problem for Bitcoin: \n\n\nWe can not ignore them. I strongly believe Bitcoin will need to move to PQ signatures in the near future. The rest of this email is premised on this belief. \n\n\nThey are large. Of the three proposed in BIP-360 <a href=\"#footnote-4722-1\" id=\"footnote-ref-4722-1\">[1]</a>, the smallest is 1.5kb f&hellip;",
  "truncated": true,
  "post_url": "/t/post-quantum-signatures-and-scaling-bitcoin-with-starks/1584/1",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}