{
  "id": 4824,
  "name": "Pieter Wuille",
  "username": "sipa",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/1100_2.png",
  "created_at": "2025-04-18T11:19:56.096Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"gmaxwell\" data-post=\"71\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/g/fbc32d/48.png\" class=\"avatar\"> gmaxwell:</div>\n<blockquote>\n<p>There are also other non-GGT algorithms in the literature with similar worst case complexity. Perhaps one of them may even be (a variation of) SFL.</p>\n</blockquote>\n</aside>\n<p>SFL is ultimately a modified version of simplex for the LP formulation of the maximum ratio closure problem, though one with two important changes:</p>\n<ul>\n<li>Whenever dependencies are made active (i.e., become basic variables in simplex terms), pick the ones whose feerate difference is maximal. This is crucial apparently, because (as far as fuzzing can confirm) it is sufficient to never hit repeated states.</li>\n<li>Operate on all chunks at once, rather than just on finding the one first chunk. This is nice from a computation perspective (no separation into subproblems that the budget needs to be split over), but also from a fairness perspective (can distribute work over all transactions equally).</li>\n</ul>\n<p>Simplex in general, without heuristics, can cycle forever. With heuristics, it can be exponential in the worst case. But our problem is very much not a general LP problem, and the max-feerate-difference heuristic is a fairly strong one, so I think it\u2019s at least plausible this makes it polynomial.</p>\n<aside class=\"quote no-group\" data-username=\"gmaxwell\" data-post=\"71\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/g/fbc32d/48.png\" class=\"avatar\"> gmaxwell:</div>\n<blockquote>\n<p>The factor of 2 is interesting to me, since that\u2019s also what GGT loses from having to run both forward and backward to save a factor of N in the worst case-- right? If so leaving that out would leave it competitive with SFL in average performance but still better than SFL\u2019s conjectured worst case.</p>\n</blockquote>\n</aside>\n<p>I think I saw a factor of 1.5 from running forward and backward, but this is perhaps a good thing to include in further benchmarks, to compare SFL with a version of GGT that just runs forward (which has <span class=\"math\">\\mathcal{O}(n^4)</span> worst-case complexity, FWIW).</p>\n<p>And of course, these are tiny constant factors. They may also be achievable by mundane implementation aspects, like picking a different data structure here or there. Or they may be the consequence of a dumb oversight in my unreviewed implementations.</p>\n<aside class=\"quote no-group\" data-username=\"gmaxwell\" data-post=\"71\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/g/fbc32d/48.png\" class=\"avatar\"> gmaxwell:</div>\n<blockquote>\n<p>I confess that I\u2019m happy to see you seemingly leaning towards SFL because GGT\u2019s arithmetic struck me as particularly ugly.</p>\n</blockquote>\n</aside>\n<p>I think SFL is more elegant too, mostly because it really has a small amount of state: the set of active edges. The implementation does need a lot of precomputed values to be efficient, but those precomputed values can all be determined in <span class=\"math\">\\mathcal{O}(n^2)</span> time from the set of active dependencies. On the other hand, GGT has a lot of state: the flows between the source/sink and each transactions, and the flows along every dependency, and a copy of all of that per instance of the min-cut problem. It just feels like there is redundancy in there that is not exploited (e.g., there can be many equivalent flows that represent the same cut).</p>\n<aside class=\"quote no-group\" data-username=\"gmaxwell\" data-post=\"71\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/g/fbc32d/48.png\" class=\"avatar\"> gmaxwell:</div>\n<blockquote>\n<p>Preferring linearizations with smaller chunks first among options with equivalent feerate diagrams sounds pretty attractive particularly absent any kind of just in time space constrained linearization.</p>\n</blockquote>\n</aside>\n<p>All else being equal, we should of course prefer smaller chunks over bigger ones, as it reduces the binpacking loss at the end of a block (it can be compensated through other means too, but if it can be done through smaller chunks it\u2019s just a win overall). But on the other hand, <em>exactly</em> equal feerate chunks are just a special case. If we seriously cared about the binpacking impact of larger chunks, we should arguably also prefer splitting up \u201cchunks\u201d into quasi-chunks that have <em>almost</em> the same feerate. Unfortunately, that does break some of the theory (e.g., now it is no longer the case that chunks are monotonically decreasing in feerate), but as long as we\u2019re talking about small feerate differences, this may still well be worth it in practice.</p>\n<aside class=\"quote no-group\" data-username=\"gmaxwell\" data-post=\"71\" data-topic=\"303\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/g/fbc32d/48.png\" class=\"avatar\"> gmaxwell:</div>\n<blockquote>\n<p>But how often does it even matter historically? My WAG is that it\u2019s almost always the case in practice that the optimal diagram is unique unless transactions are the same sizes.</p>\n</blockquote>\n</aside>\n<p>I have certainly seen clusters with many exactly-equal transaction fees and sizes.</p>",
  "post_number": 72,
  "post_type": 1,
  "posts_count": 78,
  "updated_at": "2025-04-19T12:47:57.181Z",
  "reply_count": 0,
  "reply_to_post_number": 71,
  "quote_count": 1,
  "incoming_link_count": 2,
  "reads": 32,
  "readers_count": 31,
  "score": 31.4,
  "yours": false,
  "topic_id": 303,
  "topic_slug": "how-to-linearize-your-cluster",
  "topic_title": "How to linearize your cluster",
  "topic_html_title": "How to linearize your cluster",
  "category_id": 8,
  "display_username": "Pieter Wuille",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"gmaxwell, post:71, topic:303\"]\nThere are also other non-GGT algorithms in the literature with similar worst case complexity. Perhaps one of them may even be (a variation of) SFL.\n[/quote]\n\nSFL is ultimately a modified version of simplex for the LP formulation of the maximum ratio closure problem, though one with two important changes:\n* Whenever dependencies are made active (i.e., become basic variables in simplex terms), pick the ones whose feerate difference is maximal. This is crucial apparently, because (as far as fuzzing can confirm) it is sufficient to never hit repeated states.\n* Operate on all chunks at once, rather than just on finding the one first chunk. This is nice from a computation perspective (no separation into subproblems that the budget needs to be split over), but also from a fairness perspective (can distribute work over all transactions equally).\n\nSimplex in general, without heuristics, can cycle forever. With heuristics, it can be exponential in the worst case. But our problem is very much not a general LP problem, and the max-feerate-difference heuristic is a fairly strong one, so I think it's at least plausible this makes it polynomial.\n\n[quote=\"gmaxwell, post:71, topic:303\"]\nThe factor of 2 is interesting to me, since that\u2019s also what GGT loses from having to run both forward and backward to save a factor of N in the worst case-- right? If so leaving that out would leave it competitive with SFL in average performance but still better than SFL\u2019s conjectured worst case.\n[/quote]\n\nI think I saw a factor of 1.5 from running forward and backward, but this is perhaps a good thing to include in further benchmarks, to compare SFL with a version of GGT that just runs forward (which has $\\mathcal{O}(n^4)$ worst-case complexity, FWIW).\n\nAnd of course, these are tiny constant factors. They may also be achievable by mundane implementation aspects, like picking a different data structure here or there. Or they may be the consequence of a dumb oversight in my unreviewed implementations.\n\n[quote=\"gmaxwell, post:71, topic:303\"]\nI confess that I\u2019m happy to see you seemingly leaning towards SFL because GGT\u2019s arithmetic struck me as particularly ugly.\n[/quote]\n\nI think SFL is more elegant too, mostly because it really has a small amount of state: the set of active edges. The implementation does need a lot of precomputed values to be efficient, but those precomputed values can all be determined in $\\mathcal{O}(n^2)$ time from the set of active dependencies. On the other hand, GGT has a lot of state: the flows between the source/sink and each transactions, and the flows along every dependency, and a copy of all of that per instance of the min-cut problem. It just feels like there is redundancy in there that is not exploited (e.g., there can be many equivalent flows that represent the same cut).\n\n[quote=\"gmaxwell, post:71, topic:303\"]\nPreferring linearizations with smaller chunks first among options with equivalent feerate diagrams sounds pretty attractive particularly absent any kind of just in time space constrained linearization.\n[/quote]\n\nAll else being equal, we should of course prefer smaller chunks over bigger ones, as it reduces the binpacking loss at the end of a block (it can be compensated through other means too, but if it can be done through smaller chunks it's just a win overall). But on the other hand, *exactly* equal feerate chunks are just a special case. If we seriously cared about the binpacking impact of larger chunks, we should arguably also prefer splitting up \"chunks\" into quasi-chunks that have *almost* the same feerate. Unfortunately, that does break some of the theory (e.g., now it is no longer the case that chunks are monotonically decreasing in feerate), but as long as we're talking about small feerate differences, this may still well be worth it in practice.\n\n[quote=\"gmaxwell, post:71, topic:303\"]\nBut how often does it even matter historically? My WAG is that it\u2019s almost always the case in practice that the optimal diagram is unique unless transactions are the same sizes.\n[/quote]\n\nI have certainly seen clusters with many exactly-equal transaction fees and sizes.",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 96,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "SFL is ultimately a modified version of simplex for the LP formulation of the maximum ratio closure problem, though one with two important changes: \n\nWhenever dependencies are made active (i.e., become basic variables in simplex terms), pick the ones whose feerate difference is maximal. This is cru&hellip;",
  "truncated": true,
  "post_url": "/t/how-to-linearize-your-cluster/303/72",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}