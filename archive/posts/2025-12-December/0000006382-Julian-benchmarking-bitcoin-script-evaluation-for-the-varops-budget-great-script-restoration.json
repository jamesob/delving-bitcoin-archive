{
  "id": 6382,
  "name": "",
  "username": "Julian",
  "avatar_template": "/letter_avatar_proxy/v4/letter/j/74df32/{size}.png",
  "created_at": "2025-12-05T14:43:09.680Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"6\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/417_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Doing benchmarks on the more powerful logic new opcodes enable might be more interesting; eg the <a href=\"https://bitcoinmagazine.com/technical/a-zero-knowledge-proof-is-verified-on-bitcoin-for-the-first-time-in-history\" rel=\"noopener nofollow ugc\">OP_CAT based zkp verifier</a>? How many zkps (implemented that way) could we verify in a block, if 100ms (or whatever) of cpu time were the only constraint? Seems to have some 223k operations per script, 30k ADD/DUP, 20k IF/ENDIF/SUB, 10k SWAP/LESSTHAN/TOALT/FROMALT, 400 CAT/1SUB/DEPTH/SHA256, 1 CHECKSIG, etc.</p>\n</blockquote>\n</aside>\n<p>Unfortunately it seems that this implementation won\u2019t run properly due to the new number type used in GSR, we use an unsigned arbitrary length integer instead of the current signed 32bit int. The new stack limits and OP_MUL should also drastically reduce the number of transactions needed and probably also reduce their validation time.</p>\n<aside class=\"quote no-group\" data-username=\"instagibbs\" data-post=\"4\" data-topic=\"2094\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/instagibbs/48/28_2.png\" class=\"avatar\"> instagibbs:</div>\n<blockquote>\n<p>TIL it was that slow. I worry that benchmarking against the <em>worst case</em> as the new \u201caverage\u201d is the wrong goal as this may potentially become the average way of interacting with Bitcoin (unlike using lots of signatures, which seems rare). Basically we should expect ~every block to approach that level of verification cost, so I\u2019d expect we would target something we would be happy with for IBD or at tip with relatively turbulent mempools. <em>waving wildly</em> On the order of 100ms?</p>\n</blockquote>\n</aside>\n<p>We benchmark a large collection of possible scripts and extract the worst case as the slowest execution time, this does not mean that it will be the new average, the 15 opcodes were disabled due to paranoia of nodes being DDoSed, as in an attacker trying to construct a block that causes memory overflows or extremely slow execution times.</p>\n<p>As seen in the benchmark, almost every script is much faster and only uses a small fraction of the varops budget. But we are interested in the worst cases and those worst cases are only reached when hashing (which you can do right now without any restrictions and produce blocks much slower than 100ms) and arithmetic on very large numbers.</p>\n<p>I don\u2019t think we can or should predict what the average block with GSR will look like, we only want to make sure there is a reasonable upper bound for script validation times, the purpose of the benchmark is to establish this upper bound.</p>\n<p>If 80,000 sig ops is too slow, why was it preserved in Taproot/BIP340-342? Varops really just wants to generalize this limit to all operations, without introducing a new worst case script.</p>",
  "post_number": 8,
  "post_type": 1,
  "posts_count": 14,
  "updated_at": "2025-12-05T14:43:09.680Z",
  "reply_count": 2,
  "reply_to_post_number": null,
  "quote_count": 2,
  "incoming_link_count": 1,
  "reads": 17,
  "readers_count": 16,
  "score": 18.4,
  "yours": false,
  "topic_id": 2094,
  "topic_slug": "benchmarking-bitcoin-script-evaluation-for-the-varops-budget-great-script-restoration",
  "topic_title": "Benchmarking Bitcoin Script Evaluation for the Varops Budget (Great Script Restoration)",
  "topic_html_title": "Benchmarking Bitcoin Script Evaluation for the Varops Budget (Great Script Restoration)",
  "category_id": 7,
  "display_username": "",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"ajtowns, post:6, topic:2094\"]\nDoing benchmarks on the more powerful logic new opcodes enable might be more interesting; eg the [OP_CAT based zkp verifier](https://bitcoinmagazine.com/technical/a-zero-knowledge-proof-is-verified-on-bitcoin-for-the-first-time-in-history)? How many zkps (implemented that way) could we verify in a block, if 100ms (or whatever) of cpu time were the only constraint? Seems to have some 223k operations per script, 30k ADD/DUP, 20k IF/ENDIF/SUB, 10k SWAP/LESSTHAN/TOALT/FROMALT, 400 CAT/1SUB/DEPTH/SHA256, 1 CHECKSIG, etc.\n\n[/quote]\n\nUnfortunately it seems that this implementation won\u2019t run properly due to the new number type used in GSR, we use an unsigned arbitrary length integer instead of the current signed 32bit int. The new stack limits and OP_MUL should also drastically reduce the number of transactions needed and probably also reduce their validation time.\n\n[quote=\"instagibbs, post:4, topic:2094\"]\nTIL it was that slow. I worry that benchmarking against the *worst case* as the new \u201caverage\u201d is the wrong goal as this may potentially become the average way of interacting with Bitcoin (unlike using lots of signatures, which seems rare). Basically we should expect \\~every block to approach that level of verification cost, so I\u2019d expect we would target something we would be happy with for IBD or at tip with relatively turbulent mempools. *waving wildly* On the order of 100ms?\n\n[/quote]\n\nWe benchmark a large collection of possible scripts and extract the worst case as the slowest execution time, this does not mean that it will be the new average, the 15 opcodes were disabled due to paranoia of nodes being DDoSed, as in an attacker trying to construct a block that causes memory overflows or extremely slow execution times.\n\nAs seen in the benchmark, almost every script is much faster and only uses a small fraction of the varops budget. But we are interested in the worst cases and those worst cases are only reached when hashing (which you can do right now without any restrictions and produce blocks much slower than 100ms) and arithmetic on very large numbers.\n\nI don\u2019t think we can or should predict what the average block with GSR will look like, we only want to make sure there is a reasonable upper bound for script validation times, the purpose of the benchmark is to establish this upper bound.\n\nIf 80,000 sig ops is too slow, why was it preserved in Taproot/BIP340-342? Varops really just wants to generalize this limit to all operations, without introducing a new worst case script.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 962,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Unfortunately it seems that this implementation won\u2019t run properly due to the new number type used in GSR, we use an unsigned arbitrary length integer instead of the current signed 32bit int. The new stack limits and OP_MUL should also drastically reduce the number of transactions needed and probab&hellip;",
  "truncated": true,
  "post_url": "/t/benchmarking-bitcoin-script-evaluation-for-the-varops-budget-great-script-restoration/2094/8",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}