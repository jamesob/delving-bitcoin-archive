{
  "id": 6358,
  "name": "Jonathan Harvey-Buschel",
  "username": "jonhbit",
  "avatar_template": "/user_avatar/delvingbitcoin.org/jonhbit/{size}/1661_2.png",
  "created_at": "2025-12-01T20:18:24.933Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"11\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>No, I meant, say you use 24 bits for blknum, 14 for txindex, 12 for output number, 1 for direction and 12 for blocknumber, that uniquely identifies each update in 64 bits.  But it someone uses the 4096th output of a tx for a channel, you can\u2019t encode it in the set.  For that, you simply encode it raw, outside the minisketch.</p>\n</blockquote>\n</aside>\n<p>Ah ok, makes sense now. I think another option is to use more bits per field, and then \u2018overlap\u2019 fields by XORing between the low-entropy bits of one field with the high-entropy bits of another.</p>\n<p>As an example, a 24 bit blknum field supports another ~300 years of blockheights (we could probably shrink it?). blknum could be encoded little-endian (LE) / with the LSBs starting from index 0. txindex is expanded to 18 bits, also encoded as LE, but starts from index 20. So the two fields overlap on 4 bits:</p>\n<p><code>Key[0:19] = LE(blknum)[0:19]</code></p>\n<p><code>Key[20:23] = LE(blknum)[20:23] \u2295 LE(txindex)[0:3]</code></p>\n<p><code>Key[24:37] = LE(txindex)[4:17]</code></p>\n<p>IMO we can adjust the size of these fields based on current constraints like min. tx size, etc. such that the amount of overlap is minimal, but we wouldn\u2019t need this fallback path.</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"11\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>You don\u2019t need to signal.  When you get their sketch, it fails for you.  So you go larger, if you can.</p>\n</blockquote>\n</aside>\n<p>This is the message flow I was thinking of in my response:</p>\n<pre data-code-wrap=\"mermaid\"><code class=\"lang-mermaid\">sequenceDiagram\n    participant Alice\n    participant Bob\n    \n    Alice-&gt;&gt;Bob: RequestSketch()\n    Bob--&gt;&gt;Alice: SketchDifferenceOfTwoFourths\n    Alice-&gt;&gt;Alice: DecodeSketch()\n    \n    alt DecodeSketch() failed\n        Alice-&gt;&gt;Bob: RequestSketchExtension()\n        Bob--&gt;&gt;Alice: SketchDifferenceOfThirdFourth\n        Alice-&gt;&gt;Alice: decode\n    end\n</code></pre>\n<p>I\u2019m unclear on what you meant by \u201cgo larger\u201d, but I think you meant that Alice should build a sketch from a larger set locally and retry reconciliation?. IIUC, if the number of differences exceeds the capacity of the sketch Bob sent Alice, Alice retrying reconciliation in this way would only succeed if the number of differences decreased between her first and second sets. Which may happen if she has reconciled with other peers in the meantime.</p>\n<p>I think we\u2019d probably want to do both? So if initial reconciliation fails, wait for timer_interval / 3 seconds, expand our local set, build a larger sketch, and try reconciliation again. If the 2nd reconciliation fails, ask Bob for a sketch extension and retry reconciliation a 3rd time. If it still fails, either:</p>\n<ul>\n<li>Query Bob for all set elements and reconcile locally (lots of bandwidth, minimal CPU)</li>\n<li>Give up on reconciliation with Bob for this interval, retry the normal reconciliation protocol in (timer_interval) * 2/3 seconds. Hope that our reconciliation with other peers reduces our difference with Bob.</li>\n</ul>\n<p>Another option is to ask Bob for a fresh sketch of the same capacity, instead of an extension of the 1st sketch we received.</p>\n<p>IIUC we mostly agree on the options for handling initial reconciliation failure; I think having evidence to decide will require simulation and tweaking parameters there.</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"11\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>Per-peer salt penalizes scaling.  Now each peer costs you more than bandwidth.  If we can avoid this, we should, and I think we can.</p>\n</blockquote>\n</aside>\n<p>My response earlier may have been missing a <code>/s</code> tag, sorry; I think we may just have a different mental model for which parts of this process consume more or less resources. From the benchmarks in the minisketch repo, and comments upthread, we know that:</p>\n<ul>\n<li>Encoding a sketch is very fast; most of the compute for reconciliation is part of sketch merging &amp; decoding.</li>\n<li>Decode time is quadratic with # of differences.</li>\n<li>Given current optimizations, decode time is 2x as long for 64-bit keys vs. 32-bit keys.</li>\n</ul>\n<p>My argument re: salting and 32-bit set keys, is that the additional complexity of per-connection salts, and the extra work of computing more set keys (1 per connection vs. 1 global set key), is <em>worth the expected ~2x savings</em> in compute for sketch decoding.</p>\n<p>As a supporting point, non-cryptographic hash functions like <a href=\"https://xxhash.com/\" rel=\"noopener nofollow ugc\">xxhash</a> are extremely fast for small inputs. As a detracting point, I suspect that a per-peer salt would require using a bit more memory to keep track of per-peer sketch state.</p>\n<p>I\u2019m not married to a requirement that we use 32-bit keys, but I think it\u2019s worth exploring / keeping in mind. Perhaps we can tweak other knobs, keep the # of differences down, and then not lose much by having longer 64-bit keys.</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"11\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>The current blockheight you are aware of.  This is important, because channel updates must be refreshed every 2048 blocks (IIRC in the new spec proposal), and you will accept new channel announcements on each block.  So you expect non-zero differences in this case.</p>\n<p>The block hash would allow you to see forks, if that happened.</p>\n</blockquote>\n</aside>\n<p>Makes sense, I agree <img src=\"https://delvingbitcoin.org/images/emoji/twitter/+1.png?v=14\" title=\":+1:\" class=\"emoji\" alt=\":+1:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"11\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>Note that the long pole in the scaling tent is channel updates.  Node announcements only change when you change IP address or something, and there are far fewer nodes than channels x 2.  Channel announcements only happen once per channel.</p>\n</blockquote>\n</aside>\n<p><img src=\"https://delvingbitcoin.org/images/emoji/twitter/+1.png?v=14\" title=\":+1:\" class=\"emoji only-emoji\" alt=\":+1:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"11\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>I think in practice, implementations will fall back to asking for everything if reconciliation fails. It has the benefit of being simple, both to implement and test.</p>\n</blockquote>\n</aside>\n<p>Fair; though I suspect maintaining a larger set / allowing messages to remain in the set for longer will help a lot with reconciliation reliability. Another question for simulation!</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"12\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>Yes, there\u2019s a whole load of fun avoiding griefing here. Some rando connects and sends you 8k elements of junk, you don\u2019t want to spend 1 second of CPU (based roughly on the graphs on the minisketch page). Fortunately you can limit it to some ceiling simply by trimming first. The ideal BOLT spec would give exact numbers here, but thorough benchmarks required (like, how long does it take the build the set for all the gossip in the first place? How long to maintain it on each block? etc).</p>\n</blockquote>\n</aside>\n<p>IIUC, the sketch decode has multiple steps, and most of the compute is in the final step. Before that final step, a decoder would know if decode is expected to yield a successful reconciliation with very high probability, before executing that final step. So an early exit should make the cost for that much smaller; I think this isn\u2019t yet implemented in the minisketch library though.</p>\n<p>I imagine you\u2019d only want to accept sketches after explicitly requesting them, and you\u2019d disconnect peers that repeatedly send malformed sketches.</p>\n<p>I agree a lot of this will depend on some more benchmarking, especially since I think our set and difference sizes may be larger than what is covered on the minisketch repo right now. More varied benchmarking should be a straightforward first step before network-level simulation, I\u2019ll look into it.</p>",
  "post_number": 13,
  "post_type": 1,
  "posts_count": 20,
  "updated_at": "2025-12-01T20:19:43.253Z",
  "reply_count": 3,
  "reply_to_post_number": 11,
  "quote_count": 2,
  "incoming_link_count": 1,
  "reads": 27,
  "readers_count": 26,
  "score": 25.4,
  "yours": false,
  "topic_id": 2105,
  "topic_slug": "gossip-observer-new-project-to-monitor-the-lightning-p2p-network",
  "topic_title": "Gossip Observer: New project to monitor the Lightning P2P network",
  "topic_html_title": "Gossip Observer: New project to monitor the Lightning P2P network",
  "category_id": 7,
  "display_username": "Jonathan Harvey-Buschel",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"rustyrussell, post:11, topic:2105\"]\nNo, I meant, say you use 24 bits for blknum, 14 for txindex, 12 for output number, 1 for direction and 12 for blocknumber, that uniquely identifies each update in 64 bits.  But it someone uses the 4096th output of a tx for a channel, you can\u2019t encode it in the set.  For that, you simply encode it raw, outside the minisketch.\n\n[/quote]\n\nAh ok, makes sense now. I think another option is to use more bits per field, and then \u2018overlap\u2019 fields by XORing between the low-entropy bits of one field with the high-entropy bits of another.\n\nAs an example, a 24 bit blknum field supports another ~300 years of blockheights (we could probably shrink it?). blknum could be encoded little-endian (LE) / with the LSBs starting from index 0. txindex is expanded to 18 bits, also encoded as LE, but starts from index 20. So the two fields overlap on 4 bits:\n\n`Key[0:19] = LE(blknum)[0:19]`\n\n`Key[20:23] = LE(blknum)[20:23] \u2295 LE(txindex)[0:3]`\n\n`Key[24:37] = LE(txindex)[4:17]`\n\nIMO we can adjust the size of these fields based on current constraints like min. tx size, etc. such that the amount of overlap is minimal, but we wouldn't need this fallback path.\n\n[quote=\"rustyrussell, post:11, topic:2105\"]\nYou don\u2019t need to signal.  When you get their sketch, it fails for you.  So you go larger, if you can.\n[/quote]\n\nThis is the message flow I was thinking of in my response:\n\n```mermaid\nsequenceDiagram\n    participant Alice\n    participant Bob\n    \n    Alice->>Bob: RequestSketch()\n    Bob-->>Alice: SketchDifferenceOfTwoFourths\n    Alice->>Alice: DecodeSketch()\n    \n    alt DecodeSketch() failed\n        Alice->>Bob: RequestSketchExtension()\n        Bob-->>Alice: SketchDifferenceOfThirdFourth\n        Alice->>Alice: decode\n    end\n```\n\nI'm unclear on what you meant by \"go larger\", but I think you meant that Alice should build a sketch from a larger set locally and retry reconciliation?. IIUC, if the number of differences exceeds the capacity of the sketch Bob sent Alice, Alice retrying reconciliation in this way would only succeed if the number of differences decreased between her first and second sets. Which may happen if she has reconciled with other peers in the meantime.\n\nI think we'd probably want to do both? So if initial reconciliation fails, wait for timer_interval / 3 seconds, expand our local set, build a larger sketch, and try reconciliation again. If the 2nd reconciliation fails, ask Bob for a sketch extension and retry reconciliation a 3rd time. If it still fails, either:\n\n- Query Bob for all set elements and reconcile locally (lots of bandwidth, minimal CPU)\n- Give up on reconciliation with Bob for this interval, retry the normal reconciliation protocol in (timer_interval) * 2/3 seconds. Hope that our reconciliation with other peers reduces our difference with Bob.\n\nAnother option is to ask Bob for a fresh sketch of the same capacity, instead of an extension of the 1st sketch we received.\n\nIIUC we mostly agree on the options for handling initial reconciliation failure; I think having evidence to decide will require simulation and tweaking parameters there.\n\n[quote=\"rustyrussell, post:11, topic:2105\"]\nPer-peer salt penalizes scaling.  Now each peer costs you more than bandwidth.  If we can avoid this, we should, and I think we can.\n[/quote]\n\nMy response earlier may have been missing a `/s` tag, sorry; I think we may just have a different mental model for which parts of this process consume more or less resources. From the benchmarks in the minisketch repo, and comments upthread, we know that:\n\n- Encoding a sketch is very fast; most of the compute for reconciliation is part of sketch merging & decoding.\n- Decode time is quadratic with # of differences.\n- Given current optimizations, decode time is 2x as long for 64-bit keys vs. 32-bit keys.\n\nMy argument re: salting and 32-bit set keys, is that the additional complexity of per-connection salts, and the extra work of computing more set keys (1 per connection vs. 1 global set key), is _worth the expected ~2x savings_ in compute for sketch decoding.\n\nAs a supporting point, non-cryptographic hash functions like [xxhash](https://xxhash.com/) are extremely fast for small inputs. As a detracting point, I suspect that a per-peer salt would require using a bit more memory to keep track of per-peer sketch state.\n\nI'm not married to a requirement that we use 32-bit keys, but I think it's worth exploring / keeping in mind. Perhaps we can tweak other knobs, keep the # of differences down, and then not lose much by having longer 64-bit keys.\n\n[quote=\"rustyrussell, post:11, topic:2105\"]\nThe current blockheight you are aware of.  This is important, because channel updates must be refreshed every 2048 blocks (IIRC in the new spec proposal), and you will accept new channel announcements on each block.  So you expect non-zero differences in this case.\n\nThe block hash would allow you to see forks, if that happened.\n[/quote]\n\nMakes sense, I agree :+1: \n\n[quote=\"rustyrussell, post:11, topic:2105\"]\nNote that the long pole in the scaling tent is channel updates.  Node announcements only change when you change IP address or something, and there are far fewer nodes than channels x 2.  Channel announcements only happen once per channel.\n[/quote]\n\n:+1: \n\n[quote=\"rustyrussell, post:11, topic:2105\"]\nI think in practice, implementations will fall back to asking for everything if reconciliation fails. It has the benefit of being simple, both to implement and test.\n[/quote]\n\nFair; though I suspect maintaining a larger set / allowing messages to remain in the set for longer will help a lot with reconciliation reliability. Another question for simulation!\n\n[quote=\"rustyrussell, post:12, topic:2105\"]\nYes, there\u2019s a whole load of fun avoiding griefing here. Some rando connects and sends you 8k elements of junk, you don\u2019t want to spend 1 second of CPU (based roughly on the graphs on the minisketch page). Fortunately you can limit it to some ceiling simply by trimming first. The ideal BOLT spec would give exact numbers here, but thorough benchmarks required (like, how long does it take the build the set for all the gossip in the first place? How long to maintain it on each block? etc).\n[/quote]\n\nIIUC, the sketch decode has multiple steps, and most of the compute is in the final step. Before that final step, a decoder would know if decode is expected to yield a successful reconciliation with very high probability, before executing that final step. So an early exit should make the cost for that much smaller; I think this isn't yet implemented in the minisketch library though.\n\nI imagine you'd only want to accept sketches after explicitly requesting them, and you'd disconnect peers that repeatedly send malformed sketches.\n\nI agree a lot of this will depend on some more benchmarking, especially since I think our set and difference sizes may be larger than what is covered on the minisketch repo right now. More varied benchmarking should be a straightforward first step before network-level simulation, I'll look into it.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 982,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Ah ok, makes sense now. I think another option is to use more bits per field, and then \u2018overlap\u2019 fields by XORing between the low-entropy bits of one field with the high-entropy bits of another. \nAs an example, a 24 bit blknum field supports another ~300 years of blockheights (we could probably shr&hellip;",
  "truncated": true,
  "post_url": "/t/gossip-observer-new-project-to-monitor-the-lightning-p2p-network/2105/13",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}