{
  "id": 6435,
  "name": "Jonathan Harvey-Buschel",
  "username": "jonhbit",
  "avatar_template": "/user_avatar/delvingbitcoin.org/jonhbit/{size}/1661_2.png",
  "created_at": "2025-12-15T18:57:15.730Z",
  "cooked": "<aside class=\"quote no-group quote-modified\" data-username=\"rustyrussell\" data-post=\"14\" data-topic=\"2105\" data-full=\"true\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<aside class=\"quote no-group\" data-username=\"jonhbit\" data-post=\"13\" data-topic=\"2105\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/jonhbit/48/1661_2.png\" class=\"avatar\"> jonhbit:</div>\n<blockquote>\n<p>IMO we can adjust the size of these fields based on current constraints like min. tx size, etc. such that the amount of overlap is minimal, but we wouldn\u2019t need this fallback path.</p>\n</blockquote>\n</aside>\n<p>But now you need to detect clashes and decide who wins.  Easier to up-front fail to decode, in practice.</p>\n</blockquote>\n</aside>\n<p>I agree that we\u2019ll need some logic to handle outpoints that we can\u2019t encode. Given that the top block of a 24-bit blocknum will flip ~142 years from now, IMO it\u2019s fine to XOR that with the bottom bit of txindex.</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"14\" data-topic=\"2105\" data-full=\"true\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>How about:</p>\n<ol>\n<li>Send a sketch every 60 seconds.  You may reduce the set before sending.</li>\n<li>If you receive a sketch you can decode, simply reply with any messages the sender is missing.</li>\n<li>If you can\u2019t decode:\n<ol>\n<li>If they are on a different blockheight, ignore.</li>\n<li>If you can send a larger set, do so next time.</li>\n<li>If you have other peers, wait until you get more failures.</li>\n<li>If they have much less gossip than you, start streaming gossip.</li>\n<li>Otherwise, something is wrong, query them for everything (or if you don\u2019t have a channel with them, ignore?).</li>\n</ol>\n</li>\n</ol>\n<p>I don\u2019t really think a query protocol is needed.</p>\n</blockquote>\n</aside>\n<p>I got to talk to someone from the LDK team last week, and they presented some convincing arguments of why a query protocol doesn\u2019t really add value. But the consequences of the ordering you\u2019re describing seem a bit \u2018flipped\u2019 to me, specifically point 3.2.</p>\n<p>Since sketch decode is most of the work, in order for Alice to increase her odds of a successful sketch decode for the next received sketch, she will send her peer Bob a larger sketch, and he\u2019ll perform (much) more work, and possibly end up sending Alice more messages she\u2019s missing? The extra work is done by Bob, for Alice\u2019s benefit.</p>\n<p>A simplified version of my diagram above is that Alice never explicitly requests initial sketches (so your step 1). But she MAY request an extension, and attempt decode again. The decode work is still done by Alice, not Bob. However, I <em>think</em> that would require new P2P messages so Alice could query Bob for missing set elements.</p>\n<p>Another point that came out of discussions last week was that, instead of tracking the \u2018freshness\u2019 of sketches per peer (I make a new sketch for each peer right before sending a sketch to them), a node can have one \u2018internal\u2019 timer of when they will recompute their sketch, and separate peer-per timers of when they will send whichever sketch they have. So there would be no tracking of which elements were included in the last sketch sent to a particular peer, and the cost of serving a sketch extension is just bandwidth vs. more compute.</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"15\" data-topic=\"2105\" data-full=\"true\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>That API would be great, but meanwhile I think you just trim untrusted sources to use a small sketch, which bounds the time.</p>\n</blockquote>\n</aside>\n<p>That would definitely work. FWIW, I think the odds of getting that feature added to libminisketch are high, if the use case can be clearly demonstrated.</p>\n<aside class=\"quote no-group\" data-username=\"rustyrussell\" data-post=\"15\" data-topic=\"2105\" data-full=\"true\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/rustyrussell/48/154_2.png\" class=\"avatar\"> rustyrussell:</div>\n<blockquote>\n<p>If a failure to decode simply (eventually) results in you streaming all gossip, it\u2019s no worse than the current case where a peer explicitly asks you for all gossip?</p>\n</blockquote>\n</aside>\n<p>I\u2019m not sure how often the \u2018stream all gossip\u2019 fallback is used now, so\u2026maybe? If a node is offline for long enough, I definitely agree that reconciliation won\u2019t work for catching up on gossip. But that feels separate from handling a decode failure during normal operation. It\u2019s interesting that decode failure/success gives some signal on how much information a node is missing, compared to the situation now / with flooding.</p>",
  "post_number": 16,
  "post_type": 1,
  "posts_count": 20,
  "updated_at": "2025-12-15T18:58:58.332Z",
  "reply_count": 0,
  "reply_to_post_number": 14,
  "quote_count": 3,
  "incoming_link_count": 0,
  "reads": 19,
  "readers_count": 18,
  "score": 3.8,
  "yours": false,
  "topic_id": 2105,
  "topic_slug": "gossip-observer-new-project-to-monitor-the-lightning-p2p-network",
  "topic_title": "Gossip Observer: New project to monitor the Lightning P2P network",
  "topic_html_title": "Gossip Observer: New project to monitor the Lightning P2P network",
  "category_id": 7,
  "display_username": "Jonathan Harvey-Buschel",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"rustyrussell, post:14, topic:2105, full:true\"]\n[quote=\"jonhbit, post:13, topic:2105\"]\nIMO we can adjust the size of these fields based on current constraints like min. tx size, etc. such that the amount of overlap is minimal, but we wouldn\u2019t need this fallback path.\n[/quote]\n\n\nBut now you need to detect clashes and decide who wins.  Easier to up-front fail to decode, in practice.\n[/quote]\n\nI agree that we'll need some logic to handle outpoints that we can't encode. Given that the top block of a 24-bit blocknum will flip ~142 years from now, IMO it's fine to XOR that with the bottom bit of txindex.\n\n[quote=\"rustyrussell, post:14, topic:2105, full:true\"]\nHow about:\n\n1. Send a sketch every 60 seconds.  You may reduce the set before sending.\n2. If you receive a sketch you can decode, simply reply with any messages the sender is missing.\n3. If you can\u2019t decode:\n   1. If they are on a different blockheight, ignore.\n   2. If you can send a larger set, do so next time.\n   3. If you have other peers, wait until you get more failures.\n   4. If they have much less gossip than you, start streaming gossip.\n   5. Otherwise, something is wrong, query them for everything (or if you don\u2019t have a channel with them, ignore?).\n\n\nI don\u2019t really think a query protocol is needed.\n[/quote]\n\nI got to talk to someone from the LDK team last week, and they presented some convincing arguments of why a query protocol doesn't really add value. But the consequences of the ordering you're describing seem a bit 'flipped' to me, specifically point 3.2.\n\nSince sketch decode is most of the work, in order for Alice to increase her odds of a successful sketch decode for the next received sketch, she will send her peer Bob a larger sketch, and he'll perform (much) more work, and possibly end up sending Alice more messages she's missing? The extra work is done by Bob, for Alice's benefit.\n\nA simplified version of my diagram above is that Alice never explicitly requests initial sketches (so your step 1). But she MAY request an extension, and attempt decode again. The decode work is still done by Alice, not Bob. However, I *think* that would require new P2P messages so Alice could query Bob for missing set elements.\n\nAnother point that came out of discussions last week was that, instead of tracking the 'freshness' of sketches per peer (I make a new sketch for each peer right before sending a sketch to them), a node can have one 'internal' timer of when they will recompute their sketch, and separate peer-per timers of when they will send whichever sketch they have. So there would be no tracking of which elements were included in the last sketch sent to a particular peer, and the cost of serving a sketch extension is just bandwidth vs. more compute.\n\n[quote=\"rustyrussell, post:15, topic:2105, full:true\"]\nThat API would be great, but meanwhile I think you just trim untrusted sources to use a small sketch, which bounds the time.\n[/quote]\n\nThat would definitely work. FWIW, I think the odds of getting that feature added to libminisketch are high, if the use case can be clearly demonstrated.\n\n[quote=\"rustyrussell, post:15, topic:2105, full:true\"]\nIf a failure to decode simply (eventually) results in you streaming all gossip, it\u2019s no worse than the current case where a peer explicitly asks you for all gossip?\n[/quote]\n\nI'm not sure how often the 'stream all gossip' fallback is used now, so...maybe? If a node is offline for long enough, I definitely agree that reconciliation won't work for catching up on gossip. But that feels separate from handling a decode failure during normal operation. It's interesting that decode failure/success gives some signal on how much information a node is missing, compared to the situation now / with flooding.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 982,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "But now you need to detect clashes and decide who wins.  Easier to up-front fail to decode, in practice. \n\n\nI agree that we\u2019ll need some logic to handle outpoints that we can\u2019t encode. Given that the top block of a 24-bit blocknum will flip ~142 years from now, IMO it\u2019s fine to XOR that with the bo&hellip;",
  "truncated": true,
  "post_url": "/t/gossip-observer-new-project-to-monitor-the-lightning-p2p-network/2105/16",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}