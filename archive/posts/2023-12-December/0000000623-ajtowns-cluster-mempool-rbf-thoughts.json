{
  "id": 623,
  "name": "Anthony Towns",
  "username": "ajtowns",
  "avatar_template": "/user_avatar/delvingbitcoin.org/ajtowns/{size}/417_2.png",
  "created_at": "2023-12-05T15:56:26.733Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"sdaftuar\" data-post=\"7\" data-topic=\"156\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/letter_avatar_proxy/v4/letter/s/0ea827/48.png\" class=\"avatar\"> sdaftuar:</div>\n<blockquote>\n<p>So if we permit a transaction to conflict with 100 in-mempool transactions, and if we permit each cluster to have up to 100 transactions, then we\u2019re looking at 10000 potential chunks to iterate. That seems like it could be slow.</p>\n</blockquote>\n</aside>\n<p>An <span class=\"math\">O(n)</span> operation on two sets of 10k pairs of <code>int64_t</code> seems pretty fine? (Maybe add a log(n) factor to combine the clusters) You might need to be clever about generating the set of new clusters efficiently, based on the original set and the conflicted/new transactions, rather than doing it from scratch though?</p>",
  "post_number": 10,
  "post_type": 1,
  "posts_count": 25,
  "updated_at": "2023-12-05T15:56:26.733Z",
  "reply_count": 0,
  "reply_to_post_number": 7,
  "quote_count": 1,
  "incoming_link_count": 0,
  "reads": 30,
  "readers_count": 29,
  "score": 6.0,
  "yours": false,
  "topic_id": 156,
  "topic_slug": "cluster-mempool-rbf-thoughts",
  "topic_title": "Cluster Mempool RBF Thoughts",
  "topic_html_title": "Cluster Mempool RBF Thoughts",
  "category_id": 8,
  "display_username": "Anthony Towns",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"sdaftuar, post:7, topic:156\"]\nSo if we permit a transaction to conflict with 100 in-mempool transactions, and if we permit each cluster to have up to 100 transactions, then we\u2019re looking at 10000 potential chunks to iterate. That seems like it could be slow.\n[/quote]\n\nAn $O(n)$ operation on two sets of 10k pairs of `int64_t` seems pretty fine? (Maybe add a log(n) factor to combine the clusters) You might need to be clever about generating the set of new clusters efficiently, based on the original set and the conflicted/new transactions, rather than doing it from scratch though?",
  "actions_summary": [],
  "moderator": true,
  "admin": true,
  "staff": true,
  "user_id": 3,
  "hidden": false,
  "trust_level": 4,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "An O(n) operation on two sets of 10k pairs of int64_t seems pretty fine? (Maybe add a log(n) factor to combine the clusters) You might need to be clever about generating the set of new clusters efficiently, based on the original set and the conflicted/new transactions, rather than doing it from scr&hellip;",
  "truncated": true,
  "post_url": "/t/cluster-mempool-rbf-thoughts/156/10",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}