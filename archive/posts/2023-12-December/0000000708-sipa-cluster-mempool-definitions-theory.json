{
  "id": 708,
  "name": "Pieter Wuille",
  "username": "sipa",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sipa/{size}/102_2.png",
  "created_at": "2023-12-11T03:20:42.120Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"ajtowns\" data-post=\"6\" data-topic=\"202\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/3_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Oh, actually, I think you want the smallest ones last, if anything? (Or is my guess for getting mildly better performance out of greedy knapsack selection off the mark?)</p>\n<p>Is this about optimising for the last few transactions in a block, or choosing a canonical ordering so there\u2019s less uncertainty/ambiguity, or something else?</p>\n</blockquote>\n</aside>\n<p>It\u2019s about optimizing for the last few transactions in a block; the more chunks clusters are broken up in, the more puzzle pieces there are to use. I don\u2019t think you can - without whole-mempool context - say whether the beginning or the end of a cluster is better to have small pieces, as you don\u2019t know ahead of time where they\u2019ll end up in a block. And I think the splitting itself is more important than the ordering.</p>\n<aside class=\"quote no-group quote-modified\" data-username=\"ajtowns\" data-post=\"6\" data-topic=\"202\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/3_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>You can\u2019t get a strictly unique \u201cperfect\u201d linearisation, since if you have txs A, B, C, C spending A and B, and A,B having equal fee and size, but lower feerate than C, then [ABC] and [BAC] are equally good linearisations. You could break the tie by resorting to your arbitrary order R_2R2R_2, of course, but that\u2019s still picking a winner arbitrarily\u2026</p>\n</blockquote>\n</aside>\n<p>Yeah. I don\u2019t think we need to pick a well-defined unique optimal.</p>\n<aside class=\"quote no-group quote-modified\" data-username=\"ajtowns\" data-post=\"6\" data-topic=\"202\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/ajtowns/48/3_2.png\" class=\"avatar\"> ajtowns:</div>\n<blockquote>\n<p>Your definition of optoptopt seems weird? Shouldn\u2019t that just be \\operatorname{opt}(G) = L_G + \\operatorname{opt}(G \\setminus S_G)opt(G)=LG+opt(G\u2216SG)\\operatorname{opt}(G) = L_G + \\operatorname{opt}(G \\setminus S_G) where S_GSGS_G is the highest-feerate subset of GGG and L_GLGL_G is the first valid linearisation of S_GSGS_G?</p>\n<p>I would have proven the uniqueness claim non-constructively: set f(L) = |{L_2 | L \\ge L2}|f(L)=|{L2|L\u2265L2}|f(L) = |{L_2 | L \\ge L2}|. Pick a linearisation L_xLxL_x where f(L_x) \\ge f(L)f(Lx)\u2265f(L)f(L_x) \\ge f(L) for all LLL. If this value equals the count of all linearisations, then L_x \\ge LLx\u2265LL_x \\ge L for all LLL, so L_xLxL_x is an optimal linearisation. If it\u2019s not the case, then there is some L_yLyL_y where L_x \\not\\ge L_yLx\u2271LyL_x \\not\\ge L_y, so calculate L_z = \\operatorname{merge}(L_x, L_y)Lz=merge(Lx,Ly)L_z = \\operatorname{merge}(L_x, L_y) which gives us L_z \\ge L_xLz\u2265LxL_z \\ge L_x but also L_z \\ge L_yLz\u2265LyL_z \\ge L_y. But for any LLL where L_x \\ge LLx\u2265LL_x \\ge L, L_z \\ge LLz\u2265LL_z \\ge L by transitivity, so f(L_z) \\gt f(L_x)f(Lz)&gt;f(Lx)f(L_z) \\gt f(L_x) which contradicts our choice of L_xLxL_x.</p>\n</blockquote>\n</aside>\n<p>Yeah, that\u2019s proving the existence of optimality through <span class=\"math\">\\operatorname{merge}</span>. My thinking was to prove existence of optimality before introducing merging (because proving that \u201cmove best subset to the front, continue\u201d is optimal seems more intuitive than through merging), but perhaps that\u2019s an unnecessary detour.</p>\n<p>An alternative way to prove that, I think, is as follows. Let <span class=\"math\">M</span> be the set of maximal elements of the set of valid linearizations for a given graph (maxima have no elements that compare strictly higher than them, but may have elements incomparable to them).</p>\n<ul>\n<li>If <span class=\"math\">M = \\{\\}</span>: impossible in a finite set (start with any element and keep picking a strictly larger element, eventually you end up in a cycle, which is impossible as it implies elements strictly larger than themselves).</li>\n<li>If <span class=\"math\">M = \\{m\\}</span>, then <span class=\"math\">m</span> is optimal. Again start with any element, and keep picking strictly larger elements. Each of these chains must end with <span class=\"math\">m</span> as it\u2019s the only element with no larger ones. Thus, <span class=\"math\">m &gt;</span> everything else.</li>\n<li>Otherwise <span class=\"math\">M</span> consists of two or more elements: merge them, and end up with something better than both. This is in contradiction with them being maximal elements.</li>\n</ul>",
  "post_number": 7,
  "post_type": 1,
  "updated_at": "2023-12-11T04:57:05.856Z",
  "reply_count": 0,
  "reply_to_post_number": 6,
  "quote_count": 1,
  "incoming_link_count": 0,
  "reads": 4,
  "readers_count": 3,
  "score": 0.8,
  "yours": false,
  "topic_id": 202,
  "topic_slug": "cluster-mempool-definitions-theory",
  "topic_title": "Cluster mempool definitions & theory",
  "topic_html_title": "Cluster mempool definitions &amp; theory",
  "category_id": 9,
  "display_username": "Pieter Wuille",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "version": 5,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"ajtowns, post:6, topic:202\"]\nOh, actually, I think you want the smallest ones last, if anything? (Or is my guess for getting mildly better performance out of greedy knapsack selection off the mark?)\n\nIs this about optimising for the last few transactions in a block, or choosing a canonical ordering so there\u2019s less uncertainty/ambiguity, or something else?\n[/quote]\n\nIt's about optimizing for the last few transactions in a block; the more chunks clusters are broken up in, the more puzzle pieces there are to use. I don't think you can - without whole-mempool context - say whether the beginning or the end of a cluster is better to have small pieces, as you don't know ahead of time where they'll end up in a block. And I think the splitting itself is more important than the ordering.\n\n[quote=\"ajtowns, post:6, topic:202\"]\nYou can\u2019t get a strictly unique \u201cperfect\u201d linearisation, since if you have txs A, B, C, C spending A and B, and A,B having equal fee and size, but lower feerate than C, then [ABC] and [BAC] are equally good linearisations. You could break the tie by resorting to your arbitrary order R_2R2R_2, of course, but that\u2019s still picking a winner arbitrarily\u2026\n[/quote]\n\nYeah. I don't think we need to pick a well-defined unique optimal.\n\n[quote=\"ajtowns, post:6, topic:202\"]\nYour definition of optoptopt seems weird? Shouldn\u2019t that just be \\operatorname{opt}(G) = L_G + \\operatorname{opt}(G \\setminus S_G)opt(G)=LG+opt(G\u2216SG)\\operatorname{opt}(G) = L_G + \\operatorname{opt}(G \\setminus S_G) where S_GSGS_G is the highest-feerate subset of GGG and L_GLGL_G is the first valid linearisation of S_GSGS_G?\n\nI would have proven the uniqueness claim non-constructively: set f(L) = |\\{L_2 | L \\ge L2\\}|f(L)=|{L2|L\u2265L2}|f(L) = |\\{L_2 | L \\ge L2\\}|. Pick a linearisation L_xLxL_x where f(L_x) \\ge f(L)f(Lx)\u2265f(L)f(L_x) \\ge f(L) for all LLL. If this value equals the count of all linearisations, then L_x \\ge LLx\u2265LL_x \\ge L for all LLL, so L_xLxL_x is an optimal linearisation. If it\u2019s not the case, then there is some L_yLyL_y where L_x \\not\\ge L_yLx\u2271LyL_x \\not\\ge L_y, so calculate L_z = \\operatorname{merge}(L_x, L_y)Lz=merge(Lx,Ly)L_z = \\operatorname{merge}(L_x, L_y) which gives us L_z \\ge L_xLz\u2265LxL_z \\ge L_x but also L_z \\ge L_yLz\u2265LyL_z \\ge L_y. But for any LLL where L_x \\ge LLx\u2265LL_x \\ge L, L_z \\ge LLz\u2265LL_z \\ge L by transitivity, so f(L_z) \\gt f(L_x)f(Lz)>f(Lx)f(L_z) \\gt f(L_x) which contradicts our choice of L_xLxL_x.\n[/quote]\n\nYeah, that's proving the existence of optimality through $\\operatorname{merge}$. My thinking was to prove existence of optimality before introducing merging (because proving that \"move best subset to the front, continue\" is optimal seems more intuitive than through merging), but perhaps that's an unnecessary detour.\n\nAn alternative way to prove that, I think, is as follows. Let $M$ be the set of maximal elements of the set of valid linearizations for a given graph (maxima have no elements that compare strictly higher than them, but may have elements incomparable to them). \n* If $M = \\{\\}$: impossible in a finite set (start with any element and keep picking a strictly larger element, eventually you end up in a cycle, which is impossible as it implies elements strictly larger than themselves).\n* If $M = \\{m\\}$, then $m$ is optimal. Again start with any element, and keep picking strictly larger elements. Each of these chains must end with $m$ as it's the only element with no larger ones. Thus, $m >$ everything else.\n* Otherwise $M$ consists of two or more elements: merge them, and end up with something better than both. This is in contradiction with them being maximal elements.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 96,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}