{
  "id": 3471,
  "name": "Antoine Poinsot",
  "username": "AntoineP",
  "avatar_template": "/user_avatar/delvingbitcoin.org/antoinep/{size}/483_2.png",
  "created_at": "2024-11-04T18:49:27.441Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"andrewtoth\" data-post=\"4\" data-topic=\"1222\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/andrewtoth/48/576_2.png\" class=\"avatar\"> andrewtoth:</div>\n<blockquote>\n<p>Based on insights from a private conversation, Libbitcoin will also skip checking confirmability if below the milestone. This means that transactions are written in order in the confirmability thread, but their inputs are assumed to exist and be yet unspent. Skipping this check is where the real speedup lies I believe, and was not clear to me on first read.</p>\n</blockquote>\n</aside>\n<p>Thanks for pointing out it\u2019s worth underlining this in the writeup. Will edit OP.</p>\n<p>I do also think this is what drives most of the IBD speedup there. And it is directly related to their architecture, doing it for Bitcoin Core wouldn\u2019t bring much benefit since you still have to update the UTxO set (see also <a href=\"https://gnusha.org/bitcoin-core-dev/2024-10-24.log\">this #bitcoin-core-dev discussion</a> discussion about this).</p>\n<aside class=\"quote no-group\" data-username=\"josibake\" data-post=\"5\" data-topic=\"1222\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/josibake/48/83_2.png\" class=\"avatar\"> josibake:</div>\n<blockquote>\n<p>My intuition is that the speedups are coming from the more aggressive peer utilisation during download, and the clear separation of unordered vs ordered checks to take advantage of parallelism.</p>\n</blockquote>\n</aside>\n<p>Yes although in the context of this specific benchmark it\u2019s more about being able to skip a whole class of checks than parallelizing them, i think.</p>\n<aside class=\"quote no-group\" data-username=\"josibake\" data-post=\"5\" data-topic=\"1222\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/josibake/48/83_2.png\" class=\"avatar\"> josibake:</div>\n<blockquote>\n<p>These are very high-level handwavey claims, and as its been mentioned already, Libbitcoin might be able to close this gap on fully validating new blocks after implementing libsecp / SHANI optimisations that are currently in Core.</p>\n</blockquote>\n</aside>\n<p>Even if they do, we can expect there still being an edge in using a UTxO set (as long as it doesn\u2019t get enormous) as you check inputs against a much smaller index.</p>\n<aside class=\"quote no-group\" data-username=\"josibake\" data-post=\"5\" data-topic=\"1222\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/josibake/48/83_2.png\" class=\"avatar\"> josibake:</div>\n<blockquote>\n<p>My personal view on the role of a Bitcoin node is that its primary purpose is to validate and propagate new blocks as quickly as possible, such that all nodes and miners on the network can quickly come to agreement on what the longest/heaviest PoW chain is. This is why I favour the <em>Block</em> based data model.</p>\n</blockquote>\n</aside>\n<p>This isn\u2019t so much block storage which makes a difference but how their content is indexed. In this case it would be clearer to make a distinction between a historical transactions index vs an unspent outputs index.</p>",
  "post_number": 7,
  "post_type": 1,
  "updated_at": "2024-11-04T18:49:27.441Z",
  "reply_count": 0,
  "reply_to_post_number": 4,
  "quote_count": 2,
  "incoming_link_count": 1,
  "reads": 26,
  "readers_count": 25,
  "score": 10.2,
  "yours": false,
  "topic_id": 1222,
  "topic_slug": "libbitcoin-for-core-people",
  "topic_title": "Libbitcoin for Core people",
  "topic_html_title": "Libbitcoin for Core people",
  "category_id": 8,
  "display_username": "Antoine Poinsot",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"andrewtoth, post:4, topic:1222\"]\nBased on insights from a private conversation, Libbitcoin will also skip checking confirmability if below the milestone. This means that transactions are written in order in the confirmability thread, but their inputs are assumed to exist and be yet unspent. Skipping this check is where the real speedup lies I believe, and was not clear to me on first read.\n[/quote]\n\nThanks for pointing out it's worth underlining this in the writeup. Will edit OP.\n\nI do also think this is what drives most of the IBD speedup there. And it is directly related to their architecture, doing it for Bitcoin Core wouldn't bring much benefit since you still have to update the UTxO set (see also [this #bitcoin-core-dev discussion](https://gnusha.org/bitcoin-core-dev/2024-10-24.log) discussion about this).\n\n[quote=\"josibake, post:5, topic:1222\"]\nMy intuition is that the speedups are coming from the more aggressive peer utilisation during download, and the clear separation of unordered vs ordered checks to take advantage of parallelism.\n[/quote]\n\nYes although in the context of this specific benchmark it's more about being able to skip a whole class of checks than parallelizing them, i think.\n\n[quote=\"josibake, post:5, topic:1222\"]\nThese are very high-level handwavey claims, and as its been mentioned already, Libbitcoin might be able to close this gap on fully validating new blocks after implementing libsecp / SHANI optimisations that are currently in Core.\n[/quote]\n\nEven if they do, we can expect there still being an edge in using a UTxO set (as long as it doesn't get enormous) as you check inputs against a much smaller index.\n\n[quote=\"josibake, post:5, topic:1222\"]\nMy personal view on the role of a Bitcoin node is that its primary purpose is to validate and propagate new blocks as quickly as possible, such that all nodes and miners on the network can quickly come to agreement on what the longest/heaviest PoW chain is. This is why I favour the *Block* based data model.\n[/quote]\n\nThis isn't so much block storage which makes a difference but how their content is indexed. In this case it would be clearer to make a distinction between a historical transactions index vs an unspent outputs index.",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 12,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}