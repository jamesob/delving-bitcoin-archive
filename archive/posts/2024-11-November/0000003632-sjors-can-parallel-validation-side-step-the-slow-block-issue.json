{
  "id": 3632,
  "name": "Sjors Provoost",
  "username": "sjors",
  "avatar_template": "/user_avatar/delvingbitcoin.org/sjors/{size}/59_2.png",
  "created_at": "2024-11-28T14:01:03.991Z",
  "cooked": "<p>The <a href=\"https://delvingbitcoin.org/t/great-consensus-cleanup-revival/710\">Great Consensus Cleanup</a> (revival) proposal attempts to address worst case block validation time through a consensus change. This is fundamentally a whack-a-mole game, as there could always be some unknown unknown method out there to produce blocks that take a long time to validate.</p>\n<p>Every whack takes years and can be difficult to execute without disclosing the vulnerability.</p>\n<p>And with every future soft fork we need to deeply worry about block validation time. Although SegWit and Taproot have made it easier to reason about this sort of thing, and entirely new schemes like Simplicity take full account of it.</p>\n<p><strong>It would be really nice if we can make slow blocks a problem only for the miner who produced one.</strong> That would make them a useless instrument for attacks, leaving only a concern for accidents (and protecting miners through standardness rules, but those can be changed more quickly).</p>\n<p>Perhaps parallel block validation can achieve this.</p>\n<p>The idea of parallel block validation is that if your node sees two blocks competing for the same height, it tries to validate both in parallel and picks whichever it finishes first, which it then announces and builds on.</p>\n<p>In the current situation Bitcoin Core will evaluate whichever block is sees first, and completely ignore the outside world until it\u2019s done validating. It only matters which block reaches the node first.</p>\n<p>Instead, parallel block validation should cause fast-to-validate blocks to propagate better when they\u2019re directly competing with a slow-to-validate block. This increases the stale risk for slow-to-validate blocks, which increases the cost of any attack that involves such blocks.</p>\n<p>Pure parallel validation is very complicated to implement. Instead, a simpler approach could be that while the node is busy validating a block, it keeps listening to announcements for competing blocks. If such a block appears, it aborts the ongoing validation and tries the new block instead.</p>\n<p>This approach could be problem if a slow block arrives immediately <em>after</em> a normal block (perhaps intentionally). So maybe the following heuristic can be used: keep track of average (weight adjusted) validation time and when validation takes more than five standard deviations longer, abort if a competing block is seen.</p>\n<p>The slow block would not be marked invalid. If another block is mined on top of it, we\u2019ll try validation once more. But if a third block builds on the fast chain, we abort again, etc.</p>\n<p>One problem with this solution is that it is really difficult to build, at least in Bitcoin Core. It would also leave older Bitcoin Core nodes vulnerable, as well as any alternative implementation that didn\u2019t implement parallel validation.</p>\n<p>But putting that aside, I\u2019m unsure if it actually solves the problem in the first place. In part because I don\u2019t fully understand the attacks that people are worried about.</p>\n<aside class=\"quote no-group\" data-username=\"AntoineP\" data-post=\"1\" data-topic=\"710\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/antoinep/48/483_2.png\" class=\"avatar\"><a href=\"https://delvingbitcoin.org/t/great-consensus-cleanup-revival/710/1\">Great Consensus Cleanup Revival</a></div>\n<blockquote>\n<p>It\u2019s well known maliciously crafted non-Segwit transactions can be pretty expensive to validate. Large block validation times could give attacking miners an unfair advantage, hinder block propagation (and its uniformity) across the network or even have detrimental consequences on software relying on block availability.</p>\n</blockquote>\n</aside>\n<p>Does the large miner advantage stay in place even if their blocks are at increased risk of reorg?</p>\n<p>If miners typically run higher end hardware for their node, does that mean slow blocks propagate just fine between miners, with the other nodes in the network being out of the loop?</p>\n<p>Does it create an incentive for miners who trust each other (or collude) to skip validation so they always build on the first-seen block, ignoring a fast-to-validate competitor block?</p>\n<p>Does this accidentally introduce an incentive to produce empty blocks? Or is the five-sigma threshold enough to prevent that? There used to be a slight advantage for smaller blocks due to the time it takes to transmit the bytes, but that\u2019s been thwarted by compact blocks (when they work). Slow validation seems to be an orders of magnitude bigger bottleneck than bandwidth (seconds or minutes vs. a few dozen milliseconds).</p>\n<p>I\u2019m unsure how to best analyse this.</p>",
  "post_number": 1,
  "post_type": 1,
  "updated_at": "2024-11-28T14:05:40.685Z",
  "reply_count": 1,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 7,
  "reads": 19,
  "readers_count": 18,
  "score": 58.8,
  "yours": false,
  "topic_id": 1288,
  "topic_slug": "can-parallel-validation-side-step-the-slow-block-issue",
  "topic_title": "Can parallel validation side-step the slow block issue?",
  "topic_html_title": "Can parallel validation side-step the slow block issue?",
  "category_id": 7,
  "display_username": "Sjors Provoost",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "The [Great Consensus Cleanup](https://delvingbitcoin.org/t/great-consensus-cleanup-revival/710) (revival) proposal attempts to address worst case block validation time through a consensus change. This is fundamentally a whack-a-mole game, as there could always be some unknown unknown method out there to produce blocks that take a long time to validate.\n\nEvery whack takes years and can be difficult to execute without disclosing the vulnerability.\n\nAnd with every future soft fork we need to deeply worry about block validation time. Although SegWit and Taproot have made it easier to reason about this sort of thing, and entirely new schemes like Simplicity take full account of it.\n\n**It would be really nice if we can make slow blocks a problem only for the miner who produced one.** That would make them a useless instrument for attacks, leaving only a concern for accidents (and protecting miners through standardness rules, but those can be changed more quickly).\n\nPerhaps parallel block validation can achieve this.\n\nThe idea of parallel block validation is that if your node sees two blocks competing for the same height, it tries to validate both in parallel and picks whichever it finishes first, which it then announces and builds on.\n\nIn the current situation Bitcoin Core will evaluate whichever block is sees first, and completely ignore the outside world until it's done validating. It only matters which block reaches the node first. \n\nInstead, parallel block validation should cause fast-to-validate blocks to propagate better when they're directly competing with a slow-to-validate block. This increases the stale risk for slow-to-validate blocks, which increases the cost of any attack that involves such blocks.\n\nPure parallel validation is very complicated to implement. Instead, a simpler approach could be that while the node is busy validating a block, it keeps listening to announcements for competing blocks. If such a block appears, it aborts the ongoing validation and tries the new block instead.\n\nThis approach could be problem if a slow block arrives immediately _after_ a normal block (perhaps intentionally). So maybe the following heuristic can be used: keep track of average (weight adjusted) validation time and when validation takes more than five standard deviations longer, abort if a competing block is seen.\n\nThe slow block would not be marked invalid. If another block is mined on top of it, we'll try validation once more. But if a third block builds on the fast chain, we abort again, etc.\n\nOne problem with this solution is that it is really difficult to build, at least in Bitcoin Core. It would also leave older Bitcoin Core nodes vulnerable, as well as any alternative implementation that didn't implement parallel validation.\n\nBut putting that aside, I'm unsure if it actually solves the problem in the first place. In part because I don't fully understand the attacks that people are worried about.\n\n[quote=\"AntoineP, post:1, topic:710\"]\nIt\u2019s well known maliciously crafted non-Segwit transactions can be pretty expensive to validate. Large block validation times could give attacking miners an unfair advantage, hinder block propagation (and its uniformity) across the network or even have detrimental consequences on software relying on block availability.\n[/quote]\n\nDoes the large miner advantage stay in place even if their blocks are at increased risk of reorg?\n\nIf miners typically run higher end hardware for their node, does that mean slow blocks propagate just fine between miners, with the other nodes in the network being out of the loop?\n\nDoes it create an incentive for miners who trust each other (or collude) to skip validation so they always build on the first-seen block, ignoring a fast-to-validate competitor block?\n\nDoes this accidentally introduce an incentive to produce empty blocks? Or is the five-sigma threshold enough to prevent that? There used to be a slight advantage for smaller blocks due to the time it takes to transmit the bytes, but that's been thwarted by compact blocks (when they work). Slow validation seems to be an orders of magnitude bigger bottleneck than bandwidth (seconds or minutes vs. a few dozen milliseconds).\n\nI'm unsure how to best analyse this.",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 71,
  "hidden": false,
  "trust_level": 3,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [
    {
      "id": "eyes",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false
}