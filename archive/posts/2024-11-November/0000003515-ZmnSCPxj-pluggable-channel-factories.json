{
  "id": 3515,
  "name": "ZmnSCPxj jxPCSnmZ",
  "username": "ZmnSCPxj",
  "avatar_template": "/letter_avatar_proxy/v4/letter/z/ee7513/{size}.png",
  "created_at": "2024-11-14T15:02:21.300Z",
  "cooked": "<blockquote>\n<blockquote>\n<p>A node:</p>\n<ul>\n<li>SHOULD  monitor the funding transactions in the blockchain, to identify channels that are being closed.</li>\n</ul>\n</blockquote>\n<p>\u2026</p>\n</blockquote>\n<p>Indeed, the equivalent of BOLT7 requirement to monitor the blockchain for unilateral exit of the factory would need to be implemented by the plugin, not the base software.</p>\n<p>A note however is that even if the factory layer is closed and its hosted channels directly published onchain, the channel can keep operating. So the base node software would still monitor the blockchain as normal for channels inside channel factories; even if the factory layer is closed, it may end up with channels directly onchain instead, and the channels can still continue to operate as channels.</p>\n<p>Of course, there may be factories where closing the factory also closes the hosted channels (possibly in some edge cases, such as a single SuperScalar instance timing out and being resolved using the timeout branch, where channels are never published; this \u201cshould not\u201d happen, but accidents can happen, such as an LSP getting forcibly shut down somehow) so there is a need for the factory plugin to inform its attached base node software to forget an in-factory channel.</p>\n<blockquote>\n<p>Similarly the announcement of such channels will be tricky\u2026</p>\n</blockquote>\n<p>Some years back (I forgot exactly when) there was some discussion about generalizing gossip, where a node only needs to point to some onchain fund that it can show proof it has shared n-of-n control over, and that would let the node gossip some number of channels (i.e. it shows 1 mBTC of onchain fund that it can prove it has one shard of n-of-n control over, we let it gossip up to N * 1mBTC of total channel capacity).</p>\n<p>This is because Lightning uses the Bitcoin blockchain UTXO set to limit the size of the gossiped public network; this is the REAL reason we even require channel announcements to point to an unspent TXO.</p>\n<p>So I think that gossip change needs to be put in place first before we can discuss gossip for channels inside factories.  So for now, I am deliberately saying \u201cout of scope\u201d for this bit; I want to focus on the protocol that gets channels hosted in factories.</p>\n<p>(off-topic, but for the public network at least, instead of hosting channels inside a factory, an alternative is my sidepools idea. Basically, instead of a N &gt; 2 offchain mechanism containing N=2 mechanisms, we have N=2 mechanisms directly on the blockchain and a parallel N &gt; 2 mechanism (\u201cto the side\u201d, hence \u201csidepool\u201d). The public routing nodes can then swap funds on the N &gt; 2 mechanism to \u201creload\u201d capacity on the N=2 mechanisms. This gets us some of the nice properties of both worlds: no need to change the gossip protocol (all the existing public 2-of-2 channels remain as plain onchain 2-of-2 channels and existing pathfinding algos that assume nodes and 2-party channels remain operational, and still using the Bitcoin UTXO set as a backstop against uncontrolled growth of the gossiped public network) while still allowing effective use of liquidity (with something better than Decker-Wattenhofer, we can swap on the N &gt; 2 mechanism \u201cJIT\u201d, effectively doing a \u201cJIT rebalance\u201d whenever a channel is depleted and we need to forward over it; this requires all parties to be online, but public forwarding nodes have a strong incentive to be as close to 100% uptime anyway; even with just Decker-Wattenhofer we can probably do a single large rebalance once a day and that will still get us 90% of the benefit of full N &gt; 2 mechanisms).)</p>",
  "post_number": 3,
  "post_type": 1,
  "updated_at": "2024-11-14T15:02:21.300Z",
  "reply_count": 0,
  "reply_to_post_number": 2,
  "quote_count": 0,
  "incoming_link_count": 0,
  "reads": 1,
  "readers_count": 0,
  "score": 0,
  "yours": false,
  "topic_id": 1252,
  "topic_slug": "pluggable-channel-factories",
  "topic_title": "Pluggable Channel Factories",
  "topic_html_title": "Pluggable Channel Factories",
  "category_id": 7,
  "display_username": "ZmnSCPxj jxPCSnmZ",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "reply_to_user": {
    "username": "renepickhardt",
    "name": "Rene Pickhardt",
    "avatar_template": "/user_avatar/delvingbitcoin.org/renepickhardt/{size}/7_2.png"
  },
  "bookmarked": false,
  "raw": ">>A node:\n>>\n>>* SHOULD  monitor the funding transactions in the blockchain, to identify channels that are being closed.\n>\n> ...\n\nIndeed, the equivalent of BOLT7 requirement to monitor the blockchain for unilateral exit of the factory would need to be implemented by the plugin, not the base software.\n\nA note however is that even if the factory layer is closed and its hosted channels directly published onchain, the channel can keep operating. So the base node software would still monitor the blockchain as normal for channels inside channel factories; even if the factory layer is closed, it may end up with channels directly onchain instead, and the channels can still continue to operate as channels.\n\nOf course, there may be factories where closing the factory also closes the hosted channels (possibly in some edge cases, such as a single SuperScalar instance timing out and being resolved using the timeout branch, where channels are never published; this \"should not\" happen, but accidents can happen, such as an LSP getting forcibly shut down somehow) so there is a need for the factory plugin to inform its attached base node software to forget an in-factory channel.\n\n> Similarly the announcement of such channels will be tricky...\n\nSome years back (I forgot exactly when) there was some discussion about generalizing gossip, where a node only needs to point to some onchain fund that it can show proof it has shared n-of-n control over, and that would let the node gossip some number of channels (i.e. it shows 1 mBTC of onchain fund that it can prove it has one shard of n-of-n control over, we let it gossip up to N * 1mBTC of total channel capacity).\n\nThis is because Lightning uses the Bitcoin blockchain UTXO set to limit the size of the gossiped public network; this is the REAL reason we even require channel announcements to point to an unspent TXO.\n\nSo I think that gossip change needs to be put in place first before we can discuss gossip for channels inside factories.  So for now, I am deliberately saying \"out of scope\" for this bit; I want to focus on the protocol that gets channels hosted in factories.\n\n(off-topic, but for the public network at least, instead of hosting channels inside a factory, an alternative is my sidepools idea. Basically, instead of a N > 2 offchain mechanism containing N=2 mechanisms, we have N=2 mechanisms directly on the blockchain and a parallel N > 2 mechanism (\"to the side\", hence \"sidepool\"). The public routing nodes can then swap funds on the N > 2 mechanism to \"reload\" capacity on the N=2 mechanisms. This gets us some of the nice properties of both worlds: no need to change the gossip protocol (all the existing public 2-of-2 channels remain as plain onchain 2-of-2 channels and existing pathfinding algos that assume nodes and 2-party channels remain operational, and still using the Bitcoin UTXO set as a backstop against uncontrolled growth of the gossiped public network) while still allowing effective use of liquidity (with something better than Decker-Wattenhofer, we can swap on the N > 2 mechanism \"JIT\", effectively doing a \"JIT rebalance\" whenever a channel is depleted and we need to forward over it; this requires all parties to be online, but public forwarding nodes have a strong incentive to be as close to 100% uptime anyway; even with just Decker-Wattenhofer we can probably do a single large rebalance once a day and that will still get us 90% of the benefit of full N > 2 mechanisms).)",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 104,
  "hidden": false,
  "trust_level": 2,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false
}