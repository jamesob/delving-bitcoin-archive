{
  "id": 5222,
  "name": "George Tsagkarelis",
  "username": "GeorgeTsagk",
  "avatar_template": "/user_avatar/delvingbitcoin.org/georgetsagk/{size}/162_2.png",
  "created_at": "2025-06-05T11:08:21.071Z",
  "cooked": "<p>Would like to add some comments to a few of the points made in previous messages:</p>\n<blockquote>\n<p><a class=\"mention\" href=\"/u/joostjager\">@joostjager</a>: In my view, it is more sustainable to design the network to be resilient and private even when nodes compete on latency, rather than relying on weak measures that only obscure the problem and leave critical questions unanswered.</p>\n</blockquote>\n<p>It\u2019s also important to note that there are more crucial things to address that directly improve privacy over lightning, like forwarding and sender/receiver delays to mitigate the on/off path adversaries as described previously in this thread. Without addressing these, applying a privacy-dressing on the sender\u2019s feedback is only a partial illusion of privacy.</p>\n<p>On top of that the sender may be considered the only actor that deserves to know as much as possible w.r.t what\u2019s going on with their payment, they\u2019re the ones piloting it at the end of the day.</p>\n<blockquote>\n<p><a class=\"mention\" href=\"/u/roasbeef\">@roasbeef</a>: One way to partially address this concern would be to: prefix the latency encoding with the type and parameter. So the final value on the wire would be <code>encoding_type || encode_param || encoding_value</code>.</p>\n</blockquote>\n<p>I don\u2019t really see the value of having the prefix. If you want to round up or down to buckets of 100ms then you\u2019re free to do so in the simple <code>uint64</code> encoding. Why would the sender want to know whether you\u2019re doing it or not?</p>\n<blockquote>\n<p><a class=\"mention\" href=\"/u/t-bast\">@t-bast</a>: Sacrificing those to get performance gains for which we don\u2019t have any concrete use-case today doesn\u2019t make any sense to me.</p>\n</blockquote>\n<p>A 2-part reply:</p>\n<p>a) We\u2019re not really <strong>sacrificing</strong> privacy, it\u2019s more like being honest about the current situation. Similarly, we are not gaining any privacy by obfuscating the latency that is reported to the sender. Adversaries face no extra difficulties in analyzing traffic.</p>\n<p>b) Focusing on the performance of LN is a fundamental use-case. Every day someone pays for their food or ticket with LN and the payment resolves fast is a small win for the whole network. I\u2019m not saying we need 100ms instead of 1s, but we definitely need to treat performance as a fundamental requirement of the network.</p>\n<blockquote>\n<p><a class=\"mention\" href=\"/u/t-bast\">@t-bast</a>: As we\u2019ve highlighted several times during spec meetings, privacy loves company: you can only achieve good enough privacy if that is the default behavior of the network.</p>\n</blockquote>\n<p>I still don\u2019t understand whether we\u2019re assuming that most people are willing to strip away parts of the software for the sake of speed. If that\u2019s the assumption, then the real mitigations for privacy (forwarding &amp; sender/receiver delays) are really questionable, as anyone can just set the delays to 0s for a faster experience.</p>\n<p>As you mentioned above \u201cyou can only achieve good enough privacy if that is the <strong>default</strong> behavior of the network\u201d, I believe there\u2019s a reason we don\u2019t want to say \u201cthe enforced behavior of the network\u201d, as in we still want to allow people to tweak their node <strong>if they really want to</strong>.</p>\n<p>If all implementations have forwarding batching, sender &amp; receiver delays and many other enhancements for privacy turned on (maybe some not even configurable), then would the majority of the network choose to nullify them? All we can really do is guide the user into making the right choices by controlling what\u2019s configurable, what the default values are, and by making sure to highlight the privacy impact of certain configuration choices in documentation.</p>\n<h3><a name=\"p-5222-final-personal-note-1\" class=\"anchor\" href=\"#p-5222-final-personal-note-1\"></a>Final personal note</h3>\n<p>Attributable failures are very good at defining the hop that gets the blame in a route, not retrieving the latencies. The reported latencies are by nature \u201chandwavy\u201d, it\u2019s what the node <strong>claims</strong> to have held the HTLC for. Any (sane) pathfinding algorithm would normalize that value first before incorporating it.</p>\n<p>One of the arguments against expressive latency is that we\u2019re guiding nodes into picking the super fast chosen few routing nodes for payments and channel opens, weakening the topology of the lightning network. That\u2019s already happening today by having websites score nodes for you and then guiding you into choosing the best ones, which is already a worse version of the problem being played out right now.</p>\n<p>Instead I\u2019d like to see a future where we don\u2019t have to rely on external websites to source metrics and data for the network from and what your own node provides locally would be more than sufficient. The very existence of these websites is an indicator that people desire performance, and it\u2019s better to satisfy performance locally and on a p2p level (alongside privacy) rather than by submitting or fetching stats.</p>\n<h4><a name=\"p-5222-proposed-way-forward-2\" class=\"anchor\" href=\"#p-5222-proposed-way-forward-2\"></a>Proposed way forward</h4>\n<p>Keep the latency encoding as a <code>uint64</code>, where the value is the milliseconds the HTLC was held for. Each implementation is free to do bucketing or thresholds on the values they report when forwarding, without the need to report it. Similarly, the sender is free to apply thresholds or bucketing on the reported values, without signalling if they\u2019re doing it or not. Whether the former are going to be configurable is also up to the implementations (personal opinion is to not have it configurable, i.e someone has to build their own binary to change it).</p>\n<p>If we ever have a more solid foundation on changing the encoding to be <strong>something specific</strong> then we can always upgrade to a more strict encoding (use a new TLV field and eventually deprecate the old one).</p>",
  "post_number": 26,
  "post_type": 1,
  "posts_count": 40,
  "updated_at": "2025-06-05T12:17:42.240Z",
  "reply_count": 2,
  "reply_to_post_number": null,
  "quote_count": 0,
  "incoming_link_count": 1,
  "reads": 21,
  "readers_count": 20,
  "score": 19.2,
  "yours": false,
  "topic_id": 1723,
  "topic_slug": "latency-and-privacy-in-lightning",
  "topic_title": "Latency and Privacy in Lightning",
  "topic_html_title": "Latency and Privacy in Lightning",
  "category_id": 7,
  "display_username": "George Tsagkarelis",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 3,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "Would like to add some comments to a few of the points made in previous messages:\n\n> @joostjager: In my view, it is more sustainable to design the network to be resilient and private even when nodes compete on latency, rather than relying on weak measures that only obscure the problem and leave critical questions unanswered.\n\nIt's also important to note that there are more crucial things to address that directly improve privacy over lightning, like forwarding and sender/receiver delays to mitigate the on/off path adversaries as described previously in this thread. Without addressing these, applying a privacy-dressing on the sender's feedback is only a partial illusion of privacy.\n\nOn top of that the sender may be considered the only actor that deserves to know as much as possible w.r.t what's going on with their payment, they're the ones piloting it at the end of the day.\n\n> @roasbeef: One way to partially address this concern would be to: prefix the latency encoding with the type and parameter. So the final value on the wire would be `encoding_type || encode_param || encoding_value`. \n\nI don't really see the value of having the prefix. If you want to round up or down to buckets of 100ms then you're free to do so in the simple `uint64` encoding. Why would the sender want to know whether you're doing it or not?\n\n> @t-bast: Sacrificing those to get performance gains for which we don\u2019t have any concrete use-case today doesn\u2019t make any sense to me.\n\nA 2-part reply:\n\na) We're not really **sacrificing** privacy, it's more like being honest about the current situation. Similarly, we are not gaining any privacy by obfuscating the latency that is reported to the sender. Adversaries face no extra difficulties in analyzing traffic.\n\nb) Focusing on the performance of LN is a fundamental use-case. Every day someone pays for their food or ticket with LN and the payment resolves fast is a small win for the whole network. I'm not saying we need 100ms instead of 1s, but we definitely need to treat performance as a fundamental requirement of the network.\n\n> @t-bast: As we\u2019ve highlighted several times during spec meetings, privacy loves company: you can only achieve good enough privacy if that is the default behavior of the network.\n\nI still don't understand whether we're assuming that most people are willing to strip away parts of the software for the sake of speed. If that's the assumption, then the real mitigations for privacy (forwarding & sender/receiver delays) are really questionable, as anyone can just set the delays to 0s for a faster experience.\n\nAs you mentioned above \"you can only achieve good enough privacy if that is the **default** behavior of the network\", I believe there's a reason we don't want to say \"the enforced behavior of the network\", as in we still want to allow people to tweak their node **if they really want to**.\n\nIf all implementations have forwarding batching, sender & receiver delays and many other enhancements for privacy turned on (maybe some not even configurable), then would the majority of the network choose to nullify them? All we can really do is guide the user into making the right choices by controlling what's configurable, what the default values are, and by making sure to highlight the privacy impact of certain configuration choices in documentation.\n\n### Final personal note\n\nAttributable failures are very good at defining the hop that gets the blame in a route, not retrieving the latencies. The reported latencies are by nature \"handwavy\", it's what the node **claims** to have held the HTLC for. Any (sane) pathfinding algorithm would normalize that value first before incorporating it.\n\nOne of the arguments against expressive latency is that we're guiding nodes into picking the super fast chosen few routing nodes for payments and channel opens, weakening the topology of the lightning network. That's already happening today by having websites score nodes for you and then guiding you into choosing the best ones, which is already a worse version of the problem being played out right now.\n\nInstead I'd like to see a future where we don't have to rely on external websites to source metrics and data for the network from and what your own node provides locally would be more than sufficient. The very existence of these websites is an indicator that people desire performance, and it's better to satisfy performance locally and on a p2p level (alongside privacy) rather than by submitting or fetching stats.\n\n#### Proposed way forward\n\nKeep the latency encoding as a `uint64`, where the value is the milliseconds the HTLC was held for. Each implementation is free to do bucketing or thresholds on the values they report when forwarding, without the need to report it. Similarly, the sender is free to apply thresholds or bucketing on the reported values, without signalling if they're doing it or not. Whether the former are going to be configurable is also up to the implementations (personal opinion is to not have it configurable, i.e someone has to build their own binary to change it).\n\n\nIf we ever have a more solid foundation on changing the encoding to be **something specific** then we can always upgrade to a more strict encoding (use a new TLV field and eventually deprecate the old one).",
  "actions_summary": [],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 144,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Would like to add some comments to a few of the points made in previous messages: \n\n<a class=\"mention\" href=\"/u/joostjager\">@joostjager</a>: In my view, it is more sustainable to design the network to be resilient and private even when nodes compete on latency, rather than relying on weak measures that only obscure the problem and leave criti&hellip;",
  "truncated": true,
  "post_url": "/t/latency-and-privacy-in-lightning/1723/26",
  "reactions": [],
  "current_user_reaction": null,
  "reaction_users_count": 0,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}