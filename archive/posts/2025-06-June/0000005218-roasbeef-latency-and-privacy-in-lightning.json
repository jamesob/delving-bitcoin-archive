{
  "id": 5218,
  "name": "",
  "username": "roasbeef",
  "avatar_template": "/user_avatar/delvingbitcoin.org/roasbeef/{size}/160_2.png",
  "created_at": "2025-06-05T01:21:02.876Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"t-bast\" data-post=\"22\" data-topic=\"1723\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/t-bast/48/98_2.png\" class=\"avatar\"> t-bast:</div>\n<blockquote>\n<p>Can you please summarize the options proposed? I don\u2019t think there\u2019s any written form of it</p>\n</blockquote>\n</aside>\n<p>Here\u2019s my attempt at summarizing the options.</p>\n<p>Skip the first two sections here for the options.</p>\n<h3><a name=\"p-5218-background-1\" class=\"anchor\" href=\"#p-5218-background-1\"></a>Background</h3>\n<p>Attributable errors provides a way for a sender to receive a tamper-evident error. This means that the sender can pinpoint <em>which</em> node in the route inadvertently or purposefully garbled the error.  Today any node can flip a bit in the onion errors, which renders the entire error undecryptable, in a manner where no blame can be ascribed.</p>\n<p>The path finding of most implementations today has some component that will attempt to penalize a given node, or set of nodes for an unsuccessful route. The opposite is also useful as the path finder is able to <em>reward</em> nodes for enabling the forwarding attempt to succeed up until a certain point.</p>\n<p>Without a way to attribute onion error garbling to a particular node, path finders either need to penalize the entire route, or do nothing. Both aren\u2019t great options.</p>\n<p>As a way to incentive the uptake of attributable errors by implementations, Joost proposed that the \u201chold time\u201d be encoded in the errors for failed payments. In theory, this would allow path finders to pinpoint which nodes are persistently slow (bad network, faulty hardware, slow disk, etc) and penalize them in their path finding implementation. This rests on the assumption that users want fast payments, as poor payments are very bad UX (depending on the app, can appear to be stuck if no visual feedback is given).</p>\n<p>FWIW, I don\u2019t think any path finding implementation has <em>yet</em> be updated to take this hold time information into account. Even today, path finders can bias towards geographically colocated nodes to reduce e2e latency (eg: no need to bounce to Tokyo, then LA, if the payment is going to Mexico).</p>\n<h3><a name=\"p-5218-problem-statement-2\" class=\"anchor\" href=\"#p-5218-problem-statement-2\"></a>Problem Statement</h3>\n<p>If we want to encode these hold times in the onion error, then a question that naturally arises is: <strong>what encoding granularity should be used</strong>? By this I mean, do we encode the latency numbers out right, or some less precise value, that may still be useful.</p>\n<p>A related question is if we encode this hold time: <strong>to what degree does this decay privacy</strong>? This question is what motivated this post to begin with.</p>\n<p>Before proceeding to the encoding options, I think it\u2019s important to emphasize that: <strong>the sender always knows how much time the attempt took</strong>. They can also further bisect the reported values, either by iteratively probing nodes in the path, or connecting out to them to measure ping latency. This brings forth a related third question: <strong>what do we gain by encoding less precise values</strong>?</p>\n<p>One other aspect as mentioned above is that a forwarding node can themselves become a sender. Even ignoring the latency encoding, log the resolution times of HTLCs they forward. For each of those HTLCs (similar amount, CLTV budget, etc), they can launch probes to attempt to correlate the destination. As mentioned above, variable receiver settlement delays mitigates this somewhat.</p>\n<h3><a name=\"p-5218-latency-encoding-options-3\" class=\"anchor\" href=\"#p-5218-latency-encoding-options-3\"></a>Latency Encoding Options</h3>\n<p>I missed some of the initial discussion in the last spec meeting, but IIUC we have the following encoding options:</p>\n<ul>\n<li><strong>Precise Values</strong>:\n<ul>\n<li><strong>Rationale</strong>: The sender already knows how long the route takes, and can measure how long it takes each node to forward as mentioned above.</li>\n<li><strong>Encoding</strong>: Encode the actual value in milliseconds.</li>\n</ul>\n</li>\n<li><strong>Bucketed Values</strong>:\n<ul>\n<li><strong>Rationale</strong>: We don\u2019t want to make it trivial to keep track of what the true per-hop latency is, so we should reduce the precision.</li>\n<li><strong>Encoding</strong>: Given a bucket size (another parameter), report the bucket that a value falls in. So if we have buckets of 100 ms, and the actual latency is 120 ms, then 100 ms is reported.</li>\n</ul>\n</li>\n<li><strong>Threshold Values</strong>:\n<ul>\n<li><strong>Rationale</strong>: Payments already take 1.5 RTTs per hop to extend, then half a round trip per hop (assuming pipelining) to settle. Therefore we can just extrapolate based no common geographical latencies, and pick a min/threshold value. IMO, this only viable if were space constrained, and want to encode the latency value in a single byte.</li>\n<li><strong>Encoding</strong>: The value encoded isn\u2019t the actual latency, but the latency subtracted (floor of zero) or divided by some threshold. In the examples below, we assume this threshold is 200 ms, and the actual payment latency was 225 ms.\n<ul>\n<li><strong>Subtracting</strong>: A value of <em>25</em> is encoded. If the value is below the threshold, then zero is reported.</li>\n<li><strong>Dividing</strong>: A value of <em>1</em> is encoded. Again if the value is below the threshold, zero is reported.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>As we know LN is geographically distributed, so the actual latency depends on exactly where all the nodes are located. <a href=\"https://wondernetwork.com/pings\" rel=\"noopener nofollow ugc\">Sites like this can be used</a> to get an idea of what types of latencies one would see in the real world.</p>\n<p>Both the threshold and bucket options need some parameter selected for an initial deployment. How do should we come up with such a parameter? During the discussion it was suggested that we just use a relatively high value like 300 ms, as it takes 1.5 RTT even in the direct hop case. Ofc payments can definitely be faster than 300 ms (small amount of hops, well connected merchant, etc), but anything around ~200-500 ms <em>feels</em> instant.</p>\n<h3><a name=\"p-5218-flexibility-concerns-4\" class=\"anchor\" href=\"#p-5218-flexibility-concerns-4\"></a>Flexibility Concerns</h3>\n<p>One concern brought up during the discussion was flexibility: if we aren\u2019t encoding the actual value, then we need to pick some parameter for either the bucket, or the threshold value. The param is yet another value to bikeshed over.</p>\n<p>Changing this value in the future, may mean another long update cycle, as the senders need to upgrade to know how to parse/interpret the new value and it isn\u2019t <em>really</em> useful until all the forwarding nodes also start to set these new values.</p>\n<h3><a name=\"p-5218-flexibility-middle-ground-5\" class=\"anchor\" href=\"#p-5218-flexibility-middle-ground-5\"></a>Flexibility Middle Ground</h3>\n<p>One way to partially address this concern would be to: prefix the latency encoding with the type and parameter. So the final value on the wire would be <code>encoding_type || encode_param || encoding_value</code>. This would:</p>\n<ol>\n<li>Let nodes choose if they wanted to give granular information or not (hey! I\u2019m fast, pick me!).\n<ul>\n<li>Does one node choosing the precise excessively leak information? I\u2019m not sure, as the sender knows what the real latency is.</li>\n</ul>\n</li>\n<li>Avoid hard coding the bucket/threshold param. As a result, we/nodes/implementations have a path to change it in the future.</li>\n</ol>\n<p>With this an open question is: if all, or just one of the encoding modes is specified (with the expectation that senders can interpret them all).</p>\n<hr>\n<p>Personally, I favor: the self identifying encoding, with either just the actual value, or buckets (100ms?).</p>",
  "post_number": 24,
  "post_type": 1,
  "posts_count": 40,
  "updated_at": "2025-06-05T01:37:44.257Z",
  "reply_count": 2,
  "reply_to_post_number": null,
  "quote_count": 1,
  "incoming_link_count": 10,
  "reads": 26,
  "readers_count": 25,
  "score": 80.2,
  "yours": false,
  "topic_id": 1723,
  "topic_slug": "latency-and-privacy-in-lightning",
  "topic_title": "Latency and Privacy in Lightning",
  "topic_html_title": "Latency and Privacy in Lightning",
  "category_id": 7,
  "display_username": "",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 2,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"t-bast, post:22, topic:1723\"]\nCan you please summarize the options proposed? I don\u2019t think there\u2019s any written form of it\n[/quote]\n\nHere's my attempt at summarizing the options. \n\nSkip the first two sections here for the options. \n\n### Background\n\nAttributable errors provides a way for a sender to receive a tamper-evident error. This means that the sender can pinpoint _which_ node in the route inadvertently or purposefully garbled the error.  Today any node can flip a bit in the onion errors, which renders the entire error undecryptable, in a manner where no blame can be ascribed. \n\nThe path finding of most implementations today has some component that will attempt to penalize a given node, or set of nodes for an unsuccessful route. The opposite is also useful as the path finder is able to _reward_ nodes for enabling the forwarding attempt to succeed up until a certain point. \n\nWithout a way to attribute onion error garbling to a particular node, path finders either need to penalize the entire route, or do nothing. Both aren't great options. \n\nAs a way to incentive the uptake of attributable errors by implementations, Joost proposed that the \"hold time\" be encoded in the errors for failed payments. In theory, this would allow path finders to pinpoint which nodes are persistently slow (bad network, faulty hardware, slow disk, etc) and penalize them in their path finding implementation. This rests on the assumption that users want fast payments, as poor payments are very bad UX (depending on the app, can appear to be stuck if no visual feedback is given). \n\nFWIW, I don't think any path finding implementation has _yet_ be updated to take this hold time information into account. Even today, path finders can bias towards geographically colocated nodes to reduce e2e latency (eg: no need to bounce to Tokyo, then LA, if the payment is going to Mexico). \n\n### Problem Statement\n\nIf we want to encode these hold times in the onion error, then a question that naturally arises is: **what encoding granularity should be used**? By this I mean, do we encode the latency numbers out right, or some less precise value, that may still be useful. \n\nA related question is if we encode this hold time: **to what degree does this decay privacy**? This question is what motivated this post to begin with. \n\nBefore proceeding to the encoding options, I think it's important to emphasize that: **the sender always knows how much time the attempt took**. They can also further bisect the reported values, either by iteratively probing nodes in the path, or connecting out to them to measure ping latency. This brings forth a related third question: **what do we gain by encoding less precise values**? \n\nOne other aspect as mentioned above is that a forwarding node can themselves become a sender. Even ignoring the latency encoding, log the resolution times of HTLCs they forward. For each of those HTLCs (similar amount, CLTV budget, etc), they can launch probes to attempt to correlate the destination. As mentioned above, variable receiver settlement delays mitigates this somewhat. \n\n### Latency Encoding Options \n\nI missed some of the initial discussion in the last spec meeting, but IIUC we have the following encoding options:\n  * **Precise Values**:\n     * **Rationale**: The sender already knows how long the route takes, and can measure how long it takes each node to forward as mentioned above. \n     * **Encoding**: Encode the actual value in milliseconds. \n  * **Bucketed Values**:\n     * **Rationale**: We don't want to make it trivial to keep track of what the true per-hop latency is, so we should reduce the precision. \n     * **Encoding**: Given a bucket size (another parameter), report the bucket that a value falls in. So if we have buckets of 100 ms, and the actual latency is 120 ms, then 100 ms is reported. \n   * **Threshold Values**:\n      * **Rationale**: Payments already take 1.5 RTTs per hop to extend, then half a round trip per hop (assuming pipelining) to settle. Therefore we can just extrapolate based no common geographical latencies, and pick a min/threshold value. IMO, this only viable if were space constrained, and want to encode the latency value in a single byte. \n      * **Encoding**: The value encoded isn't the actual latency, but the latency subtracted (floor of zero) or divided by some threshold. In the examples below, we assume this threshold is 200 ms, and the actual payment latency was 225 ms. \n         * **Subtracting**: A value of _25_ is encoded. If the value is below the threshold, then zero is reported. \n         * **Dividing**: A value of _1_ is encoded. Again if the value is below the threshold, zero is reported.\n\nAs we know LN is geographically distributed, so the actual latency depends on exactly where all the nodes are located. [Sites like this can be used](https://wondernetwork.com/pings) to get an idea of what types of latencies one would see in the real world. \n\nBoth the threshold and bucket options need some parameter selected for an initial deployment. How do should we come up with such a parameter? During the discussion it was suggested that we just use a relatively high value like 300 ms, as it takes 1.5 RTT even in the direct hop case. Ofc payments can definitely be faster than 300 ms (small amount of hops, well connected merchant, etc), but anything around ~200-500 ms _feels_ instant. \n\n### Flexibility Concerns\n\nOne concern brought up during the discussion was flexibility: if we aren't encoding the actual value, then we need to pick some parameter for either the bucket, or the threshold value. The param is yet another value to bikeshed over. \n\nChanging this value in the future, may mean another long update cycle, as the senders need to upgrade to know how to parse/interpret the new value and it isn't _really_ useful until all the forwarding nodes also start to set these new values. \n\n### Flexibility Middle Ground \n\nOne way to partially address this concern would be to: prefix the latency encoding with the type and parameter. So the final value on the wire would be `encoding_type || encode_param || encoding_value`. This would:\n  1. Let nodes choose if they wanted to give granular information or not (hey! I'm fast, pick me!). \n      * Does one node choosing the precise excessively leak information? I'm not sure, as the sender knows what the real latency is. \n  2. Avoid hard coding the bucket/threshold param. As a result, we/nodes/implementations have a path to change it in the future. \n\nWith this an open question is: if all, or just one of the encoding modes is specified (with the expectation that senders can interpret them all).\n\n----- \n\nPersonally, I favor: the self identifying encoding, with either just the actual value, or buckets (100ms?).",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 143,
  "hidden": false,
  "trust_level": 2,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Here\u2019s my attempt at summarizing the options. \nSkip the first two sections here for the options. \n<a name=\"p-5218-background-1\" class=\"anchor\" href=\"#p-5218-background-1\"></a>Background\nAttributable errors provides a way for a sender to receive a tamper-evident error. This means that the sender can pinpoint which node in the route inadvertently or purposefully garbled the e&hellip;",
  "truncated": true,
  "post_url": "/t/latency-and-privacy-in-lightning/1723/24",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}