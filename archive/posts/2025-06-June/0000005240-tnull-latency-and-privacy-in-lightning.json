{
  "id": 5240,
  "name": "",
  "username": "tnull",
  "avatar_template": "/user_avatar/delvingbitcoin.org/tnull/{size}/449_2.png",
  "created_at": "2025-06-06T09:35:30.861Z",
  "cooked": "<aside class=\"quote no-group\" data-username=\"t-bast\" data-post=\"37\" data-topic=\"1723\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/t-bast/48/98_2.png\" class=\"avatar\"> t-bast:</div>\n<blockquote>\n<p>Based on my current understanding, my preferred choice would be:</p>\n<ul>\n<li>receiver-side random delays</li>\n<li>sender-side random delay on retries</li>\n<li>small randomized batching interval at intermediate nodes (mostly for performance, but also to add a small amount of noise of relay latency)</li>\n<li>random message padding / cover traffic (which I think doesn\u2019t have to be CBR to be effective)</li>\n</ul>\n</blockquote>\n</aside>\n<p>Yes, totally agree in generally here.</p>\n<p>Although I don\u2019t think we need to add sender-side retry delays if we wouldn\u2019t retry over exactly the same route. And, AFAIK, only LND currently does this under certain circumstances where they give a node a \u2018second chance\u2019 if they report back one of a certain set of failure codes.</p>\n<aside class=\"quote no-group\" data-username=\"t-bast\" data-post=\"37\" data-topic=\"1723\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"24\" height=\"24\" src=\"https://delvingbitcoin.org/user_avatar/delvingbitcoin.org/t-bast/48/98_2.png\" class=\"avatar\"> t-bast:</div>\n<blockquote>\n<p>As you say, this doesn\u2019t rule out the current 1ms encoding for attributable failures. But I\u2019d be curious to have <a class=\"mention\" href=\"/u/mattcorallo\">@MattCorallo</a> and <a class=\"mention\" href=\"/u/tnull\">@tnull</a>\u2019s thoughts here: they mentioned during the spec meeting that intermediate forwarding delays are important for privacy even when we have random message padding and cover traffic, and I don\u2019t understand why. So I may be missing something important.</p>\n</blockquote>\n</aside>\n<p>So, while the attack described in the Revelio paper is mostly based on a heuristic that exploits the distinct packet sizes, they still group the streams of IP packages / 3-tuple (sender IP, receiver IP, message length, basically) that an adversary might observe at different points by their timing. Basically, the adversary would be able to observe the HTLC dance at one point in time / in the network, and then an HTLC dance at a later point / a different point in the network. To correlate these two observations and reconstruct that it was in fact the same payment they use timing information. The same approach could be utilized by an on-path adversary with multiple vantage points in the network post-PTLCs, but of course currently they can simply match the payment hash to ensure that two observations are indeed the same payment.</p>\n<p>So yes, the more entropy/noise we add/maintain to/in the forwarding process the harder we make the adversary\u2019s job of coming up with reliable models, which is why we likely wouldn\u2019t want to drop the forwarding delay entirely (although note it\u2019s mostly about maximizing <em>uncertainty</em> not the added net delay necessarily).</p>",
  "post_number": 39,
  "post_type": 1,
  "posts_count": 40,
  "updated_at": "2025-06-06T09:35:30.861Z",
  "reply_count": 1,
  "reply_to_post_number": 37,
  "quote_count": 1,
  "incoming_link_count": 2,
  "reads": 22,
  "readers_count": 21,
  "score": 34.4,
  "yours": false,
  "topic_id": 1723,
  "topic_slug": "latency-and-privacy-in-lightning",
  "topic_title": "Latency and Privacy in Lightning",
  "topic_html_title": "Latency and Privacy in Lightning",
  "category_id": 7,
  "display_username": "",
  "primary_group_name": null,
  "flair_name": null,
  "flair_url": null,
  "flair_bg_color": null,
  "flair_color": null,
  "flair_group_id": null,
  "badges_granted": [],
  "version": 1,
  "can_edit": false,
  "can_delete": false,
  "can_recover": false,
  "can_see_hidden_post": false,
  "can_wiki": false,
  "user_title": null,
  "bookmarked": false,
  "raw": "[quote=\"t-bast, post:37, topic:1723\"]\nBased on my current understanding, my preferred choice would be:\n\n* receiver-side random delays\n* sender-side random delay on retries\n* small randomized batching interval at intermediate nodes (mostly for performance, but also to add a small amount of noise of relay latency)\n* random message padding / cover traffic (which I think doesn\u2019t have to be CBR to be effective)\n[/quote]\n\nYes, totally agree in generally here. \n\nAlthough I don't think we need to add sender-side retry delays if we wouldn't retry over exactly the same route. And, AFAIK, only LND currently does this under certain circumstances where they give a node a 'second chance' if they report back one of a certain set of failure codes.\n\n[quote=\"t-bast, post:37, topic:1723\"]\nAs you say, this doesn\u2019t rule out the current 1ms encoding for attributable failures. But I\u2019d be curious to have @MattCorallo and @tnull\u2019s thoughts here: they mentioned during the spec meeting that intermediate forwarding delays are important for privacy even when we have random message padding and cover traffic, and I don\u2019t understand why. So I may be missing something important.\n[/quote]\n\nSo, while the attack described in the Revelio paper is mostly based on a heuristic that exploits the distinct packet sizes, they still group the streams of IP packages / 3-tuple (sender IP, receiver IP, message length, basically) that an adversary might observe at different points by their timing. Basically, the adversary would be able to observe the HTLC dance at one point in time / in the network, and then an HTLC dance at a later point / a different point in the network. To correlate these two observations and reconstruct that it was in fact the same payment they use timing information. The same approach could be utilized by an on-path adversary with multiple vantage points in the network post-PTLCs, but of course currently they can simply match the payment hash to ensure that two observations are indeed the same payment. \n\nSo yes, the more entropy/noise we add/maintain to/in the forwarding process the harder we make the adversary's job of coming up with reliable models, which is why we likely wouldn't want to drop the forwarding delay entirely (although note it's mostly about maximizing *uncertainty* not the added net delay necessarily).",
  "actions_summary": [
    {
      "id": 2,
      "count": 1
    }
  ],
  "moderator": false,
  "admin": false,
  "staff": false,
  "user_id": 145,
  "hidden": false,
  "trust_level": 1,
  "deleted_at": null,
  "user_deleted": false,
  "edit_reason": null,
  "can_view_edit_history": true,
  "wiki": false,
  "excerpt": "Yes, totally agree in generally here. \nAlthough I don\u2019t think we need to add sender-side retry delays if we wouldn\u2019t retry over exactly the same route. And, AFAIK, only LND currently does this under certain circumstances where they give a node a \u2018second chance\u2019 if they report back one of a certain &hellip;",
  "truncated": true,
  "post_url": "/t/latency-and-privacy-in-lightning/1723/39",
  "reactions": [
    {
      "id": "+1",
      "type": "emoji",
      "count": 1
    }
  ],
  "current_user_reaction": null,
  "reaction_users_count": 1,
  "current_user_used_main_reaction": false,
  "can_accept_answer": false,
  "can_unaccept_answer": false,
  "accepted_answer": false,
  "topic_accepted_answer": null
}