# Delving Simplicity Part â…¢: Building Data Types

roconnor-blockstream | 2025-09-02 23:52:41 UTC | #1

In [Part â…¡](https://delvingbitcoin.org/t/delving-simplicity-part-combinator-completeness-of-simplicity/1935) of this series, we introduced Simplicityâ€™s type system and its core set of computational combinators. However, with only three kinds of type formers and nine core combinators, the language may seem too meager for practical computations. Can we really build any computation using only the three fundamental forms of composition we described in Part â…  of this series? In the same way that computers are built out of logic gates, we start with the humble bit and build up abstractions from it. Letâ€™s delve in.

# Boolean Logic

In Part â…¡, we introduced the Boolean type, which is `ğŸ™ + ğŸ™`. We use the notation `ğŸš` for this type. It has two values: `Ïƒá´¸âŸ¨âŸ©` and `Ïƒá´¿âŸ¨âŸ©`. By convention, we use the notation `0` or `false` for `Ïƒá´¸âŸ¨âŸ©`, and the notation `1` or `true` for `Ïƒá´¿âŸ¨âŸ©`. Using our computational combinators, we can build Boolean logic operators.

## And operation

The logical `and : ğŸš Ã— ğŸš âŠ¢ ğŸš` operation takes two bits as input and returns one bit as output. Since Simplicity expressions have only a single input type, we use the product of the two input arguments as the input type. There are several ways of implementing this function. One way is to branch on the first bit: if the first bit is `false`, we return `false`; otherwise, we return the second bit.

```none
and â‰” case (injl unit) (drop iden) : ğŸš Ã— ğŸš âŠ¢ ğŸš
```

We can check this definition on the input `âŸ¨false, falseâŸ©` by using equational reasoning:

```none
âŸ¦andâŸ§âŸ¨false, falseâŸ©
 = {expand the notation for false}
âŸ¦andâŸ§âŸ¨Ïƒá´¸âŸ¨âŸ©, Ïƒá´¸âŸ¨âŸ©âŸ©
 = {expand the definition of and}
âŸ¦case (injl unit) (drop iden)âŸ§âŸ¨Ïƒá´¸âŸ¨âŸ©, Ïƒá´¸âŸ¨âŸ©âŸ©
 = {evaluate case for Ïƒá´¸}
âŸ¦injl unitâŸ§âŸ¨âŸ¨âŸ©, Ïƒá´¸âŸ¨âŸ©âŸ©
 = {evaluate injl}
Ïƒá´¸(âŸ¦unitâŸ§âŸ¨âŸ¨âŸ©, Ïƒá´¸âŸ¨âŸ©âŸ©)
 = {evaluate unit}
Ïƒá´¸âŸ¨âŸ©
 = {by the notation for false}
false
```

We get the expected result of `false`. 

Letâ€™s try it again on the input `âŸ¨true, trueâŸ©`.

```none
âŸ¦andâŸ§âŸ¨true, trueâŸ©
 = {expand the notation for true and the definition of and}
âŸ¦case (injl unit) (drop iden)âŸ§âŸ¨Ïƒá´¿âŸ¨âŸ©, Ïƒá´¿âŸ¨âŸ©âŸ©
 = {evaluate case for Ïƒá´¿}
âŸ¦drop idenâŸ§âŸ¨âŸ¨âŸ©, Ïƒá´¿âŸ¨âŸ©âŸ©
 = {evaluate drop}
âŸ¦idenâŸ§(Ïƒá´¿âŸ¨âŸ©)
 = {evaluate iden}
Ïƒá´¿âŸ¨âŸ©
 = {by the notation for true}
true
```

Again, we get the expected result of `true`. We will leave trying the remaining inputs for the curious reader.

## Other logic operations

The definition of the `not` operation requires a helper combinator:

```none
                   f : A âŠ¢ C    g : B âŠ¢ C
-------------------------------------------------------------
copair f g â‰” iden â–µ unit â¨¾ case (take f) (take g) : A + B âŠ¢ C
```

The initial `iden â–µ unit : A âŠ¢ A Ã— ğŸ™`  adds an empty â€œenvironmentâ€ to the input, enabling the `case` combinator to apply. The use of `take` in the two branches drops this empty environment to execute `f` or `g`.

Now we can define all other Boolean logical operations:

* `or â‰” case (drop iden) (injr unit) : ğŸš Ã— ğŸš âŠ¢ ğŸš`
* `not â‰” copair (injr unit) (injl unit) : ğŸš âŠ¢ ğŸš`
* `xor â‰” case (drop iden) (drop not) : ğŸš Ã— ğŸš âŠ¢ ğŸš`

## Bit Adders

In digital logic, a â€œhalf-adderâ€ is a circuit that takes two bits and adds them, producing a two-bit output: a carry bit and the sum bit. We can implement this in Simplicity by pairing up the `and` and `xor` operations:

```none
half-adder â‰” and â–µ xor : ğŸš Ã— ğŸš âŠ¢ ğŸš Ã— ğŸš 
```

This function has two output bits, so we return a pair of the two output types.

A â€œfull-adderâ€ takes an additional third â€œcarry-inâ€ bit and adds them all together, producing the same two-bit output. We must use a nested tuple to represent three inputs. We have two choices: `ğŸš Ã— (ğŸš Ã— ğŸš)` or `(ğŸš Ã— ğŸš) Ã— ğŸš`. These types are not quite the same, and we must choose one. For this example, we will choose the latter.

Types in Simplicity are often nested tuples, representing an â€œenvironmentâ€ of parameters. It is common to use sequences of `take`, `drop`, and `iden` to access specific parameters from such an environment. For sequences of these combinators, a compact notation will be used:

* `O f`  is notation for `take f`.
* `I f` is notation for `drop f`.
* `H` is notation for `iden`.

For example, `I O H` means `drop (take iden) : A Ã— (B Ã— C) âŠ¢ B`, which extracts the middle value out of its input.


ğŸ›ˆ
The use of `O` and `I` for `take` and `drop` is meant to evoke a sense of binary digits. If we think of a nested tuple as a binary tree and label the treeâ€™s positions with positive binary numbers appropriately, then our notation becomes the reversed binary digits (thinking of `H` as the leading 1 digit) of a location within that tree from which we are retrieving data. Such expressions form a kind of De Bruijn indices for Simplicity

âš 
The `I`, `O`, and `H` notation is only used for subexpressions that consist only of `take`, `drop`, and `iden`. They are not used for other occurrences of `take` or `drop`.

A full-adder is the composition of two half-adders, taking the logical `or` of the two carry bits:

```none
full-adder â‰” take half-adder â–µ I H
           â¨¾ O O H â–µ (O I H â–µ I H â¨¾ half-adder)
           â¨¾ (O H â–µ I O H â¨¾ or) â–µ I I H
           : (ğŸš Ã— ğŸš) Ã— ğŸš âŠ¢ ğŸš Ã— ğŸš
```

In the first line, `take half-adder â–µ I H : (ğŸš Ã— ğŸš) Ã— ğŸš âŠ¢ (ğŸš Ã— ğŸš) Ã— ğŸš`, we run the half-adder on the first two bits, and we save the last bit. In the second line, `O O H â–µ (O I H â–µ I H â¨¾ half-adder) : (ğŸš Ã— ğŸš) Ã— ğŸš âŠ¢ ğŸš Ã— (ğŸš Ã— ğŸš)`, we save the first bit (which is the carry-out bit of the first half-adder) and run the half-adder on the last two bits. In the last line, `(O H â–µ I O H â¨¾ or) â–µ I I H: ğŸš Ã— (ğŸš Ã— ğŸš) âŠ¢ ğŸš Ã— ğŸš`, we take the logical *or* of the first two bits (which are the carry-outs of the two half-adders) and also return the sum-out bit of the second half-adder.

This code illustrates how one programs in Simplicity. We use the `I`, `O`, and `H` notation to reference bits of data from the subexpressionâ€™s input type, which is then formed into a suitable â€œenvironmentâ€ that is used to â€œcallâ€ other functions using sequential composition.

Simplicity users do not have to define such low-level operations themselves. Later in this series, we will discuss our standard library of jets that implement common functions.

Furthermore, end users are not expected to directly program in Simplicity, in the same way that end users are not expected to directly program with Bitcoin Script. Instead, we expect end users will use higher-level languages, such as SimplicityHL, to generate Simplicity. For example, SimplicityHL manages the â€œenvironmentâ€ of each subexpression, letting one use named variables, which are compiled into appropriate sequence of `take`s and `drop`s.

# Vectors

Given a Simplicity type `A`, we can define fixed-length vectors by forming iterated products of `A`:

* `AÂ² â‰” A Ã— A`
* `Aâ´ â‰” AÂ² Ã— AÂ²`
* `Aâ¸ â‰” Aâ´ Ã— Aâ´`
* `â€¦`

These types may be alternatively written as `A^2`, `A^4`, `A^8`, etc.

We will define vectors only for lengths that are powers of two. One can define notation for other powers, but a convention needs to be chosen for how to bracket the product types.

Given an expression `f : A âŠ¢ B`, we can repeatedly pair it with itself in order to â€œmapâ€ it over a vector of any fixed length:

* `fÂ² â‰” f â–µ f : AÂ² âŠ¢ BÂ²`
* `fâ´ â‰” fÂ² â–µ fÂ² : Aâ´ âŠ¢ Bâ´`
* `fâ¸ â‰” fâ´ â–µ fâ´ : Aâ¸ âŠ¢ Bâ¸`

Given a function `f : A Ã— B âŠ¢ B`, we can iterate or â€œfoldâ€ it over a vector of any fixed length:

* `fold-right-2 f â‰” O O H â–µ (O I H â–µ I H â¨¾ f) â¨¾ f : AÂ² Ã— B âŠ¢ B`
* `fold-right-4 f â‰” fold-right-2 (fold-right-2 f) : Aâ´ Ã— B âŠ¢ B`
* `fold-right-8 f â‰” fold-right-2 (fold-right-4 f) : Aâ¸ Ã— B âŠ¢ B`

There are many variations of these constructions we can implement. Given `f : A Ã— B âŠ¢ C`, we can â€œzipâ€ it over a pair of vectors with `zip-n f : (Aâ¿ Ã— Bâ¿) âŠ¢ Câ¿`. Given `f : (A Ã— B) Ã— C âŠ¢ C`, we can fold it over a pair of vectors with `bifold-right-n f : (Aâ¿ Ã— Bâ¿) âŠ¢ C`. We can combine `map` and `fold-right` into an accumulating combinator that takes `f : A Ã— C âŠ¢ C Ã— B` and results in `map-accum-right-n f : Aâ¿ Ã— C âŠ¢ C Ã— Bâ¿`. Many more variants are possible.

## Multi-bit Words

A vector of bits gives us multi-bit integers. For example, `ğŸšÂ³Â²` is a 32-bit word type. `ğŸšÂ²âµâ¶` is a 256-bit word type, which is suitable for hashes and other cryptographic operations.

Given our â€œfull-adderâ€ on bits, we can use a variant of the vector operations above to define a â€œripple carry adderâ€ over multi-bit words:

```none
full-adder-n â‰” zip-accum-right-n full-adder : (ğŸšâ¿ Ã— ğŸšâ¿) Ã— ğŸš âŠ¢ ğŸš Ã— ğŸšâ¿
```

`full-adder-n` takes two n-bit binary numbers and a one-bit carry-input value and returns a one-bit carry-out flag and an n-bit sum.

### SHA-256

In this manner, we can recursively define all our arithmetic operations on multi-bit words: subtraction, multiplication, division, etc. We can define bit-wise logical operations such as logical *and*, logical *or*, logical *xor*, etc. By repeatedly combining these operations, we can even build SHA-256â€™s block compression function: 

`sha256-hash-block â‰” â€¦ : ğŸšÂ²âµâ¶ Ã— ğŸšâµÂ¹Â² âŠ¢ ğŸšÂ²âµâ¶`

But you donâ€™t have to trust us. [The SHA-256 compression is formally defined using Simplicity](https://github.com/BlockstreamResearch/simplicity/blob/a619ab60d1c1e4c67b7e8680237ec811215f7cbc/Coq/Simplicity/SHA256.v#L93-L141) within the Rocq proof assistant (formerly named the Coq proof assistant), and it comes with [a formal proof that the `sha256-hash-block` implementation is correct](https://github.com/BlockstreamResearch/simplicity/blob/a619ab60d1c1e4c67b7e8680237ec811215f7cbc/Coq/Simplicity/SHA256.v#L235-L236).

Of course, the compression runs too slowly to be practical when executing it as raw Simplicity. We will introduce jets later in this series, which are used to execute common functions such as the SHA-256 compression function natively. However, we will still make use of such pure Simplicity implementations as formal specifications for our jets.

# Option Types

Option types are made by taking a sum with the unit type:

`Option A â‰” ğŸ™ + A`

The type `Option A` may also be written as `A?` or `ğ•Š A` (where `ğ•Š` stands for â€œsuccessorâ€). As with vectors, functions can be â€œmappedâ€ over the option type:

```none
                 f : A âŠ¢ B
------------------------------------------
f? â‰” copair (injl unit) (injr f) : A? âŠ¢ B?
```

We can also define monadic combinators such as bind:

```none
              f : A âŠ¢ B?
---------------------------------------
bind f â‰” copair (injl unit) f : A? âŠ¢ B?
```

# Variable Length Buffers

We can also define what we call â€œbuffers,â€ which are types for partially filled vectors.

* `Aá‘‰Â² â‰” A?`
* `Aá‘‰â´ â‰” AÂ²? Ã— Aá‘‰Â²`
* `Aá‘‰â¸ â‰” Aâ´? Ã— Aá‘‰â´`
* `â€¦`


ğŸ›ˆ
The type `Xá‘‰â¸` expands to `(1 + Xâ´) Ã— ((1 + XÂ²) Ã— (1 + X))`. If we pretend this is a polynomial and expand it, we get `1 + X + XÂ² + XÂ³ + Xâ´ + Xâµ + Xâ¶ + Xâ·`. Interpreting this polynomial as a type, it is the sum of all possible tuples of X up to 7, including the empty tuple. In other words, it is exactly the type of lists whose length is strictly less than 8.

As with vectors, we can define various mapping and folding operations over buffers. We can also define stack operations such as `push-<n : Aá‘‰â¿ Ã— A âŠ¢ Aâ¿ + Aá‘‰â¿` and `pop-<n : Aá‘‰â¿ âŠ¢ (Aá‘‰â¿ Ã— A)?`. `push-<n` takes a buffer and a new item and appends it to the buffer, returning a full vector in case the buffer overflows. `pop-<n` takes a buffer and removes an item, returning the smaller buffer and the item removed, optionally returning nothing in case the original buffer was empty.

For example, we can define `push-<n` recursively:

* ```
  push-<2 â‰” case (drop (injr (injr iden))) (injl iden)
* ```
  push-<4 â‰” ((O I H â–µ IH) â¨¾ push-<2) â–µ O O H
          â¨¾ case (I H â–µ O H â¨¾ case (injr (injr (I H) â–µ injl unit)) (injl iden))
                 (injr (I H â–µ O H))
* ```
  push-<8 â‰” ((O I H â–µ IH) â¨¾ push-<4) â–µ O O H
          â¨¾ case (I H â–µ O H â¨¾ case (injr (injr (I H) â–µ (injl unit â–µ injl unit))) (injl iden))
                 (injr (I H â–µ O H))
* `â€¦`

As you can see, raw Simplicity becomes inscrutable once one reaches a certain level of complexity. Again, we expect end users to utilize higher-level languages, such as SimplicityHL, that can generate these idiomatic expressions.

# Conclusion

In this part, we illustrated how to build logical operations starting from bits. From these logic operations, we were able to build bit-level arithmetic and illustrate how to reason about their execution. After developing vector types, we showed how to iterate over multi-bit words to define arithmetic. Continuing in this way, we can define cryptographic operations, such as SHA-256 and Schnorr signature validation, using just our computational Simplicity combinators. All of which we have actually defined using Simplicity.

This part is not meant as a comprehensive guide to the various possible data types and operations that we can build in Simplicity, but instead, it serves to illustrate how it is possible to build practical functionality within Simplicityâ€™s constraints. Even though Simplicityâ€™s types are all finitely bounded, we can still define useful vectors and buffer types and operations that iterate over values within these structures.

The actual specifications of operations in our standard library are a little different from the definitions used here. For instance, the full-adder in our standard library uses a 3-way *xor* and a â€œmajorityâ€ logic function in its implementation, rather than using two half-adders as shown here.

Later, we will see that, in practice, Simplicity programs use jets for arithmetic and cryptographic operations. However, jets are limited to replacing expressions. The combinators for iterating over buffers and vectors we have defined cannot be replaced with jets. These defined combinators will appear in actual Simplicity programs. Although, rather than directly using these combinators, we expect end users will use higher-level languages, such as SimplicityHL, to generate such Simplicity expressions.

A keen-eyed reader may have noticed that our recursively defined combinators appear to grow exponentially in expression size. However, this is not a problem. Later, when we talk about serialization, we will see that expressions are encoded as a DAG (directed acyclic graph) rather than as a tree. So the actual presentation of these expressions will only grow linearly in size.

So far, we have only been considering pure computations. However, we need some way to interact with transaction data for tasks like signing transactions, and we need to be able to have the program fail somehow if the signature is not valid. In the next part, we will discuss side-effects in Simplicity.

-------------------------

